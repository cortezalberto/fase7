"""
Ejemplo de integraci√≥n con Google Gemini

Este script demuestra c√≥mo usar el sistema AI-Native con Google Gemini en lugar del
Mock provider.

REQUISITOS:
1. Tener una API key de Google AI Studio (https://makersuite.google.com/app/apikey)
2. Configurar la API key en .env o como variable de entorno
3. Instalar dependencias: pip install google-generativeai

VENTAJAS DE GEMINI:
- API gratuita con l√≠mites generosos (60 requests/min, 1M tokens/d√≠a)
- Gemini 1.5 Flash: Muy r√°pido y econ√≥mico
- Gemini 1.5 Pro: Contexto de 2M tokens (el m√°s grande del mercado)
- Excelente para c√≥digo y razonamiento

AUTOR: Claude Code (Sonnet 4.5)
FECHA: 2025-11-19
"""

import sys
import io
import os
from dotenv import load_dotenv

# Fix Windows encoding
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# Cargar variables de entorno desde .env
load_dotenv()

from src.ai_native_mvp.llm import LLMProviderFactory, LLMMessage, LLMRole
from src.ai_native_mvp.core.ai_gateway import AIGateway
from src.ai_native_mvp.database import get_db_session
from src.ai_native_mvp.database.repositories import (
    SessionRepository,
    TraceRepository,
    RiskRepository,
    EvaluationRepository,
    TraceSequenceRepository
)

print("=" * 80)
print("EJEMPLO: Integraci√≥n con Google Gemini")
print("=" * 80)

# =============================================================================
# PASO 1: Verificar configuraci√≥n
# =============================================================================

print("\n[PASO 1] Verificar configuraci√≥n de Google Gemini...")

# Verificar que existe GEMINI_API_KEY
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    print("‚ùå ERROR: GEMINI_API_KEY no est√° configurada.")
    print("\nPara configurar:")
    print("1. Copia .env.example a .env:")
    print("   cp .env.example .env")
    print("\n2. Edita .env y agrega tu API key:")
    print("   GEMINI_API_KEY=AIzaSy...")
    print("\n3. Obt√©n tu API key GRATIS en: https://makersuite.google.com/app/apikey")
    print("   (No requiere tarjeta de cr√©dito, l√≠mites generosos)")
    sys.exit(1)

# Verificar modelo configurado
model = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
print(f"‚úÖ API Key encontrada (primeros 10 caracteres): {api_key[:10]}...")
print(f"‚úÖ Modelo configurado: {model}")

# =============================================================================
# PASO 2: Crear proveedor Gemini
# =============================================================================

print("\n[PASO 2] Crear proveedor Google Gemini...")

try:
    # Crear desde variables de entorno (m√©todo recomendado)
    llm_provider = LLMProviderFactory.create_from_env("gemini")
    print(f"‚úÖ Proveedor Gemini creado exitosamente")

    # Obtener informaci√≥n del modelo
    model_info = llm_provider.get_model_info()
    print(f"   - Proveedor: {model_info['provider']}")
    print(f"   - Modelo: {model_info['model']}")
    print(f"   - Ventana de contexto: {model_info['context_window']}")
    print(f"   - Capacidades: {', '.join([c for c in model_info['capabilities'] if c])}")
    print(f"   - Pricing: {model_info.get('pricing', 'N/A')}")

except ValueError as e:
    print(f"‚ùå ERROR: {e}")
    sys.exit(1)
except ImportError as e:
    print(f"‚ùå ERROR: {e}")
    print("\nInstala las dependencias faltantes:")
    print("   pip install google-generativeai")
    sys.exit(1)

# =============================================================================
# PASO 3: Probar generaci√≥n simple
# =============================================================================

print("\n[PASO 3] Probar generaci√≥n simple con Gemini...")

messages = [
    LLMMessage(
        role=LLMRole.SYSTEM,
        content="Eres un tutor cognitivo que ayuda a estudiantes de programaci√≥n a razonar, sin dar soluciones completas."
    ),
    LLMMessage(
        role=LLMRole.USER,
        content="¬øQu√© es una cola circular y en qu√© casos es mejor que una cola simple?"
    )
]

try:
    print("   Enviando request a Google Gemini...")
    response = llm_provider.generate(
        messages=messages,
        temperature=0.7,
        max_tokens=500
    )

    print(f"‚úÖ Respuesta recibida de {response.model}")
    print(f"\n{'‚îÄ' * 80}")
    print("RESPUESTA DEL TUTOR:")
    print(f"{'‚îÄ' * 80}")
    print(response.content)
    print(f"{'‚îÄ' * 80}")

    # Mostrar m√©tricas de uso
    print(f"\nüìä M√©tricas de uso:")
    print(f"   - Tokens de entrada (prompt): {response.usage['prompt_tokens']}")
    print(f"   - Tokens de salida (respuesta): {response.usage['completion_tokens']}")
    print(f"   - Total de tokens: {response.usage['total_tokens']}")

    # Gemini es gratuito hasta ciertos l√≠mites
    print(f"\nüí∞ Costo:")
    print(f"   - Gemini 1.5 Flash: GRATIS (hasta 60 req/min, 1M tokens/d√≠a)")
    print(f"   - Esta interacci√≥n: $0.00 USD")

except Exception as e:
    print(f"‚ùå ERROR al generar respuesta: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# =============================================================================
# PASO 4: Integrar con AIGateway
# =============================================================================

print(f"\n[PASO 4] Integrar Gemini con AIGateway...")

try:
    with get_db_session() as db:
        # Crear repositorios
        session_repo = SessionRepository(db)
        trace_repo = TraceRepository(db)
        risk_repo = RiskRepository(db)
        evaluation_repo = EvaluationRepository(db)
        sequence_repo = TraceSequenceRepository(db)

        # Crear Gateway con Gemini provider (DI)
        gateway = AIGateway(
            llm_provider=llm_provider,  # ¬°Aqu√≠ usamos Gemini en lugar de Mock!
            session_repo=session_repo,
            trace_repo=trace_repo,
            risk_repo=risk_repo,
            evaluation_repo=evaluation_repo,
            sequence_repo=sequence_repo
        )

        print("‚úÖ Gateway creado con proveedor Gemini")

        # Crear sesi√≥n
        session_id = gateway.create_session(
            student_id="gemini_test_student",
            activity_id="prog2_cola_circular",
            mode="TUTOR"
        )

        print(f"‚úÖ Sesi√≥n creada: {session_id}")

except Exception as e:
    print(f"‚ùå ERROR al crear Gateway: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# =============================================================================
# PASO 5: Procesar interacci√≥n con Gemini
# =============================================================================

print(f"\n[PASO 5] Procesar interacci√≥n usando Gemini...")

try:
    # Primera interacci√≥n: Pregunta conceptual
    print("\nüìù Interacci√≥n 1: Pregunta conceptual")
    result1 = gateway.process_interaction(
        session_id=session_id,
        prompt="¬øC√≥mo implemento una cola circular en Python? ¬øQu√© estructura de datos debo usar?",
        context={}
    )

    print(f"\n{'‚îÄ' * 80}")
    print("RESPUESTA DEL SISTEMA (con Google Gemini):")
    print(f"{'‚îÄ' * 80}")
    print(result1["message"])
    print(f"{'‚îÄ' * 80}")

    print(f"\nüìä Metadata de la interacci√≥n:")
    print(f"   - Agente usado: {result1['agent_used']}")
    print(f"   - Estado cognitivo: {result1.get('cognitive_state', 'N/A')}")
    print(f"   - Bloqueado: {'S√≠' if result1.get('blocked') else 'No'}")

    # Segunda interacci√≥n: Solicitud de c√≥digo (deber√≠a ser bloqueada por governance)
    print("\n\nüìù Interacci√≥n 2: Solicitud de c√≥digo completo (test de governance)")
    result2 = gateway.process_interaction(
        session_id=session_id,
        prompt="Dame el c√≥digo completo de una cola circular en Python, implementado y listo para usar.",
        context={}
    )

    print(f"\n{'‚îÄ' * 80}")
    print("RESPUESTA DEL SISTEMA:")
    print(f"{'‚îÄ' * 80}")
    print(result2["message"])
    print(f"{'‚îÄ' * 80}")

    print(f"\nüìä Metadata de la interacci√≥n:")
    print(f"   - Agente usado: {result2['agent_used']}")
    print(f"   - Estado cognitivo: {result2.get('cognitive_state', 'N/A')}")
    print(f"   - Bloqueado: {'S√≠' if result2.get('blocked') else 'No'}")

    if result2.get('blocked'):
        print(f"   ‚ö†Ô∏è GOV-IA bloque√≥ la solicitud (delegaci√≥n total detectada)")

except Exception as e:
    print(f"‚ùå ERROR al procesar interacci√≥n: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# =============================================================================
# PASO 6: Verificar trazas N4
# =============================================================================

print(f"\n[PASO 6] Verificar trazas N4 capturadas...")

try:
    with get_db_session() as db:
        trace_repo = TraceRepository(db)
        traces = trace_repo.get_by_session(session_id)

        print(f"‚úÖ {len(traces)} trazas capturadas:")
        for i, trace in enumerate(traces, 1):
            print(f"\n   Traza {i}:")
            print(f"   - ID: {trace.id}")
            print(f"   - Tipo: {trace.interaction_type}")
            print(f"   - Nivel: {trace.trace_level}")
            print(f"   - Estado cognitivo: {trace.cognitive_state or 'N/A'}")
            print(f"   - Contenido: {trace.content[:80]}...")

except Exception as e:
    print(f"‚ùå ERROR al recuperar trazas: {e}")
    import traceback
    traceback.print_exc()

# =============================================================================
# PASO 7: Verificar riesgos detectados
# =============================================================================

print(f"\n[PASO 7] Verificar riesgos detectados...")

try:
    with get_db_session() as db:
        risk_repo = RiskRepository(db)
        risks = risk_repo.get_by_session(session_id)

        if len(risks) > 0:
            print(f"‚ö†Ô∏è {len(risks)} riesgo(s) detectado(s):")
            for i, risk in enumerate(risks, 1):
                print(f"\n   Riesgo {i}:")
                print(f"   - Tipo: {risk.risk_type}")
                print(f"   - Nivel: {risk.risk_level}")
                print(f"   - Dimensi√≥n: {risk.dimension}")
                print(f"   - Descripci√≥n: {risk.description}")
        else:
            print("‚úÖ No se detectaron riesgos")

except Exception as e:
    print(f"‚ùå ERROR al recuperar riesgos: {e}")
    import traceback
    traceback.print_exc()

# =============================================================================
# RESUMEN FINAL
# =============================================================================

print("\n" + "=" * 80)
print("RESUMEN DE LA INTEGRACI√ìN CON GOOGLE GEMINI")
print("=" * 80)

print("""
‚úÖ Integraci√≥n exitosa con Google Gemini

Aspectos verificados:
1. ‚úÖ Configuraci√≥n de API key desde variables de entorno
2. ‚úÖ Creaci√≥n de proveedor Gemini con LLMProviderFactory
3. ‚úÖ Generaci√≥n de respuestas usando Gemini 1.5 Flash
4. ‚úÖ Integraci√≥n con AIGateway (reemplazo de Mock provider)
5. ‚úÖ Procesamiento de interacciones con Gemini
6. ‚úÖ Captura de trazas N4 (persistencia funcionando)
7. ‚úÖ Detecci√≥n de riesgos (governance activo)

El sistema AI-Native est√° completamente funcional con Google Gemini.

VENTAJAS DE GEMINI:
- üÜì Completamente GRATUITO hasta l√≠mites generosos:
  * Gemini 1.5 Flash: 60 requests/min, 1M tokens/d√≠a
  * Gemini 1.5 Pro: 2 requests/min, 32K tokens/d√≠a (GRATIS)
- ‚ö° Gemini 1.5 Flash es MUY r√°pido (m√°s que GPT-3.5)
- üß† Contexto de 2M tokens (vs 128K de GPT-4)
- üí∞ Sin costo para desarrollo y testing

COMPARATIVA DE COSTOS (100 estudiantes, 20 interacciones c/u):
- Mock: $0.00 (gratis)
- Gemini 1.5 Flash: $0.00 (gratis hasta l√≠mites)
- GPT-3.5-turbo: ~$1.40/mes
- GPT-4: ~$40/mes

PR√ìXIMOS PASOS:
1. Para usar en producci√≥n, actualiza la API para usar create_from_env()
2. Monitorea l√≠mites en Google AI Studio dashboard
3. Considera Gemini 1.5 Pro para tareas complejas (tambi√©n gratis)
4. Usa Gemini 1.5 Flash para la mayor√≠a de interacciones (muy r√°pido)

OBTENER API KEY GRATUITA:
1. Visita: https://makersuite.google.com/app/apikey
2. Inicia sesi√≥n con tu cuenta de Google
3. Crea una nueva API key (no requiere tarjeta de cr√©dito)
4. Copia la key y agr√©gala a tu archivo .env
""")

print("=" * 80)