# ============================================================================
# AI-Native MVP - Prometheus Alert Rules
# ============================================================================
# Author: Mag. Alberto Cortez
# Date: 2025-12-30
# ============================================================================

groups:
  # ==========================================================================
  # API Backend Alerts
  # ==========================================================================
  - name: ai-native-api
    rules:
      # High error rate
      - alert: HighErrorRate
        expr: |
          (
            sum(rate(http_requests_total{job="ai-native-api",status=~"5.."}[5m]))
            /
            sum(rate(http_requests_total{job="ai-native-api"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: critical
          service: ai-native-api
        annotations:
          summary: "High HTTP error rate detected"
          description: "Error rate is {{ $value | printf \"%.2f\" }}% (threshold: 5%)"

      # High response time
      - alert: HighResponseTime
        expr: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket{job="ai-native-api"}[5m])) by (le)
          ) > 2
        for: 5m
        labels:
          severity: warning
          service: ai-native-api
        annotations:
          summary: "High API response time"
          description: "95th percentile response time is {{ $value | printf \"%.2f\" }}s (threshold: 2s)"

      # API Down
      - alert: APIDown
        expr: up{job="ai-native-api"} == 0
        for: 1m
        labels:
          severity: critical
          service: ai-native-api
        annotations:
          summary: "API Backend is down"
          description: "AI-Native API has been down for more than 1 minute"

      # High LLM latency
      - alert: HighLLMLatency
        expr: |
          avg(ai_native_llm_call_duration_seconds) > 10
        for: 5m
        labels:
          severity: warning
          service: ai-native-api
        annotations:
          summary: "High LLM call latency"
          description: "Average LLM call duration is {{ $value | printf \"%.2f\" }}s"

      # Low cache hit rate
      - alert: LowCacheHitRate
        expr: ai_native_cache_hit_rate_percent < 50
        for: 10m
        labels:
          severity: warning
          service: ai-native-api
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value | printf \"%.1f\" }}% (threshold: 50%)"

      # Critical risks detected
      - alert: CriticalRisksDetected
        expr: increase(ai_native_risks_detected_total{risk_level="CRITICAL"}[1h]) > 5
        for: 5m
        labels:
          severity: warning
          service: ai-native-api
        annotations:
          summary: "Multiple critical risks detected"
          description: "{{ $value }} critical risks detected in the last hour"

      # Governance blocks spike
      - alert: GovernanceBlocksSpike
        expr: increase(ai_native_governance_blocks_total[5m]) > 10
        for: 5m
        labels:
          severity: warning
          service: ai-native-api
        annotations:
          summary: "High number of governance blocks"
          description: "{{ $value }} governance blocks in the last 5 minutes"

  # ==========================================================================
  # PostgreSQL Alerts
  # ==========================================================================
  - name: postgresql
    rules:
      # PostgreSQL down
      - alert: PostgreSQLDown
        expr: pg_up == 0
        for: 1m
        labels:
          severity: critical
          service: postgresql
        annotations:
          summary: "PostgreSQL is down"
          description: "PostgreSQL database has been down for more than 1 minute"

      # High connection count
      - alert: PostgreSQLHighConnections
        expr: |
          pg_stat_activity_count / pg_settings_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: postgresql
        annotations:
          summary: "PostgreSQL high connection usage"
          description: "Connection usage is {{ $value | printf \"%.1f\" }}% of max_connections"

      # Deadlocks detected
      - alert: PostgreSQLDeadlocks
        expr: increase(pg_stat_database_deadlocks[5m]) > 0
        for: 1m
        labels:
          severity: warning
          service: postgresql
        annotations:
          summary: "PostgreSQL deadlocks detected"
          description: "{{ $value }} deadlocks in the last 5 minutes"

      # Low cache hit ratio
      - alert: PostgreSQLLowCacheHitRatio
        expr: |
          pg_stat_database_blks_hit / (pg_stat_database_blks_hit + pg_stat_database_blks_read) < 0.9
        for: 10m
        labels:
          severity: warning
          service: postgresql
        annotations:
          summary: "PostgreSQL low cache hit ratio"
          description: "Cache hit ratio is {{ $value | printf \"%.2f\" }} (threshold: 0.9)"

  # ==========================================================================
  # Redis Alerts
  # ==========================================================================
  - name: redis
    rules:
      # Redis down
      - alert: RedisDown
        expr: redis_up == 0
        for: 1m
        labels:
          severity: critical
          service: redis
        annotations:
          summary: "Redis is down"
          description: "Redis cache has been down for more than 1 minute"

      # High memory usage
      - alert: RedisHighMemoryUsage
        expr: |
          redis_memory_used_bytes / redis_memory_max_bytes * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis high memory usage"
          description: "Memory usage is {{ $value | printf \"%.1f\" }}%"

      # High eviction rate
      - alert: RedisHighEvictionRate
        expr: rate(redis_evicted_keys_total[5m]) > 100
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis high key eviction rate"
          description: "Evicting {{ $value | printf \"%.1f\" }} keys/second"

      # Too many blocked clients
      - alert: RedisTooManyBlockedClients
        expr: redis_blocked_clients > 10
        for: 5m
        labels:
          severity: warning
          service: redis
        annotations:
          summary: "Redis has too many blocked clients"
          description: "{{ $value }} clients are blocked"

  # ==========================================================================
  # Infrastructure Alerts
  # ==========================================================================
  - name: infrastructure
    rules:
      # High CPU usage (if node-exporter is enabled)
      - alert: HighCPUUsage
        expr: |
          100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
        for: 10m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High CPU usage on {{ $labels.instance }}"
          description: "CPU usage is {{ $value | printf \"%.1f\" }}%"

      # High memory usage
      - alert: HighMemoryUsage
        expr: |
          (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High memory usage on {{ $labels.instance }}"
          description: "Memory usage is {{ $value | printf \"%.1f\" }}%"

      # Disk space low
      - alert: DiskSpaceLow
        expr: |
          (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "Low disk space on {{ $labels.instance }}"
          description: "Disk usage is {{ $value | printf \"%.1f\" }}%"
