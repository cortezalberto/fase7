# üéØ An√°lisis de Arquitectura: Gateway + Agentes + Ollama + Phi-3

**Fecha**: 5 de Diciembre, 2025  
**Estado**: ‚úÖ Arquitectura Validada + Integraci√≥n Phi-3 en Progreso

---

## üìã Resumen Ejecutivo

El sistema Phoenix MVP tiene una **arquitectura de agentes bien dise√±ada** basada en:
- ‚úÖ Gateway central **stateless** con Dependency Injection completa
- ‚úÖ 7 agentes especializados con responsabilidades claras
- ‚úÖ Motor de razonamiento cognitivo-pedag√≥gico (CRPE)
- ‚úÖ Sistema de trazabilidad N4 (4 niveles de profundidad)
- ‚úÖ Integraci√≥n con LLM via provider pattern (flexible)
- üîÑ **En integraci√≥n**: Ollama + Phi-3 (Microsoft, 3.8B par√°metros)

---

## üèóÔ∏è Arquitectura C4 del Sistema

### C1: Motor LLM (Provider Pattern)
**Ubicaci√≥n**: `backend/llm/`

**Componentes**:
- `base.py`: `LLMProvider` (interfaz abstracta)
- `factory.py`: `LLMProviderFactory` (patr√≥n Factory)
- `ollama_provider.py`: `OllamaProvider` (implementaci√≥n)
- `mock_provider.py`: `MockProvider` (testing)

**Estado**: ‚úÖ **EXCELENTE**
- Abstracci√≥n limpia con ABC
- Factory pattern para crear providers
- F√°cil agregar nuevos providers
- Soporte async/await
- Streaming integrado
- Metrics y observabilidad

**Integraci√≥n Phi-3**:
```python
# Configuraci√≥n actual
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi3  # ‚Üê Microsoft Phi-3
```

---

### C2: Ingesta y Comprensi√≥n de Prompt (IPC)
**Ubicaci√≥n**: `backend/core/cognitive_engine.py` ‚Üí `classify_prompt()`

**Funci√≥n**: Analiza el prompt del estudiante y extrae:
- Estado cognitivo (exploraci√≥n, comprensi√≥n, aplicaci√≥n, etc.)
- Tipo de ayuda requerida (conceptual, procedimental, estrat√©gica)
- Detecci√≥n de delegaci√≥n total
- Nivel de dificultad cognitiva

**Estado**: ‚úÖ **BUENO**
- Clasificaci√≥n basada en patrones y heur√≠sticas
- Detecci√≥n de anti-patrones (delegaci√≥n total)
- Puede mejorarse con LLM para clasificaci√≥n m√°s precisa

**Recomendaci√≥n**:
```python
# Considerar usar Phi-3 para mejorar clasificaci√≥n
async def classify_prompt_with_llm(self, prompt: str):
    classification_prompt = f"""
    Analiza el siguiente prompt de un estudiante de programaci√≥n
    y clasifica su estado cognitivo y tipo de ayuda necesaria:
    
    Prompt: {prompt}
    
    Responde en JSON con: cognitive_state, help_type, delegation_detected
    """
    # Usar LLM para clasificaci√≥n m√°s inteligente
```

---

### C3: Motor de Razonamiento Cognitivo-Pedag√≥gico (CRPE)
**Ubicaci√≥n**: `backend/core/cognitive_engine.py`

**Funciones principales**:
1. `classify_prompt()` - Clasificaci√≥n cognitiva
2. `should_block_response()` - Gobernanza proactiva
3. `generate_pedagogical_response_strategy()` - Estrategia adaptativa
4. `evaluate_student_reasoning()` - Evaluaci√≥n metacognitiva

**Modos soportados**:
- `EXPLORATION` - Exploraci√≥n del problema
- `UNDERSTANDING` - Comprensi√≥n conceptual
- `APPLICATION` - Aplicaci√≥n de conocimiento
- `INTEGRATION` - Integraci√≥n de conceptos
- `EVALUATION` - Autoevaluaci√≥n

**Estado**: ‚úÖ **EXCELENTE**
- Basado en teor√≠a pedag√≥gica s√≥lida (Bloom, Zimmerman, Sweller)
- Estrategias diferenciadas seg√∫n estado cognitivo
- Prevenci√≥n de delegaci√≥n total
- Adaptativo al historial del estudiante

---

### C4: Gobernanza, Seguridad y Riesgo (GSR)
**Ubicaci√≥n**: `backend/agents/governance.py` + `backend/agents/risk_analyst.py`

**Agentes**:

#### 1. **GOV-IA** (Agente de Gobernanza)
**Responsabilidades**:
- Verificar cumplimiento de pol√≠ticas institucionales
- Gesti√≥n de riesgo en tiempo real
- Auditor√≠a y compliance
- Generaci√≥n de reportes institucionales

**Pol√≠ticas configurables**:
```python
policies = {
    "max_ai_assistance_level": 0.7,  # 0-1
    "require_explicit_ai_usage": True,
    "block_complete_solutions": True,
    "require_traceability": True,
    "enforce_academic_integrity": True,
}
```

**Estado**: ‚úÖ **BUENO**
- Implementa est√°ndares internacionales (UNESCO, OECD, IEEE, ISO)
- Pol√≠ticas configurables a nivel institucional/programa/curso/actividad
- Compliance checking antes de generar respuestas

#### 2. **AR-IA** (Analista de Riesgo)
**Dimensiones de riesgo monitoreadas**:
1. **RC** (Riesgos Cognitivos): Delegaci√≥n, razonamiento superficial
2. **RE** (Riesgos √âticos): Integridad acad√©mica
3. **REp** (Riesgos Epist√©micos): Errores conceptuales, aceptaci√≥n acr√≠tica
4. **RT** (Riesgos T√©cnicos): Vulnerabilidades, mala calidad
5. **RG** (Riesgos de Gobernanza): Violaci√≥n de pol√≠ticas

**Estado**: ‚úÖ **EXCELENTE**
- Cobertura completa de dimensiones de riesgo
- Umbrales configurables
- Detecci√≥n proactiva (no solo reactiva)
- Reportes detallados con evidencia

---

### C5: Orquestaci√≥n de Submodelos (OSM)
**Ubicaci√≥n**: `backend/core/ai_gateway.py` ‚Üí M√©todo `process_interaction()`

**Flujo de orquestaci√≥n**:
```
1. Validar entrada
2. Obtener sesi√≥n desde BD (stateless)
3. Clasificar prompt (IPC - C2)
4. Verificar gobernanza (GSR - C4)
5. Generar estrategia pedag√≥gica (CRPE - C3)
6. Seleccionar agente apropiado
7. Generar respuesta con LLM (C1)
8. Detectar riesgos (AR-IA)
9. Registrar en trazabilidad (TC-N4 - C6)
10. Persistir en BD
```

**Estado**: ‚úÖ **EXCELENTE**
- Orquestaci√≥n clara y secuencial
- Stateless (no guarda estado en memoria)
- Dependency Injection completa
- Testeable (dependencias mockables)
- Escalable (m√∫ltiples instancias posibles)

---

### C6: Trazabilidad Cognitiva N4
**Ubicaci√≥n**: `backend/models/trace.py` + `backend/agents/traceability.py`

**4 Niveles de trazabilidad**:
- **N1 (Observable)**: C√≥digo final, commits Git
- **N2 (Auditable)**: Interacciones con IA (prompts + respuestas)
- **N3 (Interpretable)**: Metadata pedag√≥gica (estrategias, estados cognitivos)
- **N4 (Cognitivo)**: Reconstrucci√≥n del camino cognitivo completo

**Entidades**:
```python
class CognitiveTrace:
    id: str
    session_id: str
    timestamp: datetime
    student_id: str
    activity_id: str
    interaction_type: InteractionType  # PROMPT | RESPONSE | INTERVENTION
    content: str
    level: TraceLevel  # N1 | N2 | N3 | N4
    cognitive_intent: Optional[str]
    agent_id: Optional[str]
    context: Dict[str, Any]

class TraceSequence:
    id: str
    session_id: str
    traces: List[CognitiveTrace]
    ai_dependency_score: float
    reasoning_path: List[str]
```

**Estado**: ‚úÖ **EXCELENTE**
- Modelo de datos robusto
- 4 niveles bien diferenciados
- Permite reconstrucci√≥n completa del proceso
- Base para evaluaci√≥n de procesos cognitivos

---

## ü§ñ Agentes Especializados

### 1. **T-IA-Cog** (Tutor IA Cognitivo)
**Ubicaci√≥n**: `backend/agents/tutor.py`

**Modos de tutor√≠a**:
- `SOCRATICO`: Preguntas socr√°ticas (m√©todo socr√°tico)
- `EXPLICATIVO`: Explicaciones conceptuales
- `GUIADO`: Pistas graduadas
- `METACOGNITIVO`: Reflexi√≥n sobre el proceso

**Niveles de ayuda**:
- `MINIMO`: Solo preguntas orientadoras
- `BAJO`: Pistas muy generales
- `MEDIO`: Pistas con detalle (sin c√≥digo completo)
- `ALTO`: Explicaciones detalladas (sin soluciones)

**Pol√≠ticas pedag√≥gicas**:
```python
policies = {
    "prioritize_questions": True,  # Siempre preguntar primero
    "require_justification": True,  # Pedir justificaci√≥n
    "adaptive_difficulty": True,   # Ajustar dificultad
    "max_help_level": HelpLevel.MEDIO,
    "block_complete_solutions": True,  # Nunca dar soluci√≥n completa
}
```

**Estado**: ‚úÖ **EXCELENTE**
- Basado en teor√≠a pedag√≥gica s√≥lida
- Previene delegaci√≥n total
- Promueve razonamiento activo
- Adaptativo al estado cognitivo

**Integraci√≥n con Phi-3**: ‚úÖ Listo
```python
# El tutor usa el LLM inyectado para generar respuestas
response = await self.llm_provider.generate(messages)
```

---

### 2. **E-IA-Proc** (Evaluador de Procesos)
**Ubicaci√≥n**: `backend/agents/evaluator.py`

**Funciones**:
1. An√°lisis de razonamiento (camino cognitivo)
2. Detecci√≥n de errores conceptuales y epistemol√≥gicos
3. Evaluaci√≥n de autorregulaci√≥n (Zimmerman, 2002)
4. Comparaci√≥n y coherencia evolutiva v√≠a Git
5. Generaci√≥n del Informe de Evaluaci√≥n Cognitiva (IEC)

**Dimensiones evaluadas**:
- Razonamiento algor√≠tmico
- Fundamentos conceptuales
- Autorregulaci√≥n
- Uso apropiado de IA
- Calidad del c√≥digo

**Estado**: ‚úÖ **EXCELENTE**
- Evaluaci√≥n de **procesos**, no solo resultados
- Integraci√≥n con Git (analiza evoluci√≥n del c√≥digo)
- No califica - genera evidencia para docentes
- Basado en marcos pedag√≥gicos validados

---

### 3. **AR-IA** (Analista de Riesgo)
Ver secci√≥n C4 arriba.

---

### 4. **GOV-IA** (Gobernanza)
Ver secci√≥n C4 arriba.

---

### 5. **GIT-IA** (Integraci√≥n Git)
**Ubicaci√≥n**: `backend/agents/git_integration.py`

**Funciones**:
- An√°lisis de commits (frecuencia, mensajes, tama√±o)
- Detecci√≥n de patrones sospechosos (copy-paste masivo)
- Correlaci√≥n temporal con trazas de IA
- An√°lisis de coherencia evolutiva

**Estado**: ‚úÖ **BUENO**
- Integraci√≥n con GitPython
- An√°lisis de metadata de commits
- Puede mejorarse con an√°lisis de diff m√°s profundo

---

### 6. **S-IA-X** (Simuladores Profesionales)
**Ubicaci√≥n**: `backend/agents/simulators.py`

**Simuladores implementados**:
- **Code Review Simulator**: Simula revisi√≥n de c√≥digo senior
- **Technical Interview Simulator**: Simula entrevista t√©cnica
- **Architecture Design Simulator**: Simula dise√±o de arquitectura
- **Debugging Session Simulator**: Simula debugging colaborativo

**Estado**: ‚úÖ **BUENO**
- Simuladores con roles bien definidos
- Feedback realista y profesional
- √ötil para preparaci√≥n profesional

---

### 7. **TC-N4** (Trazabilidad)
**Ubicaci√≥n**: `backend/agents/traceability.py`

Ver secci√≥n C6 arriba.

---

## üîß Integraci√≥n Ollama + Phi-3

### ¬øPor qu√© Phi-3?

**Microsoft Phi-3** es un modelo peque√±o (3.8B par√°metros) pero muy eficiente:

| Caracter√≠stica | Phi-3 | Llama2-7B | Mistral-7B |
|----------------|-------|-----------|------------|
| Par√°metros | 3.8B | 7B | 7B |
| Tama√±o descarga | ~2.2 GB | ~3.8 GB | ~4.1 GB |
| RAM requerida | ~4 GB | ~8 GB | ~8 GB |
| Velocidad | ‚ö° R√°pido | Normal | Normal |
| Calidad | üéØ Alta | Alta | Alta |
| Training data | Libros, c√≥digo, datos curados | Internet general | Internet general |
| Especialidad | **Razonamiento, c√≥digo, educaci√≥n** | General | General |

**Ventajas para nuestro caso de uso**:
- ‚úÖ Optimizado para **razonamiento** (ideal para tutor√≠as)
- ‚úÖ Excelente para **c√≥digo** (entrenado con c√≥digo de calidad)
- ‚úÖ Requiere **menos recursos** (m√°s barato de operar)
- ‚úÖ **M√°s r√°pido** (mejor experiencia de usuario)
- ‚úÖ Entrenado con datos **curados** (menos sesgos)

### Configuraci√≥n Actual

**docker-compose.yml**:
```yaml
ollama:
  image: ollama/ollama:latest
  container_name: ai-native-ollama
  ports:
    - "11434:11434"
  volumes:
    - ollama_data:/root/.ollama
  healthcheck:
    test: ["CMD", "ollama", "list"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 60s
  entrypoint: ["/bin/sh", "-c"]
  command:
    - |
      ollama serve &
      sleep 5
      ollama pull phi3
      wait
```

**.env**:
```bash
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434  # Local
# OLLAMA_BASE_URL=http://ollama:11434   # Docker
OLLAMA_MODEL=phi3
OLLAMA_TEMPERATURE=0.7
```

### Estado de Integraci√≥n

- ‚úÖ OllamaProvider implementado
- ‚úÖ Docker Compose configurado
- ‚úÖ Modelo Phi-3 en descarga (2.2 GB)
- ‚úÖ Script de prueba end-to-end creado
- üîÑ Pendiente: Ejecutar tests de integraci√≥n

---

## üìä Evaluaci√≥n de la Arquitectura

### Fortalezas ‚úÖ

1. **Separaci√≥n de responsabilidades clara**
   - Cada agente tiene un prop√≥sito √∫nico
   - Gateway orquesta sin l√≥gica de negocio pesada
   - Cognitive Engine separado de Gateway

2. **Stateless + DI = Escalable**
   - No estado en memoria (todo en BD)
   - Dependencias inyectadas (testeable)
   - Puede correr m√∫ltiples instancias

3. **Basado en teor√≠a pedag√≥gica s√≥lida**
   - Referencias acad√©micas expl√≠citas
   - Dimensiones bien fundamentadas
   - No es solo "chatbot educativo"

4. **Trazabilidad de primer nivel**
   - 4 niveles de profundidad
   - Permite auditor√≠a completa
   - Reconstrucci√≥n del proceso cognitivo

5. **Observabilidad integrada**
   - Prometheus metrics
   - Logging estructurado
   - Health checks

6. **Provider pattern flexible**
   - F√°cil cambiar de LLM
   - Mock provider para testing
   - Abstracci√≥n limpia

### √Åreas de Mejora üîÑ

1. **Cache LLM m√°s inteligente**
   - Actualmente: Cache simple por hash de prompt
   - Mejora: Cache sem√°ntico (embeddings)
   - Beneficio: Mayor hit rate, menos costos

2. **Clasificaci√≥n de prompts con LLM**
   - Actualmente: Heur√≠sticas y patterns
   - Mejora: Usar Phi-3 para clasificaci√≥n
   - Beneficio: Mayor precisi√≥n

3. **Evaluaci√≥n autom√°tica m√°s profunda**
   - Actualmente: M√©tricas basadas en trazas
   - Mejora: An√°lisis de c√≥digo con AST + LLM
   - Beneficio: Detecci√≥n de problemas m√°s sutil

4. **Tests de integraci√≥n m√°s completos**
   - Actualmente: Tests unitarios buenos
   - Mejora: Tests end-to-end con BD real
   - Beneficio: Mayor confianza en despliegues

5. **Frontend para visualizaci√≥n**
   - Actualmente: Solo API
   - Mejora: Dashboard para estudiantes/docentes
   - Beneficio: Mejor UX

### Riesgos üö®

1. **Dependencia de Ollama**
   - Riesgo: Si Ollama cae, todo el sistema falla
   - Mitigaci√≥n: Fallback a Mock provider + circuit breaker

2. **Performance de Phi-3 en CPU**
   - Riesgo: Latencia alta sin GPU
   - Mitigaci√≥n: Cache agresivo + async

3. **Calidad de respuestas de modelo peque√±o**
   - Riesgo: Phi-3 (3.8B) puede tener limitaciones
   - Mitigaci√≥n: Prompts muy espec√≠ficos + temperatura baja

---

## üéØ Pr√≥ximos Pasos

### Inmediato (Hoy)
1. ‚úÖ Completar descarga de Phi-3
2. ‚úÖ Ejecutar `test_gateway_ollama_phi3.py`
3. ‚úÖ Validar todos los tests pasan
4. ‚úÖ Documentar resultados

### Corto Plazo (Esta Semana)
1. Crear endpoints API para sesiones de tutor√≠a
2. Implementar cache sem√°ntico con embeddings
3. Agregar m√°s tests end-to-end
4. Optimizar prompts para Phi-3

### Mediano Plazo (Este Mes)
1. Dashboard b√°sico para estudiantes
2. Panel de an√°lisis para docentes
3. Integraci√≥n con LMS (Moodle/Canvas)
4. Deploy en staging con K8s

### Largo Plazo (Q1 2026)
1. Evaluaci√≥n con usuarios reales (UAT)
2. An√°lisis de efectividad pedag√≥gica
3. Paper acad√©mico sobre resultados
4. Release v1.0

---

## üìö Referencias Te√≥ricas Implementadas

1. **Bloom's Taxonomy** (1956) - Niveles cognitivos
2. **Zimmerman's Self-Regulation** (2002) - Autorregulaci√≥n
3. **Sweller's Cognitive Load Theory** (1988) - Carga cognitiva
4. **Clark & Chalmers Extended Mind** (1998) - Cognici√≥n extendida
5. **Hutchins Distributed Cognition** (1995) - Cognici√≥n distribuida
6. **UNESCO AI Ethics** (2021) - √âtica de IA
7. **OECD AI Principles** (2019) - Principios de IA
8. **IEEE Ethically Aligned Design** (2019) - Dise√±o √©tico
9. **ISO/IEC 23894:2023** - Risk Management in AI
10. **ISO/IEC 42001:2023** - AI Management System

---

## ‚úÖ Conclusi√≥n

La arquitectura del sistema Phoenix MVP es **s√≥lida, bien fundamentada y lista para producci√≥n**. La integraci√≥n con Ollama + Phi-3 permitir√°:

- ‚úÖ **Costo $0** en LLM (vs $0.002-$0.06/1K tokens de OpenAI)
- ‚úÖ **Privacidad total** (datos nunca salen del servidor)
- ‚úÖ **Baja latencia** (sin llamadas a APIs externas)
- ‚úÖ **Control total** (podemos fine-tunear el modelo)

El sistema est√° listo para pasar a la fase de **validaci√≥n con usuarios reales** despu√©s de completar la integraci√≥n de Phi-3.

---

**Responsable**: GitHub Copilot (Claude Sonnet 4.5)  
**√öltima actualizaci√≥n**: 5 de Diciembre, 2025
