# üß™ Gu√≠a de Testing del Frontend - Sistema Completo

## ‚úÖ Estado de Integraci√≥n

### **COMPLETAMENTE INTEGRADO** - Listo para probar

Todos los m√≥dulos del backend est√°n integrados en el frontend y funcionando:

## üìã Componentes Disponibles

### 1Ô∏è‚É£ **Sesiones** (`/sessions`)
- ‚úÖ Crear nuevas sesiones de aprendizaje
- ‚úÖ Listar sesiones existentes
- ‚úÖ Ver detalles de cada sesi√≥n
- **Endpoint**: `/api/v1/sessions`

### 2Ô∏è‚É£ **Tutor IA (T-IA-Cog)** (`/tutor`)
- ‚úÖ Chat interactivo con el tutor cognitivo
- ‚úÖ Generaci√≥n de trazas cognitivas autom√°ticas
- ‚úÖ Historial de conversaciones
- **Endpoint**: `/api/v1/interactions`

### 3Ô∏è‚É£ **Simuladores Profesionales (S-IA-X)** (`/simulators`)
- ‚úÖ 4 simuladores disponibles:
  - **Product Owner**: Gesti√≥n de backlog y user stories
  - **Scrum Master**: Sprint planning y ceremonias √°giles
  - **Tech Interviewer**: Entrevistas t√©cnicas y SOLID
  - **DevSecOps**: CI/CD y seguridad
- **Endpoint**: `/api/v1/simulators/interact`
- **Timeout**: 60 segundos

### 4Ô∏è‚É£ **An√°lisis de Riesgos (AR-IA)** (`/risks`)
- ‚úÖ **NUEVO**: An√°lisis autom√°tico por sesi√≥n
- ‚úÖ Detecci√≥n de riesgos en 5 dimensiones
- ‚úÖ Recomendaciones y estrategias de mitigaci√≥n
- ‚úÖ Visualizaci√≥n por nivel (CRITICAL, HIGH, MEDIUM, LOW)
- **Endpoints**:
  - `POST /api/v1/risks/analyze-session/{session_id}` ‚≠ê NUEVO
  - `GET /api/v1/events` (lista eventos del simulador)
  - `POST /api/v1/events` (crear eventos)

### 5Ô∏è‚É£ **Evaluaciones (E-IA-Proc)** (`/evaluations`)
- ‚úÖ Generaci√≥n de evaluaci√≥n cognitiva con LLM
- ‚úÖ 5 dimensiones evaluadas:
  - Planning (Planificaci√≥n)
  - Execution (Ejecuci√≥n)
  - Debugging (Depuraci√≥n)
  - Reflection (Reflexi√≥n)
  - Autonomy (Autonom√≠a)
- ‚úÖ Score de metacognici√≥n
- ‚úÖ Ratio de delegaci√≥n a IA
- **Endpoint**: `POST /api/v1/evaluations/{session_id}/generate`
- **Timeout**: 120 segundos (procesamiento LLM)

### 6Ô∏è‚É£ **Trazabilidad (TC-N4)** (`/traceability`)
- ‚úÖ **NUEVO**: Grafo completo de 4 niveles por sesi√≥n
- ‚úÖ Niveles:
  - **Nivel 1**: Eventos de Simulador
  - **Nivel 2**: Trazas Cognitivas
  - **Nivel 3**: Riesgos Detectados
  - **Nivel 4**: Evaluaciones
- ‚úÖ Resumen estad√≠stico
- ‚úÖ Distribuci√≥n de riesgos
- ‚úÖ Promedio de involucramiento de IA
- **Endpoint**: `GET /api/v1/traceability/session/{session_id}` ‚≠ê NUEVO
- **Timeout**: 45 segundos

### 7Ô∏è‚É£ **Git Analytics** (`/analytics`)
- ‚úÖ An√°lisis de commits y contribuciones
- ‚úÖ M√©tricas de calidad de c√≥digo
- **Endpoint**: `/api/v1/git-analytics/{session_id}`

---

## üöÄ C√≥mo Probar el Sistema Completo

### **PASO 1: Verificar que todo est√° corriendo**

```powershell
# Backend (Docker)
docker ps
# Deber√≠as ver: ai-native-api, ai-native-postgres, ai-native-redis, ai-native-ollama

# Verificar salud del backend
curl http://localhost:8000/api/v1/health

# Frontend
# Deber√≠a estar en http://localhost:5173
```

### **PASO 2: Flujo Completo de Testing Manual**

#### 1. **Crear Sesi√≥n** (`/sessions`)
1. Ve a http://localhost:5173/sessions
2. Haz clic en "Nueva Sesi√≥n"
3. Completa:
   - Student ID: `test_student_001`
   - Activity ID: `test_scrum_project`
   - Mode: `TUTOR`
4. **Copia el Session ID generado** (lo necesitar√°s para los siguientes pasos)

#### 2. **Interactuar con Tutor IA** (`/tutor`)
1. Ve a http://localhost:5173/tutor
2. Ingresa el Session ID de arriba
3. Haz 2-3 preguntas de programaci√≥n, por ejemplo:
   - "¬øC√≥mo implemento una cola en Python?"
   - "Expl√≠came la diferencia entre lista y tupla"
   - "¬øQu√© es recursi√≥n?"
4. Ver√°s respuestas del LLM y trazas cognitivas creadas

#### 3. **Probar Simuladores** (`/simulators`)
1. Ve a http://localhost:5173/simulators
2. Crea **sesiones nuevas** para cada simulador (cada uno necesita su propia sesi√≥n):

**Product Owner:**
- Session ID: (nueva sesi√≥n con mode=SIMULATOR, simulator_type=product_owner)
- Pregunta: "Ay√∫dame a crear un backlog para un e-commerce"

**Scrum Master:**
- Session ID: (nueva sesi√≥n)
- Pregunta: "¬øC√≥mo hago un sprint planning para 5 devs?"

**Tech Interviewer:**
- Session ID: (nueva sesi√≥n)
- Pregunta: "Expl√≠came el principio de responsabilidad √∫nica"

**DevSecOps:**
- Session ID: (nueva sesi√≥n)
- Pregunta: "¬øC√≥mo configuro CI/CD con OWASP?"

#### 4. **Crear Eventos Manualmente** (Opcional)
Usa Postman o curl para crear eventos que generen riesgos:

```bash
curl -X POST http://localhost:8000/api/v1/events \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "TU_SESSION_ID",
    "event_type": "deployment_completed",
    "event_data": {
      "environment": "production",
      "tests_executed": false,
      "version": "v1.0.0"
    },
    "description": "Deploy sin tests",
    "severity": "critical"
  }'
```

#### 5. **Analizar Riesgos** (`/risks`) ‚≠ê NUEVO
1. Ve a http://localhost:5173/risks
2. Ingresa el **Session ID de la sesi√≥n ORIGINAL** (del paso 1)
3. Haz clic en "Analizar Riesgos"
4. **Espera 5-10 segundos**
5. Ver√°s:
   - Lista de riesgos detectados autom√°ticamente
   - Nivel de cada riesgo (CRITICAL, HIGH, MEDIUM, LOW)
   - Dimensi√≥n (T√©cnico, Seguridad, Operacional, etc.)
   - Recomendaciones espec√≠ficas
   - Estrategias de mitigaci√≥n

**Eventos que generan riesgos autom√°ticamente:**
- `backlog_created` sin `has_acceptance_criteria` ‚Üí Riesgo HIGH
- `technical_decision_made` sin `justification` ‚Üí Riesgo MEDIUM
- `deployment_completed` sin `tests_executed` ‚Üí Riesgo HIGH
- `security_scan_complete` con `vulnerabilities` ‚Üí Riesgo CRITICAL

#### 6. **Generar Evaluaci√≥n** (`/evaluations`)
1. Ve a http://localhost:5173/evaluations
2. Ingresa el **mismo Session ID** del paso 1
3. Haz clic en "Generar Evaluaci√≥n"
4. **Espera 30-90 segundos** (procesamiento LLM con Ollama)
5. Ver√°s:
   - 5 scores de 0-10 (Planning, Execution, Debugging, Reflection, Autonomy)
   - Nivel de competencia (novice/competent/proficient/expert)
   - Score de metacognici√≥n
   - Ratio de delegaci√≥n a IA
   - Feedback general detallado

#### 7. **Ver Trazabilidad Completa** (`/traceability`) ‚≠ê NUEVO
1. Ve a http://localhost:5173/traceability
2. Ingresa el **mismo Session ID**
3. Haz clic en "Obtener Trazabilidad"
4. Ver√°s:
   - **Resumen**: Total de eventos, trazas, riesgos, evaluaciones
   - **Grafo de 4 niveles**: Eventos ‚Üí Trazas ‚Üí Riesgos ‚Üí Evaluaciones
   - **Artefactos relacionados**: Cada elemento con sus hijos
   - **Distribuci√≥n de riesgos**: Por nivel (CRITICAL, HIGH, etc.)
   - **Promedio de involucramiento de IA**

---

## üéØ Flujo de Testing R√°pido (5 minutos)

Si quieres probar todo r√°pidamente:

```bash
# 1. Verificar backend
curl http://localhost:8000/api/v1/health

# 2. Crear sesi√≥n
curl -X POST http://localhost:8000/api/v1/sessions \
  -H "Content-Type: application/json" \
  -d '{
    "student_id": "quick_test_001",
    "activity_id": "quick_test",
    "mode": "TUTOR"
  }'
# COPIA EL SESSION_ID DE LA RESPUESTA

# 3. Interacci√≥n con tutor
curl -X POST http://localhost:8000/api/v1/interactions \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "SESSION_ID_AQUI",
    "prompt": "¬øC√≥mo implemento una cola en Python?"
  }'

# 4. Crear evento problem√°tico
curl -X POST http://localhost:8000/api/v1/events \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "SESSION_ID_AQUI",
    "event_type": "deployment_completed",
    "event_data": {"tests_executed": false},
    "severity": "critical"
  }'

# 5. Analizar riesgos
curl -X POST http://localhost:8000/api/v1/risks/analyze-session/SESSION_ID_AQUI

# 6. Generar evaluaci√≥n (TARDA 30-90s)
curl -X POST http://localhost:8000/api/v1/evaluations/SESSION_ID_AQUI/generate

# 7. Ver trazabilidad
curl http://localhost:8000/api/v1/traceability/session/SESSION_ID_AQUI
```

---

## üìä Test End-to-End Automatizado

Ya existe un test automatizado que prueba todo el flujo:

```bash
pytest tests/test_e2e_full_workflow.py -v --no-cov
```

**Duraci√≥n**: ~4-5 minutos  
**Pasos**: 7 (sesi√≥n, tutor, simuladores, eventos, riesgos, evaluaci√≥n, trazabilidad)  
**Estado**: ‚úÖ **PASANDO** (validado el 2025-12-09)

---

## üîç Endpoints Nuevos Integrados

| Endpoint | M√©todo | Descripci√≥n | Timeout |
|----------|--------|-------------|---------|
| `/api/v1/events` | POST | Crear evento de simulador | 10s |
| `/api/v1/events` | GET | Listar eventos (filtros: session_id, student_id) | 10s |
| `/api/v1/risks/analyze-session/{id}` | POST | ‚≠ê An√°lisis autom√°tico de riesgos | 60s |
| `/api/v1/traceability/session/{id}` | GET | ‚≠ê Grafo completo de 4 niveles | 45s |
| `/api/v1/evaluations/{id}/generate` | POST | Evaluaci√≥n con LLM (Ollama) | 120s |

---

## ‚öôÔ∏è Configuraci√≥n de Timeouts

Los siguientes timeouts est√°n configurados en `apiClient.ts`:

- **Default**: 30 segundos
- **Simuladores**: 60 segundos
- **An√°lisis de Riesgos**: 60 segundos
- **Trazabilidad**: 45 segundos
- **Evaluaciones**: 120 segundos (procesamiento LLM)

---

## üêõ Troubleshooting

### Error: "Backend no responde"
```bash
docker ps  # Verificar que ai-native-api est√° corriendo
docker logs ai-native-api --tail 50  # Ver logs
docker restart ai-native-api  # Reiniciar
```

### Error: "Timeout en evaluaci√≥n"
- Es normal que tarde 30-90 segundos
- Ollama necesita cargar el modelo la primera vez
- Si persiste, verifica: `docker logs ai-native-ollama`

### Error: "No se detectan riesgos"
- Aseg√∫rate de haber creado **eventos** primero
- Los eventos deben tener condiciones espec√≠ficas (ej: `tests_executed: false`)
- Usa `POST /api/v1/events` para crear eventos manualmente

### Frontend no actualiza
```bash
cd frontEnd
npm run dev  # Reiniciar servidor de desarrollo
```

---

## üìù Notas Importantes

1. **Session ID √∫nico**: Cada simulador necesita su propia sesi√≥n
2. **Eventos generan riesgos**: El AR-IA analiza eventos autom√°ticamente
3. **LLM tarda**: La evaluaci√≥n puede tardar 30-90s la primera vez
4. **Trazabilidad completa**: Conecta eventos ‚Üí trazas ‚Üí riesgos ‚Üí evaluaciones
5. **Limpieza autom√°tica**: El test e2e limpia sesiones al finalizar

---

## ‚úÖ Checklist de Funcionalidades

- [x] Crear sesiones
- [x] Tutor IA con trazas cognitivas
- [x] 4 simuladores profesionales
- [x] Crear eventos de simulador
- [x] An√°lisis autom√°tico de riesgos (AR-IA)
- [x] Evaluaci√≥n con LLM (E-IA-Proc)
- [x] Trazabilidad de 4 niveles (TC-N4)
- [x] Frontend integrado completamente
- [x] Test end-to-end automatizado

---

## üéâ ¬°Todo Listo para Probar!

El sistema est√° **100% integrado** y listo para testing manual. Abre http://localhost:5173 y sigue el flujo de arriba.

**Disfruta probando el sistema completo!** üöÄ
