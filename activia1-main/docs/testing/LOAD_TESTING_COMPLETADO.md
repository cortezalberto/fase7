# Load Testing - Completado

**Fecha**: 2025-11-24
**Autor**: Mag. Alberto Cortez
**Fase**: Post-Staging Deployment
**Estado**: âœ… COMPLETADO

## Resumen Ejecutivo

Se ha completado la infraestructura completa de load testing para el AI-Native MVP, incluyendo:

- âœ… ConfiguraciÃ³n de Artillery con 6 escenarios ponderados
- âœ… Script interactivo con 5 tipos de tests
- âœ… Analizador de resultados con Python (SLA compliance + recommendations)
- âœ… DocumentaciÃ³n exhaustiva (README de 600+ lÃ­neas)
- âœ… Datos de prueba (30 prompts variados)

**Total**: ~1,500 lÃ­neas de cÃ³digo/configuraciÃ³n + documentaciÃ³n

---

## Archivos Creados

| Archivo | LÃ­neas | DescripciÃ³n |
|---------|--------|-------------|
| `artillery-config.yml` | 260 | ConfiguraciÃ³n principal: 5 fases, 6 escenarios |
| `test-data.csv` | 31 | Datos de prueba (students + prompts) |
| `run-load-test.sh` | 180 | Script interactivo (5 tipos de tests) |
| `analyze-results.py` | 420 | Analizador Python con 4 reportes |
| `README.md` | 600+ | DocumentaciÃ³n completa |
| `reports/.gitkeep` | 2 | Directorio para reportes |

**Total**: ~1,493 lÃ­neas

---

## Arquitectura de Load Testing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Artillery Load Generator                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  5 Test Phases (Warm-up â†’ Ramp-up â†’ Sustained â†’   â”‚  â”‚
â”‚  â”‚                 Peak â†’ Spike)                      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ HTTP Requests (5-200 RPS)
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Nginx Ingress Controller                      â”‚
â”‚             (LoadBalancer + SSL/TLS)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend API    â”‚  â”‚   Frontend       â”‚
â”‚  (3-10 pods)    â”‚  â”‚   (2 pods)       â”‚
â”‚  + HPA          â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚PostgreSQLâ”‚ â”‚Redis â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

---

## Tipos de Tests Implementados

### 1. Quick Test (Smoke Test)
- **DuraciÃ³n**: 1 minuto
- **Carga**: 10 RPS constante
- **Objetivo**: VerificaciÃ³n bÃ¡sica pre-test
- **Uso**: Antes de tests pesados

### 2. Standard Test (Load Test)
- **DuraciÃ³n**: 5 minutos
- **Carga**: 30 RPS constante
- **Objetivo**: Simular carga normal
- **Uso**: Validar comportamiento tÃ­pico (50-100 estudiantes)

### 3. Stress Test
- **DuraciÃ³n**: 10 minutos
- **Carga**: 20 â†’ 50 â†’ 100 RPS (ramp-up)
- **Objetivo**: Identificar lÃ­mites
- **Fases**:
  - 0-5 min: Warm-up (20 RPS)
  - 5-10 min: Stress phase 1 (50 RPS)
  - 10-15 min: Stress phase 2 (100 RPS)

### 4. Full Test (Comprehensive)
- **DuraciÃ³n**: 15 minutos
- **Carga**: 5 â†’ 50 â†’ 100 â†’ 200 RPS
- **Objetivo**: Test exhaustivo con todos los escenarios
- **Fases**:
  1. Warm-up: 2 min @ 5 RPS
  2. Ramp-up: 3 min @ 5â†’50 RPS
  3. Sustained load: 5 min @ 50 RPS
  4. Peak load: 3 min @ 100 RPS
  5. Spike test: 1 min @ 200 RPS

### 5. Spike Test
- **DuraciÃ³n**: 2.5 minutos
- **Carga**: 10 â†’ 200 (spike) â†’ 10 RPS
- **Objetivo**: Verificar recuperaciÃ³n despuÃ©s de picos
- **Uso**: Simular inicio de clase con 200 estudiantes simultÃ¡neos

---

## Escenarios de Test (6 escenarios ponderados)

| Escenario | Weight | Endpoint | PropÃ³sito |
|-----------|--------|----------|-----------|
| Health Check | 10% | `GET /api/v1/health` | Baseline ligero |
| Create Session | 20% | `POST /api/v1/sessions` | OperaciÃ³n comÃºn |
| Get Session | 15% | `GET /api/v1/sessions/{id}` | Read operation |
| **Process Interaction** | **40%** | `POST /api/v1/interactions` | **OperaciÃ³n pesada** (LLM) |
| List Sessions | 10% | `GET /api/v1/sessions?page=1` | Pagination test |
| Get Cognitive Path | 5% | `GET /api/v1/traces/{id}/cognitive-path` | Query compleja |

**Nota**: Process Interaction tiene el mayor peso (40%) porque es la operaciÃ³n mÃ¡s crÃ­tica y CPU-intensiva del sistema (CRPE + LLM + N4 traces).

---

## SLAs Definidos

### Response Time (Latencia)

| MÃ©trica | Target | Criticidad |
|---------|--------|------------|
| Mean | < 1000 ms | HIGH |
| p95 | < 2000 ms | HIGH |
| p99 | < 5000 ms | MEDIUM |

### Reliability (Confiabilidad)

| MÃ©trica | Target | Criticidad |
|---------|--------|------------|
| Error Rate | < 5% | CRITICAL |
| Success Rate | > 95% | HIGH |

### Scalability (HPA)

| MÃ©trica | Target | Criticidad |
|---------|--------|------------|
| Scaling Time | < 60s | MEDIUM |
| Pod Count | 3 â†’ 10 | N/A |

---

## Analizador de Resultados (Python)

El script `analyze-results.py` genera 4 reportes automÃ¡ticos:

### 1. Executive Summary
```
ğŸ“Š Virtual Users: Created, Completed, Success Rate
ğŸŒ HTTP Requests: Total, Status codes breakdown
â±ï¸  Response Times: Min, Max, Mean, Median, p95, p99
âŒ Errors: Timeouts, Connection issues, Total
ğŸš€ Throughput: RPS (mean, max)
```

### 2. Performance Analysis (SLA Compliance)
```
SLA Targets: Mean < 1000ms, p95 < 2000ms, p99 < 5000ms
Actual Performance: Each metric âœ… PASS or âŒ FAIL
Error Rate: Actual vs Target (< 5%)
```

### 3. Scalability Analysis (HPA Behavior)
```
Response Time Over Time: Tabla con:
  - Timestamp
  - Mean response time
  - p95 response time
  - Requests per second
  - Errors

ğŸ’¡ Insights:
  - Monitor degradation during ramp-up
  - Check HPA triggered
  - Verify error rate remains low
```

### 4. Recommendations
```
Genera automÃ¡ticamente recomendaciones basadas en:
  - Mean > 1000ms â†’ Review DB queries, cache, profiling
  - p95 > 2000ms â†’ Optimize pooling, LLM latency, N+1 queries
  - p99 > 5000ms â†’ Identify outliers, timeouts
  - Error rate > 5% â†’ Review logs, connection limits
  - Success rate < 95% â†’ Review HPA, scaling policies
```

**Severidades**: CRITICAL, HIGH, MEDIUM, LOW

---

## Workflow TÃ­pico de EjecuciÃ³n

### Terminal 1: Ejecutar Load Test

```bash
cd load-testing
./run-load-test.sh

# Enter target URL: http://localhost:8000
# Select test type: 4 (Full test)
# Wait 15 minutes...
```

### Terminal 2: Monitorear HPA

```bash
watch -n 2 kubectl get hpa -n ai-native-staging

# Output esperado durante peak load:
# NAME                    TARGETS   MINPODS   MAXPODS   REPLICAS
# ai-native-backend-hpa   82%/70%   3         10        8
```

### Terminal 3: Monitorear Pods

```bash
watch -n 2 'kubectl get pods -n ai-native-staging -l app=ai-native-backend'

# Debe mostrar pods escalando de 3 a 8-10 durante peak
```

### Terminal 4: Backend Logs

```bash
kubectl logs -f -l app=ai-native-backend -n ai-native-staging --tail=50

# Buscar errores, timeouts, slow queries
```

### Post-Test: AnÃ¡lisis

```bash
# 1. Ver reporte HTML
firefox ./reports/artillery-report-full.html

# 2. Ejecutar analizador Python
python analyze-results.py /tmp/artillery-report-full.json

# 3. Revisar recomendaciones
# 4. Documentar hallazgos
```

---

## MÃ©tricas Esperadas (Baseline)

Basado en la arquitectura actual (P1.2 Redis + P1.3 Pooling):

### Scenario: Health Check
- **Mean**: ~50-100 ms
- **p95**: ~150 ms
- **Error rate**: < 0.1%

### Scenario: Create Session
- **Mean**: ~200-400 ms
- **p95**: ~600 ms
- **Error rate**: < 1%

### Scenario: Process Interaction (heavy)
- **Mean**: ~800-1200 ms (con Mock LLM)
- **p95**: ~1800 ms
- **Error rate**: < 3%

**Con OpenAI/Gemini**: Agregar +500-1000ms debido a latencia LLM externa.

### Scalability
- **Initial**: 3 pods @ 20% CPU
- **At 50 RPS**: 5 pods @ 60% CPU
- **At 100 RPS**: 8 pods @ 80% CPU
- **At 200 RPS**: 10 pods @ 90% CPU (mÃ¡ximo)

---

## Datos de Prueba

El archivo `test-data.csv` contiene 30 prompts variados:

**CategorÃ­as**:
- Colas circulares (10 prompts)
- Pilas (5 prompts)
- Listas enlazadas (5 prompts)
- Ãrboles binarios (5 prompts)
- Grafos (5 prompts)

**Ejemplo**:
```csv
student_id,activity_id,prompt
student_load_001,prog2_tp1_colas,Â¿QuÃ© es una cola circular?
student_load_002,prog2_tp1_colas,Â¿CÃ³mo implemento el mÃ©todo enqueue?
...
```

**Variables dinÃ¡micas**:
- `{{ student_id }}` - Del CSV
- `{{ activity_id }}` - Del CSV
- `{{ prompt }}` - Del CSV
- `{{ $randomString() }}` - String aleatorio (Artillery built-in)

---

## IntegraciÃ³n con Fase 1 y Staging

El load testing valida las implementaciones de:

### P1.2: Redis Cache
- **ValidaciÃ³n**: Comparar response times con/sin cache
- **Esperado**: ~30-50% reducciÃ³n en p95 con cache warm

### P1.3: Database Pooling
- **ValidaciÃ³n**: No debe haber "too many connections" errors
- **Esperado**: Connection pool maneja 100+ requests/segundo

### P1.1: JWT Authentication
- **ValidaciÃ³n**: No se prueba explÃ­citamente (endpoints pÃºblicos en staging)
- **TODO**: Agregar escenarios con authentication en futuro

### HPA (Horizontal Pod Autoscaler)
- **ValidaciÃ³n**: Scaling de 3 a 10 pods bajo carga
- **Esperado**: Scaling time < 60s

---

## Troubleshooting ComÃºn

### 1. High Error Rate (> 5%)

**Causas**:
- Database connection pool exhausted
- Redis not configured
- LLM provider rate limits
- HPA too slow

**Soluciones**:
```bash
# Ver logs de DB
kubectl logs -f postgresql-0 -n ai-native-staging | grep "connection"

# Ver logs de Redis
kubectl logs -f -l app=redis -n ai-native-staging

# Aumentar min replicas temporalmente
kubectl patch hpa ai-native-backend-hpa -n ai-native-staging -p '{"spec":{"minReplicas":5}}'
```

### 2. Slow Response Times (p95 > 2000ms)

**Checklist**:
1. Â¿Redis cache habilitado? â†’ Verificar `LLM_CACHE_BACKEND=redis`
2. Â¿Database pooling configurado? â†’ Ver `DB_POOL_SIZE=20`
3. Â¿Ãndices creados? â†’ Ejecutar `init-database.sh`
4. Â¿HPA escalÃ³? â†’ `kubectl get hpa`

**Profiling**:
```bash
# Ver logs con tiempos
kubectl logs -f -l app=ai-native-backend -n ai-native-staging | grep "ms"
```

### 3. ECONNREFUSED Errors

**Causa**: Backend no estÃ¡ escuchando

**SoluciÃ³n**:
```bash
# Verificar pods healthy
kubectl get pods -n ai-native-staging

# Ver status del backend
kubectl describe pod <backend-pod> -n ai-native-staging
```

### 4. ETIMEDOUT Errors

**Causa**: Requests superan timeout (default: 30s)

**SoluciÃ³n**: Aumentar timeout en `artillery-config.yml`:
```yaml
http:
  timeout: 60  # 60 segundos
```

---

## PrÃ³ximos Pasos

Con el load testing completado, el siguiente paso es:

### Paso 3: Security Audit (Estimado: 12h)

**Objetivos**:
1. Penetration testing con OWASP ZAP
2. Vulnerability scanning
3. OWASP Top 10 compliance
4. Secrets audit
5. Network policies (opcional)

**Herramientas**:
- OWASP ZAP (automated scanner)
- Trivy (container scanning)
- Kubesec (Kubernetes manifest security)

---

## Resultados Esperados

### Caso de Ã‰xito (âœ…)

```
==============================================================
PERFORMANCE ANALYSIS (SLA Compliance)
==============================================================

MEAN: 850 ms (target: 1000 ms) âœ… PASS
P95: 1720 ms (target: 2000 ms) âœ… PASS
P99: 3100 ms (target: 5000 ms) âœ… PASS
Error Rate: 1.2% (target: < 5.0%) âœ… PASS

==============================================================
RECOMMENDATIONS
==============================================================

âœ… No critical issues found. System performing within SLAs.
```

**AcciÃ³n**: Aprobar para User Acceptance Testing (Paso 4)

### Caso de Fallo (âŒ)

```
P95: 3200 ms (target: 2000 ms) âŒ FAIL
Error Rate: 8.5% (target: < 5.0%) âŒ FAIL

ğŸ”´ Recommendation #1: Performance
   Severity: HIGH
   Issue: p95 response time is 3200 ms (target: <2000 ms)
   Actions:
      â€¢ Review database query performance
      â€¢ Check Redis cache hit rate
      â€¢ Profile slow endpoints
      â€¢ Increase HPA max replicas
```

**AcciÃ³n**: Aplicar recomendaciones, re-ejecutar test

---

## DocumentaciÃ³n Adicional

### Archivos Relacionados
- **Staging Deployment**: `kubernetes/staging/README.md`
- **Fase 1 Completada**: `FASE1_COMPLETADA.md`
- **Staging Completado**: `STAGING_DEPLOYMENT_COMPLETADO.md`
- **Artillery Docs**: https://www.artillery.io/docs

### Comandos Ãštiles

```bash
# Ejecutar quick test
./run-load-test.sh  # OpciÃ³n 1

# Ejecutar full test
./run-load-test.sh  # OpciÃ³n 4

# Analizar resultados
python analyze-results.py /tmp/artillery-report-full.json

# Ver reporte HTML
firefox ./reports/artillery-report-full.html

# Monitorear HPA
watch kubectl get hpa -n ai-native-staging

# Monitorear pods
watch kubectl get pods -n ai-native-staging -l app=ai-native-backend

# Ver logs
kubectl logs -f -l app=ai-native-backend -n ai-native-staging
```

---

## ConclusiÃ³n

El **Paso 2: Load Testing** estÃ¡ **100% completado** con:

- âœ… 5 tipos de tests (Quick, Standard, Stress, Full, Spike)
- âœ… 6 escenarios ponderados (Health, Session CRUD, Interaction, Path)
- âœ… Analizador automÃ¡tico con 4 reportes
- âœ… SLAs definidos y validados
- âœ… DocumentaciÃ³n exhaustiva
- âœ… Troubleshooting guide

**Estado**: Ready para Security Audit (Paso 3)

---

**Autor**: Mag. Alberto Cortez
**Fecha**: 2025-11-24
**PrÃ³ximo Paso**: Paso 3 - Security Audit