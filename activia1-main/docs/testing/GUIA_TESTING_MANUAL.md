# Gu√≠a de Testing Integral - Sprint 1 y Sprint 2

**Proyecto**: Ecosistema AI-Native para Ense√±anza-Aprendizaje de Programaci√≥n
**Fecha**: 2025-11-20
**Autor**: Mag. Alberto Cortez
**Versi√≥n**: 1.0

---

## Resumen Ejecutivo

Este documento describe el plan y ejecuci√≥n de testing integral para validar las funcionalidades implementadas en Sprint 1 (MVP Core) y Sprint 2 (Evaluaci√≥n + API).

### Objetivos del Testing

‚úÖ Validar todas las historias de usuario de Sprint 1 (6 HUs - 55 SP)
‚úÖ Validar todas las historias de usuario de Sprint 2 (9 HUs - 120 SP)
‚úÖ Asegurar cobertura de c√≥digo ‚â•70% (requisito en pytest.ini)
‚úÖ Validar flujos end-to-end completos de estudiante, docente y administrador
‚úÖ Garantizar cumplimiento de TODOS los criterios de aceptaci√≥n

### Alcance Total

| Sprint | Historias | Story Points | Tests Planeados |
|--------|-----------|--------------|-----------------|
| Sprint 1 | 6 HUs | 55 SP | ~90 tests |
| Sprint 2 | 9 HUs | 120 SP | ~145 tests |
| **TOTAL** | **15 HUs** | **175 SP** | **~235 tests** |

---

## Manual de Ejecuci√≥n de Tests

### Prerequisitos

```bash
# 1. Activar entorno virtual
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Unix/macOS

# 2. Instalar dependencias de testing
pip install -r requirements.txt
# Incluye: pytest, pytest-cov, pytest-mock, httpx (para tests API)

# 3. Inicializar base de datos de testing
python scripts/init_database.py --database-url "sqlite:///test_ai_native.db"
```

### Comandos de Ejecuci√≥n

#### 1. Ejecutar TODOS los tests con coverage

```bash
pytest tests/ -v --cov=src/ai_native_mvp --cov-report=html --cov-report=term
```

**Salida esperada**:
- N√∫mero total de tests ejecutados
- Cobertura ‚â•70% (pytest.ini)
- Reporte HTML en `htmlcov/index.html`

#### 2. Tests de Sprint 1 solamente

```bash
pytest tests/test_sprint1_*.py -v
```

**Tests incluidos**:
- `test_sprint1_sessions.py` (HU-EST-001)
- `test_sprint1_tutor.py` (HU-EST-002)
- `test_sprint1_governance.py` (HU-EST-003)
- `test_sprint1_crpe.py` (HU-SYS-001)
- `test_sprint1_governance_agent.py` (HU-SYS-002)
- `test_sprint1_traceability.py` (HU-SYS-003)

#### 3. Tests de Sprint 2 solamente

```bash
pytest tests/test_sprint2_*.py -v
```

**Tests incluidos**:
- `test_sprint2_adaptive_hints.py` (HU-EST-004)
- `test_sprint2_justifications.py` (HU-EST-005)
- `test_sprint2_formative_feedback.py` (HU-EST-007)
- `test_sprint2_evaluator.py` (HU-SYS-004)
- `test_sprint2_risk_analyst.py` (HU-SYS-005)
- `test_sprint2_api_endpoints.py` (HU-SYS-007)
- `test_sprint2_activities.py` (HU-DOC-001)

#### 4. Tests de Integraci√≥n y E2E

```bash
pytest tests/test_integration_e2e.py -v
```

**Escenarios validados**:
- Sesi√≥n exitosa completa
- Sesi√≥n con delegaci√≥n bloqueada
- Sesi√≥n con m√∫ltiples riesgos
- Workflow docente completo
- API end-to-end completo

#### 5. Tests de API espec√≠ficamente

```bash
pytest tests/test_api_endpoints.py tests/test_sprint2_api_endpoints.py -v
```

**Endpoints testeados**: 15+ endpoints REST

#### 6. Tests por marcadores (pytest markers)

```bash
pytest -m "sprint1" -v      # Solo Sprint 1
pytest -m "sprint2" -v      # Solo Sprint 2
pytest -m "integration" -v  # Solo integraci√≥n
pytest -m "api" -v          # Solo API
pytest -m "unit" -v         # Solo unitarios
```

#### 7. Tests de Performance

```bash
pytest tests/test_performance.py -v
```

**M√©tricas validadas**:
- Procesamiento de interacci√≥n <2 segundos
- CRPE clasifica en <500ms
- Queries optimizadas (no N+1)
- API responde <2 segundos

---

## Sprint 1 - Tests Implementados

### HU-EST-001: Iniciar Sesi√≥n (8 tests)

**Archivo**: `tests/test_sprint1_sessions.py`

```python
def test_create_session_success()
def test_create_session_generates_unique_id()
def test_create_session_sets_active_status()
def test_create_session_validates_mode()
def test_create_session_persists_to_database()
def test_api_create_session_endpoint()
def test_api_create_session_invalid_mode()
def test_api_get_session_by_id()
```

**Criterios validados**:
- ‚úÖ Sistema permite crear sesi√≥n con student_id, activity_id, mode
- ‚úÖ Sistema genera session_id √∫nico
- ‚úÖ Sesi√≥n se registra en DB con timestamp
- ‚úÖ Sistema confirma creaci√≥n
- ‚úÖ Usuario ve qu√© agente AI est√° activo

---

### HU-EST-002: Consultar Conceptos (10 tests)

**Archivo**: `tests/test_sprint1_tutor.py`

```python
def test_conceptual_query_returns_explanation()
def test_conceptual_query_no_complete_code()
def test_conceptual_query_includes_socratic_questions()
def test_conceptual_query_classified_correctly()
def test_conceptual_query_n4_trace_captured()
def test_conceptual_query_cognitive_state_exploration()
def test_conceptual_query_low_ai_involvement()
def test_conceptual_query_not_blocked()
def test_complete_conceptual_interaction_flow()
def test_multiple_conceptual_queries_sequence()
```

**Criterios validados**:
- ‚úÖ Tutor responde con explicaci√≥n conceptual, analog√≠as, preguntas
- ‚úÖ Tutor NO entrega c√≥digo completo
- ‚úÖ Solicitud clasificada correctamente por CRPE
- ‚úÖ Traza N4 captura estado EXPLORACION_CONCEPTUAL
- ‚úÖ AI involvement bajo (0.2-0.3)
- ‚úÖ Sistema no bloquea consulta conceptual

---

### HU-EST-003: Bloqueo Delegaci√≥n (13 tests)

**Archivo**: `tests/test_sprint1_governance.py`

```python
def test_delegation_detection_explicit()
def test_delegation_detection_variants()
def test_delegation_blocks_before_generation()
def test_delegation_returns_pedagogical_message()
def test_delegation_n4_trace_blocked_true()
def test_delegation_governance_action_logged()
def test_delegation_risk_detected()
def test_delegation_offers_decomposition_guide()
def test_delegation_counts_for_risk_analysis()
def test_configurable_delegation_patterns()
def test_delegation_full_workflow()
def test_multiple_delegation_attempts()
def test_delegation_after_valid_interactions()
```

**Criterios validados**:
- ‚úÖ Sistema bloquea delegaci√≥n total
- ‚úÖ Mensaje pedag√≥gico explica POR QU√â
- ‚úÖ Gu√≠a a descomponer problema
- ‚úÖ Bloqueo ANTES de generar c√≥digo
- ‚úÖ Traza N4 con blocked=true
- ‚úÖ Riesgo COGNITIVE_DELEGATION registrado
- ‚úÖ Interacci√≥n cuenta para an√°lisis de riesgos

---

### HU-SYS-001: CRPE (20 tests)

**Archivo**: `tests/test_sprint1_crpe.py`

Tests de clasificaci√≥n cognitiva:
- Clasifica consulta conceptual
- Clasifica delegaci√≥n total
- Clasifica implementaci√≥n
- Clasifica debugging
- Clasifica validaci√≥n

Tests de estados cognitivos:
- Detecta EXPLORACION_CONCEPTUAL
- Detecta PLANIFICACION
- Detecta IMPLEMENTACION
- Detecta VALIDACION

Tests de estrategia pedag√≥gica:
- Calcula delegation_level
- Considera historial estudiante
- Retorna estrategia estructurada
- Determina help_level
- Requiere justificaci√≥n flag
- Performance <500ms

**Criterios validados**:
- ‚úÖ Clasificaci√≥n de tipo de solicitud
- ‚úÖ Determinaci√≥n de estado cognitivo
- ‚úÖ C√°lculo de nivel de delegaci√≥n
- ‚úÖ Consideraci√≥n de historial
- ‚úÖ Retorno de estrategia pedag√≥gica
- ‚úÖ Performance <500ms
- ‚úÖ Tests cubren todos los tipos

---

### HU-SYS-002: GOV-IA (15 tests)

**Archivo**: `tests/test_sprint1_governance_agent.py`

Tests de pol√≠ticas:
- Carga pol√≠ticas globales
- Carga pol√≠ticas de actividad
- Verifica max_help_level
- Bloquea soluciones completas si policy
- Enforcea umbrales de riesgo

Tests de bloqueo:
- Bloquea ANTES de ejecuci√≥n
- Retorna mensaje pedag√≥gico
- Registra evento de gobernanza
- Permite solicitudes v√°lidas

Tests de integraci√≥n:
- GOV-IA + CRPE integraci√≥n
- Jerarqu√≠a de pol√≠ticas
- Consistencia en m√∫ltiples sesiones

**Criterios validados**:
- ‚úÖ Carga pol√≠ticas global + actividad
- ‚úÖ Verifica max_help_level, block_complete_solutions, umbrales
- ‚úÖ Bloquea ANTES si viola pol√≠tica
- ‚úÖ Retorna mensaje pedag√≥gico
- ‚úÖ Registra evento de gobernanza
- ‚úÖ Tests para cada tipo de pol√≠tica

---

### HU-SYS-003: TC-N4 (20 tests)

**Archivo**: `tests/test_sprint1_traceability.py`

Tests de trazas N4:
- Creaci√≥n con todos campos N4
- Incluye session_id
- trace_level = N4_COGNITIVO
- interaction_type apropiado
- cognitive_state capturado
- cognitive_intent capturado
- content capturado completo
- ai_involvement calculado
- metadata incluida
- Persiste en DB
- Trazas inmutables
- Timestamps precisos
- Ordenamiento correcto

Tests de secuencias:
- TraceSequence creaci√≥n
- Representa camino cognitivo
- Reconstrucci√≥n completa
- M√∫ltiples estados cognitivos
- Correlaci√≥n con riesgos
- Query de camino cognitivo

**Criterios validados**:
- ‚úÖ Cada interacci√≥n genera CognitiveTrace con N4
- ‚úÖ Incluye session_id, trace_level=N4_COGNITIVO
- ‚úÖ interaction_type, cognitive_state, cognitive_intent capturados
- ‚úÖ content, ai_involvement, metadata incluidos
- ‚úÖ Persiste en CognitiveTraceDB
- ‚úÖ Forma TraceSequence
- ‚úÖ Trazas inmutables

---

## Sprint 2 - Tests a Implementar

### HU-EST-004: Pistas Graduadas (15 tests)

**Archivo**: `tests/test_sprint2_adaptive_hints.py`

Tests de niveles de pistas:
- Nivel MINIMO: pregunta socr√°tica
- Nivel BAJO: pregunta + orientaci√≥n
- Nivel MEDIO: pista conceptual + ejemplo
- Nivel ALTO: fragmento + pseudoc√≥digo

Tests de adaptaci√≥n:
- Reduce nivel despu√©s de >5 pistas
- Reduce nivel si AI dependency >60%
- Considera historial estudiante
- AI involvement incrementa (0.3‚Üí0.5‚Üí0.7)

Tests de pistas:
- Enfocada en parte espec√≠fica
- Traza N4 captura nivel
- Nunca da soluci√≥n completa
- Escalado progresivo BAJO‚ÜíMEDIO‚ÜíALTO

Tests de integraci√≥n:
- Escalado completo workflow
- Adaptaci√≥n basada en performance
- Correlaci√≥n con evaluaci√≥n

**Criterios esperados**:
- ‚úÖ Pistas en 4 niveles
- ‚úÖ Ajuste seg√∫n historial
- ‚úÖ AI involvement incrementa
- ‚úÖ Enfocada en parte espec√≠fica
- ‚úÖ Traza N4 captura nivel
- ‚úÖ Nunca soluci√≥n completa

---

### HU-EST-005: Justificaci√≥n Decisiones (12 tests)

**Archivo**: `tests/test_sprint2_justifications.py`

Tests de captura:
- Captura decisi√≥n con justificaci√≥n
- Traza N4 con cognitive_intent=JUSTIFICATION
- Incluye alternativas consideradas
- Incluye razonamiento expl√≠cito

Tests de detecci√≥n:
- Detecta decisiones sin justificaci√≥n
- Calcula ratio justificadas/no justificadas
- Alerta LOW (50-70%)
- Alerta MEDIUM (30-50%)
- Alerta HIGH (<30%)
- Justificaciones alimentan evaluaci√≥n

Tests de integraci√≥n:
- Workflow completo: decisi√≥n‚Üícaptura‚Üían√°lisis‚Üíalerta
- Decisiones mixtas (justificadas + no justificadas)

**Criterios esperados**:
- ‚úÖ Tutor pregunta "¬øPor qu√© elegiste X?"
- ‚úÖ Justificaci√≥n en traza N4 con cognitive_intent=JUSTIFICATION
- ‚úÖ Alternativas capturadas
- ‚úÖ Detecta falta de justificaci√≥n
- ‚úÖ Riesgo LACK_JUSTIFICATION emitido
- ‚úÖ Alimenta E-IA-Proc

---

### HU-EST-007: Feedback Formativo (12 tests)

**Archivo**: `tests/test_sprint2_formative_feedback.py`

Tests de generaci√≥n:
- Genera feedback al cerrar sesi√≥n
- Incluye nivel de competencia
- Incluye puntajes por dimensi√≥n
- Incluye fortalezas identificadas
- Incluye √°reas de mejora
- Incluye recomendaciones accionables

Tests de versiones:
- Versi√≥n student-friendly
- Versi√≥n t√©cnica para docentes
- Enfoque formativo (no punitivo)
- Persiste y es accesible

Tests de integraci√≥n:
- Sesi√≥n completa ‚Üí evaluaci√≥n ‚Üí feedback
- Evoluci√≥n entre sesiones

**Criterios esperados**:
- ‚úÖ E-IA-Proc genera reporte con competencia y score
- ‚úÖ Dimensiones evaluadas
- ‚úÖ Fortalezas y mejoras identificadas
- ‚úÖ Formativo, no punitivo
- ‚úÖ Recomendaciones accionables
- ‚úÖ Almacenado y accesible

---

### HU-SYS-004: E-IA-Proc (18 tests)

**Archivo**: `tests/test_sprint2_evaluator.py`

Tests de an√°lisis:
- Analiza secuencia de trazas N4
- Coherencia del camino cognitivo
- Calidad de justificaciones
- Nivel de autorregulaci√≥n
- Manejo de errores
- Dependencia de IA

Tests de reporte:
- Genera EvaluationReport completo
- overall_competency_level
- overall_score (0-10)
- Dimensiones con puntajes
- key_strengths
- improvement_areas
- Formativo (no punitivo)
- Se dispara al cerrar sesi√≥n
- Persiste en EvaluationDB

Tests de integraci√≥n:
- Workflow completo: sesi√≥n‚Üítrazas‚Üían√°lisis‚Üíreporte‚Üípersistencia
- M√∫ltiples estados cognitivos
- Correlaci√≥n con riesgos

**Criterios esperados**:
- ‚úÖ Analiza coherencia, justificaciones, autorregulaci√≥n, errores, AI dependency
- ‚úÖ Genera EvaluationReport completo
- ‚úÖ Dimensiones evaluadas
- ‚úÖ Fortalezas y mejoras
- ‚úÖ Formativo
- ‚úÖ Autom√°tico al cerrar sesi√≥n
- ‚úÖ Persiste en DB

---

### HU-SYS-005: AR-IA (24 tests)

**Archivo**: `tests/test_sprint2_risk_analyst.py`

Tests de detecci√≥n (5 dimensiones):
- Detecta COGNITIVE_DELEGATION
- Detecta AI_DEPENDENCY (>70%)
- Detecta LACK_JUSTIFICATION
- Detecta UNCRITICAL_ACCEPTANCE (epist√©mico)
- Corre en paralelo (no bloquea)

Tests de niveles:
- CRITICAL
- HIGH
- MEDIUM
- LOW

Tests de dimensiones:
- COGNITIVE
- ETHICAL
- EPISTEMIC
- TECHNICAL
- GOVERNANCE

Tests de objeto Risk:
- Genera Risk completo
- Incluye evidencia
- Incluye recomendaciones
- Persiste en RiskDB
- Riesgo cr√≠tico dispara alerta

Tests de integraci√≥n:
- Detecci√≥n a lo largo de sesi√≥n
- M√∫ltiples riesgos misma dimensi√≥n
- Correlaci√≥n con gobernanza
- Generaci√≥n de RiskReport

**Criterios esperados**:
- ‚úÖ An√°lisis en paralelo
- ‚úÖ Genera Risk cuando detecta patr√≥n
- ‚úÖ 5 dimensiones cubiertas
- ‚úÖ Risk completo con todos los campos
- ‚úÖ Persiste en RiskDB
- ‚úÖ Cr√≠ticos disparan alertas
- ‚úÖ Tests para cada tipo

---

### HU-SYS-007: API REST (35+ tests)

**Archivo**: `tests/test_sprint2_api_endpoints.py`

Tests de Sessions (5):
- POST /api/v1/sessions
- GET /api/v1/sessions
- GET /api/v1/sessions/{id}
- PUT /api/v1/sessions/{id}
- POST /api/v1/sessions/{id}/end

Tests de Interactions (3):
- POST /api/v1/interactions (principal)
- Invalid session ‚Üí 404
- Governance block ‚Üí 403

Tests de Traces (3):
- GET /api/v1/traces/{session_id}
- GET /api/v1/traces/{session_id}/cognitive-path
- GET /api/v1/traces con filtros

Tests de Risks (3):
- GET /api/v1/risks/session/{session_id}
- GET /api/v1/risks?level=CRITICAL
- GET /api/v1/risks?resolved=false

Tests de Evaluation (1):
- GET /api/v1/evaluation/session/{session_id}

Tests de Activities (7):
- POST /api/v1/activities
- GET /api/v1/activities
- GET /api/v1/activities/{id}
- PUT /api/v1/activities/{id}
- POST /api/v1/activities/{id}/publish
- POST /api/v1/activities/{id}/archive
- DELETE /api/v1/activities/{id}

Tests de OpenAPI (2):
- GET /openapi.json
- GET /docs (Swagger UI)

Tests de Performance (5):
- POST /api/v1/interactions <2s
- List sessions paginaci√≥n eficiente
- 10 requests concurrentes
- Rate limiting funciona
- Percentiles (P50, P95, P99)

Tests de Seguridad (5):
- No secretos hardcodeados
- Input validation
- SQL injection prevention
- CORS configurado
- Error messages no exponen internals

**Criterios esperados**:
- ‚úÖ 15+ endpoints implementados
- ‚úÖ OpenAPI/Swagger auto-generado
- ‚úÖ Rate limiting y CORS
- ‚úÖ Logs estructurados
- ‚úÖ Tests integraci√≥n todos los endpoints
- ‚úÖ Performance <2s
- ‚úÖ Input validation
- ‚úÖ SQL injection prevenida

---

## Tests de Integraci√≥n E2E

**Archivo**: `tests/test_integration_e2e.py`

### Escenario 1: Sesi√≥n Exitosa Completa (20+ assertions)

```python
def test_complete_successful_session():
    # 1. Crear sesi√≥n
    # 2. Consulta conceptual (no bloqueada)
    # 3. Solicitar pista graduada
    # 4. Justificar decisi√≥n de dise√±o
    # 5. Cerrar sesi√≥n
    # 6. Recibir evaluaci√≥n formativa
    # 7. Validar trazas N4
    # 8. Validar riesgos (ninguno o bajo)
```

### Escenario 2: Sesi√≥n con Delegaci√≥n (15+ assertions)

```python
def test_session_with_delegation_blocked():
    # 1. Crear sesi√≥n
    # 2. Intentar delegaci√≥n ‚Üí bloqueado
    # 3. Recibir mensaje pedag√≥gico
    # 4. Reformular con consulta ‚Üí permitido
    # 5. Cerrar sesi√≥n
    # 6. Validar riesgo COGNITIVE_DELEGATION
    # 7. Validar traza blocked=true
```

### Escenario 3: M√∫ltiples Riesgos (20+ assertions)

```python
def test_session_with_multiple_risks():
    # 1. Crear sesi√≥n
    # 2. Delegaci√≥n ‚Üí riesgo cognitivo
    # 3. Sin justificar ‚Üí riesgo falta justificaci√≥n
    # 4. Aceptaci√≥n acr√≠tica ‚Üí riesgo epist√©mico
    # 5. Cerrar sesi√≥n
    # 6. Validar 3+ riesgos
    # 7. Validar evaluaci√≥n refleja riesgos
    # 8. Validar recomendaciones en feedback
```

### Escenario 4: Workflow Docente (25+ assertions)

```python
def test_teacher_workflow_complete():
    # 1. Docente crea actividad con pol√≠ticas
    # 2. Publica actividad
    # 3. Estudiante crea sesi√≥n en actividad
    # 4. Pol√≠ticas se aplican
    # 5. Estudiante completa sesi√≥n
    # 6. Docente visualiza trazas N4
    # 7. Docente accede evaluaci√≥n
    # 8. Docente revisa riesgos
    # 9. Docente ajusta calificaci√≥n
```

### Escenario 5: API End-to-End (30+ assertions)

```python
def test_api_end_to_end_workflow():
    # Flujo completo v√≠a API
    # 1-8: Todos los endpoints principales
    # 9: Validar respuestas completas
```

---

## Checklist de Validaci√≥n

### Sprint 1 - Completado ‚úÖ

- [x] HU-EST-001: Iniciar sesi√≥n (8 tests)
- [x] HU-EST-002: Consultar conceptos (10 tests)
- [x] HU-EST-003: Bloqueo delegaci√≥n (13 tests)
- [x] HU-SYS-001: CRPE (20 tests)
- [x] HU-SYS-002: GOV-IA (15 tests)
- [x] HU-SYS-003: TC-N4 (20 tests)

**Total Sprint 1**: 86 tests implementados

### Sprint 2 - A Implementar üîÑ

- [ ] HU-EST-004: Pistas graduadas (15 tests)
- [ ] HU-EST-005: Justificaciones (12 tests)
- [ ] HU-EST-007: Feedback formativo (12 tests)
- [ ] HU-DOC-001: Actividades (7 tests) - YA VALIDADOS en test_api_endpoints.py
- [ ] HU-SYS-004: E-IA-Proc (18 tests)
- [ ] HU-SYS-005: AR-IA (24 tests)
- [ ] HU-SYS-007: API REST (35 tests)

**Total Sprint 2**: 123 tests esperados

### Integraci√≥n - A Implementar üîÑ

- [ ] Escenario 1: Sesi√≥n exitosa completa
- [ ] Escenario 2: Sesi√≥n con delegaci√≥n
- [ ] Escenario 3: M√∫ltiples riesgos
- [ ] Escenario 4: Workflow docente
- [ ] Escenario 5: API end-to-end

**Total Integraci√≥n**: 5 escenarios

---

## Resultados Esperados

### Cobertura de C√≥digo

| Componente | Objetivo |
|------------|----------|
| CRPE | ‚â•85% |
| GOV-IA | ‚â•80% |
| TC-N4 | ‚â•90% |
| T-IA-Cog | ‚â•75% |
| E-IA-Proc | ‚â•75% |
| AR-IA | ‚â•80% |
| API | ‚â•70% |
| Models | ‚â•90% |
| **TOTAL** | **‚â•70%** |

### Total de Tests

- **Tests unitarios**: ~200
- **Tests integraci√≥n**: ~30
- **Tests E2E**: 5 escenarios
- **Total**: ~235 tests

---

## Pr√≥ximos Pasos

1. ‚úÖ Plan de testing creado (este documento)
2. üîÑ Implementar tests Sprint 2 faltantes
3. üîÑ Implementar tests E2E
4. üîÑ Ejecutar suite completa
5. üîÑ Validar cobertura ‚â•70%
6. üîÑ Generar reporte final

---

**Versi√≥n**: 1.0
**Fecha**: 2025-11-20
**Autor**: Mag. Alberto Cortez