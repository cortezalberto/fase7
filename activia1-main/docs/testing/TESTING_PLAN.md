# ðŸ§ª Plan de Testing - Mejoras AI-Native

## Objetivo
Validar que las optimizaciones de rendimiento, resiliencia y UX funcionan correctamente antes de producciÃ³n.

---

## ðŸ“‹ Pre-requisitos

- [x] Docker Desktop instalado y corriendo
- [x] Node.js 18+ instalado
- [x] PowerShell 5.1+ (Windows)
- [x] 8GB RAM disponible (4GB para Ollama + 4GB para sistema)
- [x] 10GB espacio en disco (para modelo llama3.2:3b)

---

## ðŸŽ¯ Tests de Backend

### Test 1: Verificar Modelo Llama3.2:3b

**Objetivo**: Confirmar que el modelo nuevo estÃ¡ instalado y es mÃ¡s rÃ¡pido

```powershell
# Verificar modelo instalado
docker exec ai-native-ollama ollama list

# Debe mostrar:
# llama3.2:3b    abc123    2.0 GB    ...
```

**Criterio de Ã©xito**: âœ… Modelo aparece en la lista

---

### Test 2: Keep-Alive Permanente

**Objetivo**: Validar que no hay latencia en la primera consulta

```powershell
# Primera consulta (debe ser <2s, no 10s como antes)
Measure-Command {
  curl -X POST http://localhost:8000/api/v1/tutor/ask `
    -H "Content-Type: application/json" `
    -d '{"session_id":"test","prompt":"Hola"}'
}

# Segunda consulta (debe ser <1s)
Measure-Command {
  curl -X POST http://localhost:8000/api/v1/tutor/ask `
    -H "Content-Type: application/json" `
    -d '{"session_id":"test","prompt":"Â¿CÃ³mo estÃ¡s?"}'
}
```

**Criterio de Ã©xito**: 
- âœ… Primera consulta: <3s
- âœ… Segunda consulta: <1s
- âŒ ANTES: Primera consulta ~8-10s

---

### Test 3: Reintentos Inteligentes

**Objetivo**: Confirmar que el sistema se recupera automÃ¡ticamente de fallos temporales

```powershell
# Paso 1: Detener Ollama
docker-compose stop ollama

# Paso 2: Intentar consulta (debe fallar pero reintentando)
curl -X POST http://localhost:8000/api/v1/tutor/ask `
  -H "Content-Type: application/json" `
  -d '{"session_id":"test","prompt":"Test"}' `
  -v

# Paso 3: Ver logs (debe mostrar reintentos)
docker-compose logs api | Select-String "attempt"

# Paso 4: Reiniciar Ollama rÃ¡pido
docker-compose start ollama

# Paso 5: Intentar de nuevo (debe recuperarse en 2-4s)
curl -X POST http://localhost:8000/api/v1/tutor/ask `
  -H "Content-Type: application/json" `
  -d '{"session_id":"test","prompt":"Test recuperaciÃ³n"}'
```

**Criterio de Ã©xito**:
- âœ… Logs muestran "attempt 1/3", "attempt 2/3", etc.
- âœ… Si Ollama se recupera durante reintentos, la request tiene Ã©xito
- âœ… Si no se recupera, falla despuÃ©s de 3 intentos (no infinito)

---

### Test 4: Circuit Breaker (Fallback)

**Objetivo**: Validar respuestas de fallback cuando Ollama estÃ¡ muerto

```powershell
# Detener Ollama completamente
docker-compose stop ollama

# Consulta al tutor (debe retornar fallback, no error 500)
curl -X POST http://localhost:8000/api/v1/tutor/ask `
  -H "Content-Type: application/json" `
  -d '{"session_id":"test","prompt":"Â¿CÃ³mo hago un bucle?"}'
```

**Criterio de Ã©xito**:
- âœ… HTTP 200 (no 500)
- âœ… Respuesta contiene "âš ï¸ El sistema de IA estÃ¡ experimentando dificultades"
- âœ… Respuesta tiene pistas genÃ©ricas pero Ãºtiles (preguntas socrÃ¡ticas)

---

### Test 5: ComparaciÃ³n de Performance

**Objetivo**: Medir mejora cuantificable vs. phi3

| MÃ©trica | phi3 (ANTES) | llama3.2:3b (AHORA) | Mejora |
|---------|--------------|---------------------|--------|
| Latencia primera consulta | 8-10s | <3s | **70% menos** |
| Latencia consultas siguientes | 1-2s | <1s | **50% menos** |
| RAM consumida (Ollama) | ~7GB | ~3GB | **57% menos** |
| TamaÃ±o del modelo | 4.7GB | 2.0GB | **57% menos** |

**CÃ³mo medir**:
```powershell
# Reiniciar Ollama para limpiar memoria
docker-compose restart ollama
Start-Sleep -Seconds 15

# Medir primera consulta
Measure-Command { 
  curl -s http://localhost:8000/api/v1/tutor/ask -X POST -H "Content-Type: application/json" -d '{"session_id":"perf","prompt":"Hola"}' | Out-Null 
}

# Medir RAM de Ollama
docker stats ai-native-ollama --no-stream
```

---

## ðŸŽ¨ Tests de Frontend

### Test 6: Skeleton Loading

**Objetivo**: Validar que no se ve pantalla blanca durante carga

```powershell
# Iniciar frontend
cd frontEnd
npm run dev
```

**Pasos manuales**:
1. Abrir http://localhost:5173/exercises/1 con DevTools (Network tab)
2. Throttle: "Slow 3G"
3. Recargar pÃ¡gina (Ctrl+Shift+R)

**Criterio de Ã©xito**:
- âœ… Aparecen skeletons grises animados inmediatamente
- âœ… NO se ve pantalla blanca vacÃ­a
- âœ… Skeletons se reemplazan por contenido real cuando carga

---

### Test 7: Monaco Editor

**Objetivo**: Validar editor profesional con syntax highlighting

**Pasos manuales**:
1. Ir a /exercises/1
2. Escribir cÃ³digo Python en el editor
3. Verificar:
   - âœ… Syntax highlighting (keywords en rosa, strings en amarillo)
   - âœ… Autocomplete funciona (Ctrl+Space)
   - âœ… NÃºmeros de lÃ­nea visibles
   - âœ… Tema oscuro aplicado

---

### Test 8: Panel Resizable

**Objetivo**: Validar layout de 3 columnas ajustables

**Pasos manuales**:
1. Ir a /exercises/1
2. Arrastrar divisores verticales (entre paneles)
3. Verificar:
   - âœ… Paneles se redimensionan suavemente
   - âœ… Divisor cambia de color al hover
   - âœ… TamaÃ±os se respetan (min/max)

---

### Test 9: AI Companion Modes

**Objetivo**: Validar cambio entre modos (Tutor/Juez/Simulador)

**Pasos manuales**:
1. Ir a /exercises/1
2. Click en tabs del panel derecho
3. Verificar:
   - âœ… Tab "Tutor" muestra chat
   - âœ… Tab "Juez" muestra interfaz de evaluaciÃ³n
   - âœ… Tab "Simulador" muestra interfaz de roleplay
   - âœ… Cambio de tab es instantÃ¡neo

---

### Test 10: Toast Notifications

**Objetivo**: Validar sistema de notificaciones no-intrusivo

**Pasos manuales**:
1. Ir a /exercises/1
2. Pegar cÃ³digo largo (>100 caracteres) en el editor
3. Verificar:
   - âœ… Toast amarillo aparece arriba-derecha
   - âœ… Mensaje: "âš ï¸ InserciÃ³n masiva detectada"
   - âœ… NO bloquea el cÃ³digo (puede seguir escribiendo)
   - âœ… Desaparece solo despuÃ©s de 7s

---

### Test 11: Teacher Dashboard

**Objetivo**: Validar dashboard del docente

**Pasos manuales**:
1. Ir a /teacher/dashboard
2. Verificar:
   - âœ… GrÃ¡fico de barras de actividad se renderiza
   - âœ… Tabla de riesgo muestra estudiantes
   - âœ… Badges de riesgo tienen colores (verde/amarillo/rojo)
   - âœ… Live Feed muestra eventos recientes

---

## ðŸ”¥ Test de EstrÃ©s

### Test 12: Reintentos Bajo Carga

**Objetivo**: Validar que reintentos no causan colapso con mÃºltiples usuarios

```powershell
# Simular 10 usuarios concurrentes (requiere Apache Bench o similar)
# Si no tienes ab, instala: choco install apache-httpd

ab -n 100 -c 10 -p request.json -T "application/json" http://localhost:8000/api/v1/tutor/ask
```

Contenido de `request.json`:
```json
{"session_id":"stress","prompt":"Test"}
```

**Criterio de Ã©xito**:
- âœ… Todas las requests completan (no timeouts)
- âœ… Tasa de Ã©xito >95%
- âœ… p95 latencia <5s

---

## ðŸ“Š Checklist de ValidaciÃ³n Final

### Backend
- [ ] Modelo llama3.2:3b instalado
- [ ] Keep-Alive funciona (primera consulta rÃ¡pida)
- [ ] Reintentos funcionan (logs muestran attempts)
- [ ] Fallback funciona (respuesta pedagÃ³gica cuando Ollama muerto)
- [ ] Performance mejorada vs. phi3

### Frontend
- [ ] Skeleton loading visible durante carga
- [ ] Monaco Editor con syntax highlighting
- [ ] Paneles resizables funcionan
- [ ] AI Companion con 3 modos
- [ ] Toast notifications aparecen correctamente
- [ ] Teacher Dashboard renderiza grÃ¡ficos
- [ ] No errores de TypeScript en consola

### IntegraciÃ³n
- [ ] Frontend conecta con backend (API calls funcionan)
- [ ] Chat del Tutor recibe respuestas de Ollama
- [ ] EjecuciÃ³n de cÃ³digo muestra output en terminal
- [ ] DetecciÃ³n de paste masivo dispara toast

---

## ðŸ› Registro de Bugs (Template)

Si encontrÃ¡s bugs durante testing:

```markdown
### Bug #X: [TÃ­tulo descriptivo]

**Componente**: Backend / Frontend / IntegraciÃ³n
**Severidad**: ðŸ”´ CrÃ­tico / ðŸŸ¡ Medio / ðŸŸ¢ Bajo
**Pasos para reproducir**:
1. ...
2. ...

**Resultado esperado**: ...
**Resultado actual**: ...
**Logs/Screenshots**: ...
```

---

## ðŸ“ˆ MÃ©tricas a Reportar en Tesis

| MÃ©trica | CÃ³mo medirla | Valor objetivo |
|---------|--------------|----------------|
| Latencia p50 primera consulta | Measure-Command (PowerShell) | <3s |
| Latencia p95 consultas siguientes | Measure-Command | <1.5s |
| Tasa de recuperaciÃ³n de fallos | Logs de reintentos | >80% |
| RAM consumida por Ollama | docker stats | <4GB |
| Time to Interactive (TTI) frontend | Lighthouse (DevTools) | <3s |
| Errores de consola (frontend) | DevTools Console | 0 |

---

**Ãšltima actualizaciÃ³n**: Diciembre 2025
