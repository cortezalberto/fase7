# GuÃ­a de MigraciÃ³n de Ollama a Gemini API

## ğŸ“‹ Resumen de Cambios

Este proyecto ha sido actualizado para usar **Google Gemini API** en lugar de Ollama como proveedor de LLM principal. Los cambios incluyen:

### ğŸ¯ CaracterÃ­sticas Principales

1. **IntegraciÃ³n con Gemini API**
   - âœ… Gemini 1.5 Flash para conversaciones normales (rÃ¡pido y econÃ³mico)
   - âœ… Gemini 1.5 Pro para anÃ¡lisis de cÃ³digo y tareas complejas (automÃ¡tico)
   - âœ… DetecciÃ³n automÃ¡tica del tipo de tarea

2. **Mejoras en el Tutor SocrÃ¡tico**
   - âœ… Prompts mejorados para **NUNCA** dar cÃ³digo de programaciÃ³n
   - âœ… El tutor solo explica conceptos y guÃ­a con preguntas
   - âœ… Refuerzo de reglas pedagÃ³gicas estrictas

3. **SelecciÃ³n Inteligente de Modelos**
   - Flash para: Conversaciones, preguntas socrÃ¡ticas, explicaciones conceptuales
   - Pro para: AnÃ¡lisis de cÃ³digo, debugging, optimizaciones, algoritmos complejos

---

## ğŸš€ Pasos para Migrar

### 1. Obtener API Key de Gemini

1. Visita: https://makersuite.google.com/app/apikey
2. Inicia sesiÃ³n con tu cuenta de Google
3. Crea una nueva API key
4. Copia la clave (la necesitarÃ¡s en el siguiente paso)

### 2. Configurar Variables de Entorno

Edita tu archivo `.env` (o crea uno desde `.env.example`):

```bash
# Cambiar el proveedor a Gemini
LLM_PROVIDER=gemini

# Agregar tu API key de Gemini
GEMINI_API_KEY=TU_API_KEY_AQUI

# ConfiguraciÃ³n opcional (con valores por defecto)
GEMINI_MODEL=gemini-1.5-flash
GEMINI_TEMPERATURE=0.7
GEMINI_TIMEOUT=60
GEMINI_MAX_RETRIES=3
```

### 3. Actualizar Dependencias (si es necesario)

El proveedor de Gemini usa `httpx` que ya deberÃ­a estar instalado. Si no:

```bash
pip install httpx
```

### 4. Reiniciar el Backend

```bash
# Si usas Docker
docker-compose restart backend

# Si ejecutas localmente
# Ctrl+C para detener
python -m backend
```

---

## ğŸ”„ Rollback a Ollama (si es necesario)

Si necesitas volver a usar Ollama, simplemente cambia en `.env`:

```bash
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=phi3
```

---

## ğŸ“Š ComparaciÃ³n: Ollama vs Gemini

| Aspecto | Ollama | Gemini |
|---------|--------|--------|
| **Costo** | Gratis (local) | Pago por uso ($) |
| **Velocidad** | Depende del hardware | Muy rÃ¡pido (Flash) |
| **Privacidad** | 100% local | Datos enviados a Google |
| **Mantenimiento** | Requiere infraestructura | Administrado por Google |
| **Modelos** | Open source (Llama, Phi, etc.) | Gemini Flash & Pro |
| **Calidad** | Buena (depende del modelo) | Excelente |

---

## ğŸ¤– CÃ³mo Funciona la SelecciÃ³n AutomÃ¡tica de Modelos

El sistema detecta automÃ¡ticamente si una consulta requiere anÃ¡lisis de cÃ³digo basÃ¡ndose en palabras clave:

### Palabras Clave que Activan el Modelo Pro:
- `cÃ³digo`, `code`
- `funciÃ³n`, `function`
- `clase`, `class`
- `mÃ©todo`, `method`
- `algoritmo`, `algorithm`
- `complejidad`, `complexity`
- `bug`, `error`, `debug`
- `refactor`, `optimizar`, `optimize`

### Ejemplos:

**ConversaciÃ³n Normal (Flash):**
```
Usuario: "Â¿QuÃ© es un bucle?"
Sistema: Usa Gemini Flash â†’ Respuesta rÃ¡pida y clara
```

**AnÃ¡lisis de CÃ³digo (Pro):**
```
Usuario: "Â¿CÃ³mo puedo optimizar este algoritmo de ordenamiento?"
Sistema: Detecta "optimizar" + "algoritmo" â†’ Usa Gemini Pro
```

---

## ğŸ”’ Mejoras en el Tutor SocrÃ¡tico

### Nuevas Reglas Estrictas:

El tutor ahora tiene instrucciones **muy claras** para:

1. **NUNCA dar cÃ³digo de programaciÃ³n**
   - âŒ No sintaxis de ningÃºn lenguaje
   - âŒ No fragmentos de cÃ³digo funcional
   - âŒ No pseudocÃ³digo detallado

2. **Solo explicar conceptos**
   - âœ… Explicaciones en lenguaje natural
   - âœ… Preguntas socrÃ¡ticas que guÃ­an
   - âœ… Conceptos teÃ³ricos y estrategias

3. **Rechazar solicitudes de cÃ³digo**
   - Si el estudiante pide cÃ³digo, el tutor redirige con preguntas
   - Ejemplo: "En vez de darte el cÃ³digo, ayÃºdame a entender: Â¿quÃ© intentaste?"

### Ejemplo de InteracciÃ³n:

**Antes (podrÃ­a dar cÃ³digo):**
```
Usuario: "Dame el cÃ³digo para sumar dos nÃºmeros"
Tutor: "Claro, usa: def suma(a, b): return a + b"
```

**Ahora (solo guÃ­a):**
```
Usuario: "Dame el cÃ³digo para sumar dos nÃºmeros"
Tutor: "ğŸ¤” Antes de escribir cÃ³digo, explicame:
1. Â¿QuÃ© entradas necesita tu funciÃ³n?
2. Â¿QuÃ© operaciÃ³n matemÃ¡tica querÃ©s realizar?
3. Â¿QuÃ© resultado esperÃ¡s obtener?

Contame tu plan en lenguaje natural primero."
```

---

## ğŸ§ª Pruebas

### Verificar que Gemini Funciona:

```python
# test_gemini.py
import asyncio
from backend.llm import LLMProviderFactory, LLMMessage, LLMRole

async def test():
    provider = LLMProviderFactory.create_from_env("gemini")
    
    messages = [
        LLMMessage(role=LLMRole.USER, content="Â¿QuÃ© es un algoritmo?")
    ]
    
    response = await provider.generate(messages)
    print(f"Modelo: {response.model}")
    print(f"Respuesta: {response.content}")
    print(f"Tokens: {response.usage}")

asyncio.run(test())
```

### Verificar SelecciÃ³n de Modelos:

```python
# Test 1: ConversaciÃ³n normal (deberÃ­a usar Flash)
messages = [LLMMessage(role=LLMRole.USER, content="Hola, Â¿cÃ³mo estÃ¡s?")]
response = await provider.generate(messages, is_code_analysis=False)
# response.model == "gemini-1.5-flash"

# Test 2: AnÃ¡lisis de cÃ³digo (deberÃ­a usar Pro)
messages = [LLMMessage(role=LLMRole.USER, content="Analiza este cÃ³digo")]
response = await provider.generate(messages, is_code_analysis=True)
# response.model == "gemini-1.5-pro"
```

---

## ğŸ’° Costos Estimados

**Gemini API Pricing (aproximado):**

| Modelo | Input (1M tokens) | Output (1M tokens) |
|--------|------------------|-------------------|
| Flash  | $0.075          | $0.30             |
| Pro    | $1.25           | $5.00             |

**Ejemplo de uso mensual moderado:**
- 1,000 conversaciones/mes
- ~500 tokens por conversaciÃ³n
- Costo estimado: **$5-15/mes**

*Nota: Precios sujetos a cambios. Verifica en: https://ai.google.dev/pricing*

---

## ğŸ› ï¸ Troubleshooting

### Error: "GEMINI_API_KEY is required"
**SoluciÃ³n:** Verifica que tu `.env` tiene `GEMINI_API_KEY=tu_key_aqui`

### Error: 429 (Rate Limit)
**SoluciÃ³n:** 
- Espera 1 minuto y reintenta
- Considera aumentar `GEMINI_MAX_RETRIES`
- Verifica lÃ­mites de tu API key en Google Cloud Console

### Error: 401 (Unauthorized)
**SoluciÃ³n:** 
- Verifica que tu API key es vÃ¡lida
- Regenera la key en https://makersuite.google.com/app/apikey

### El tutor sigue dando cÃ³digo
**SoluciÃ³n:**
- Verifica que estÃ¡s usando la versiÃ³n actualizada de `ai_gateway.py`
- Los prompts actualizados estÃ¡n en `backend/core/ai_gateway.py` y `backend/agents/tutor_prompts.py`

---

## ğŸ“ Archivos Modificados

### Nuevos Archivos:
- `backend/llm/gemini_provider.py` - Proveedor de Gemini

### Archivos Actualizados:
- `backend/llm/factory.py` - Registro del proveedor Gemini
- `backend/core/ai_gateway.py` - SelecciÃ³n automÃ¡tica de modelos y prompts mejorados
- `backend/agents/tutor_prompts.py` - Prompts reforzados anti-cÃ³digo
- `.env.example` - ConfiguraciÃ³n de Gemini

---

## âœ… Checklist de MigraciÃ³n

- [ ] Obtener API key de Gemini
- [ ] Actualizar `.env` con `LLM_PROVIDER=gemini`
- [ ] Agregar `GEMINI_API_KEY` al `.env`
- [ ] Verificar que `httpx` estÃ¡ instalado
- [ ] Reiniciar el backend
- [ ] Probar una conversaciÃ³n normal (deberÃ­a usar Flash)
- [ ] Probar anÃ¡lisis de cÃ³digo (deberÃ­a usar Pro)
- [ ] Verificar que el tutor NO da cÃ³digo

---

## ğŸ“ FilosofÃ­a del Tutor

El tutor ha sido diseÃ±ado con una filosofÃ­a pedagÃ³gica estricta:

> **"No te doy el pescado, te enseÃ±o a pescar"**

- âŒ No resolver el problema por el estudiante
- âœ… Guiar el razonamiento con preguntas
- âœ… Fomentar la explicitaciÃ³n del pensamiento
- âœ… Reforzar conceptos teÃ³ricos
- âœ… Promover la autonomÃ­a y el aprendizaje profundo

---

## ğŸ“ Soporte

Si tienes problemas con la migraciÃ³n:
1. Verifica la secciÃ³n Troubleshooting
2. Revisa los logs del backend
3. Prueba con Ollama temporalmente para descartar otros problemas
4. Verifica que tu API key de Gemini tiene cuota disponible

---

**Â¡MigraciÃ³n completada! ğŸ‰**

El sistema ahora usa Gemini API para respuestas mÃ¡s rÃ¡pidas y precisas, con un tutor que realmente enseÃ±a en vez de solo dar respuestas.
