# AI Gateway - Documentaci√≥n T√©cnica Completa

## Informe Profesional del Orquestador Central AI-Native

**Archivo**: `backend/core/ai_gateway.py`
**Versi√≥n**: 2.0 (Refactorizado STATELESS - 2025-11-19)
**Autor del An√°lisis**: Claude Code
**Fecha**: Diciembre 2025

---

## 1. Visi√≥n General

El **AI Gateway** es el componente central del ecosistema AI-Native que act√∫a como orquestador maestro de todos los submodelos de inteligencia artificial. Implementa la arquitectura C4 (Context, Classification, Cognition, Control) y coordina el flujo completo desde la recepci√≥n de una petici√≥n del estudiante hasta la generaci√≥n de una respuesta pedag√≥gica.

### 1.1 Caracter√≠sticas Principales

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| **STATELESS** | No mantiene estado en memoria; toda persistencia v√≠a repositorios BD |
| **Dependency Injection** | Todos los repositorios y providers son inyectados |
| **Escalable** | Soporta m√∫ltiples instancias (load balancer) |
| **Testeable** | F√°cil mockeo de dependencias |
| **Cache LLM** | Reduce costos de LLM 30-50% en prompts repetidos |

### 1.2 Diagrama de Arquitectura C1-C6

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                           AI GATEWAY                                     ‚îÇ
‚îÇ                    (Orquestador Central STATELESS)                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                          ‚îÇ
‚îÇ   C1: Motor LLM          C2: IPC                 C3: CRPE               ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ   ‚îÇ  Ollama/Mock ‚îÇ       ‚îÇ Clasificaci√≥n‚îÇ       ‚îÇ  Razonamiento‚îÇ        ‚îÇ
‚îÇ   ‚îÇ  Provider    ‚îÇ       ‚îÇ de Prompts   ‚îÇ       ‚îÇ  Cognitivo   ‚îÇ        ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îÇ   C4: GSR                C5: OSM                 C6: TC-N4              ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ   ‚îÇ  Gobernanza  ‚îÇ       ‚îÇ Orquestaci√≥n ‚îÇ       ‚îÇ Trazabilidad ‚îÇ        ‚îÇ
‚îÇ   ‚îÇ  PII/Riesgo  ‚îÇ       ‚îÇ de Agentes   ‚îÇ       ‚îÇ Cognitiva    ‚îÇ        ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îÇ                                                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 2. Componentes Internos (C1-C6)

### 2.1 C1: Motor LLM

**Archivo**: `backend/llm/factory.py`

El Motor LLM gestiona la conexi√≥n con proveedores de modelos de lenguaje.

```python
# Inicializaci√≥n del provider
self.llm = llm_provider or LLMProviderFactory.create("mock", config)
```

**Proveedores Soportados**:

| Provider | Descripci√≥n | Configuraci√≥n |
|----------|-------------|---------------|
| `mock` | Provider simulado para testing | Sin config requerida |
| `ollama` | LLMs locales (Phi-3, Llama 2, Mistral) | `OLLAMA_BASE_URL`, `OLLAMA_MODEL` |

**Factory Pattern**:
```python
# Crear desde variables de entorno (recomendado)
provider = LLMProviderFactory.create_from_env()

# Crear espec√≠fico
provider = LLMProviderFactory.create("ollama", {
    "base_url": "http://localhost:11434",
    "model": "phi3"
})
```

### 2.2 C2: IPC (Ingesta y Comprensi√≥n de Prompt)

**Archivo**: `backend/core/cognitive_engine.py` ‚Üí `classify_prompt()`

El IPC analiza el prompt del estudiante y extrae metadatos cruciales para el procesamiento.

```python
def classify_prompt(self, prompt: str, context: Dict[str, Any]) -> Dict[str, Any]:
    """
    Clasifica el prompt del estudiante y determina el estado cognitivo

    Returns:
        {
            "is_total_delegation": bool,      # ¬øSolicita c√≥digo completo?
            "is_question": bool,               # ¬øEs una pregunta?
            "requests_explanation": bool,      # ¬øSolicita explicaci√≥n?
            "cognitive_state": CognitiveState, # Estado cognitivo detectado
            "requires_intervention": bool,     # ¬øRequiere intervenci√≥n GOV-IA?
            "suggested_response_type": str     # Tipo de respuesta sugerido
        }
    """
```

**Detecci√≥n de Delegaci√≥n Total**:
```python
delegation_signals = [
    "dame el c√≥digo completo",
    "hac√© todo",
    "resolvelo por m√≠",
    "c√≥digo entero",
    "implementa todo"
]
```

**Estados Cognitivos Detectados** (`CognitiveState`):

| Estado | Se√±ales de Detecci√≥n | Descripci√≥n |
|--------|---------------------|-------------|
| `EXPLORACION` | "no entiendo", "no s√©" | Fase inicial de comprensi√≥n |
| `PLANIFICACION` | "c√≥mo implemento", "c√≥mo hago" | Dise√±o de soluci√≥n |
| `IMPLEMENTACION` | (default) | Escribiendo c√≥digo |
| `DEPURACION` | "error", "bug", "falla" | Resolviendo problemas |
| `VALIDACION` | "funciona", "correcto" | Verificando soluci√≥n |

**Tipos de Respuesta Sugeridos**:

| Tipo | Cu√°ndo se Aplica |
|------|------------------|
| `socratic_questioning` | Delegaci√≥n detectada |
| `conceptual_explanation` | Solicita explicaci√≥n |
| `guided_hints` | Pregunta general |
| `clarification_request` | Prompt ambiguo |

### 2.3 C3: CRPE (Motor de Razonamiento Cognitivo-Pedag√≥gico)

**Archivo**: `backend/core/cognitive_engine.py` ‚Üí `CognitiveReasoningEngine`

El CRPE genera estrategias pedag√≥gicas basadas en la clasificaci√≥n del prompt y el historial del estudiante.

```python
def generate_pedagogical_response_strategy(
    self,
    prompt: str,
    classification: Dict[str, Any],
    student_history: Optional[List[CognitiveTrace]] = None
) -> Dict[str, Any]:
    """
    Returns:
        {
            "response_type": str,           # Tipo de respuesta
            "cognitive_state": CognitiveState,
            "max_help_level": float,        # 0-1
            "instructions": List[str],      # Instrucciones para LLM
            "constraints": List[str],       # Restricciones
            "expected_elements": List[str], # Elementos esperados en respuesta
            "student_context": Dict         # Contexto del estudiante
        }
    """
```

**Pol√≠ticas Pedag√≥gicas Configurables**:

```python
self.pedagogical_policies = {
    "max_help_level": 0.7,              # Nivel m√°ximo de ayuda (0-1)
    "require_justification": True,       # Exigir justificaci√≥n
    "block_total_delegation": True,      # Bloquear delegaci√≥n total
    "adaptive_difficulty": True,         # Dificultad adaptativa
}
```

**Estrategias por Tipo de Respuesta**:

#### Socratic Questioning
```python
strategy["instructions"] = [
    "No proporcionar c√≥digo completo",
    "Hacer preguntas que gu√≠en el razonamiento",
    "Solicitar que el estudiante explique su comprensi√≥n del problema",
    "Pedir que descomponga el problema en pasos"
]
```

#### Conceptual Explanation
```python
strategy["instructions"] = [
    "Explicar conceptos fundamentales relevantes",
    "Usar ejemplos simples y analog√≠as",
    "Evitar dar la implementaci√≥n espec√≠fica",
    "Conectar con conocimientos previos"
]
```

#### Guided Hints
```python
strategy["instructions"] = [
    "Proporcionar pistas graduadas",
    "Sugerir direcci√≥n sin revelar la soluci√≥n",
    "Ofrecer pseudoc√≥digo de alto nivel si es apropiado",
    "Pedir que el estudiante justifique sus pr√≥ximos pasos"
]
```

### 2.4 C4: GSR (Gobernanza, Seguridad y Riesgo)

**Archivo**: `backend/agents/governance.py` ‚Üí `GobernanzaAgent`

El GSR implementa gobernanza institucional basada en marcos internacionales:
- UNESCO (2021): √âtica de IA
- OECD AI Principles (2019)
- IEEE Ethically Aligned Design (2019)
- ISO/IEC 23894:2023: Risk Management
- ISO/IEC 42001:2023: AI Management System

#### Sanitizaci√≥n de PII (Informaci√≥n Personal Identificable)

```python
def sanitize_prompt(self, prompt: str) -> tuple[str, bool]:
    """
    Filtra PII del prompt antes de enviarlo al LLM.

    Detecta y reemplaza:
    - Emails ‚Üí [EMAIL_REDACTED]
    - DNI ‚Üí [DNI_REDACTED]
    - Tel√©fonos ‚Üí [PHONE_REDACTED]
    - Tarjetas de cr√©dito ‚Üí [CARD_REDACTED]

    Returns:
        (prompt_sanitizado, pii_detectado)
    """
```

**Patrones Regex para PII**:
```python
self.pii_patterns = {
    "email": r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
    "dni": r'\b\d{7,8}\b',  # DNI argentino
    "phone": r'\b\d{2,4}[-.\s]?\d{4}[-.\s]?\d{4}\b',
    "credit_card": r'\b\d{4}[-.\s]?\d{4}[-.\s]?\d{4}[-.\s]?\d{4}\b',
}
```

#### Verificaci√≥n de Cumplimiento

```python
def verify_compliance(
    self,
    trace_sequence=None,
    policies: Optional[Dict[str, Any]] = None,
    action: Optional[str] = None,
    context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Returns:
        {
            "compliant": bool,
            "status": ComplianceStatus,  # COMPLIANT, WARNING, VIOLATION
            "violations": List[Dict],
            "warnings": List[Dict],
            "allow_action": bool,
            "required_adjustments": List[str]
        }
    """
```

### 2.5 C5: OSM (Orquestaci√≥n de Submodelos)

El OSM distribuye las peticiones a los agentes apropiados seg√∫n el modo de sesi√≥n.

```python
# Routing por modo de agente
if current_mode == AgentMode.TUTOR:
    response = await self._process_tutor_mode(...)
elif current_mode == AgentMode.SIMULATOR:
    response = self._process_simulator_mode(...)
elif current_mode == AgentMode.EVALUATOR:
    response = self._process_evaluator_mode(...)
```

**Modos de Agente** (`AgentMode`):

| Modo | Agente | Descripci√≥n |
|------|--------|-------------|
| `TUTOR` | T-IA-Cog | Tutor cognitivo (4 modos pedag√≥gicos) |
| `EVALUATOR` | E-IA-Proc | Evaluador de procesos |
| `SIMULATOR` | S-IA-X | Simuladores profesionales (11 roles) |
| `RISK_ANALYST` | AR-IA | An√°lisis de riesgos (5 dimensiones) |
| `GOVERNANCE` | GOV-IA | Gobernanza institucional |
| `PRACTICE` | - | Pr√°ctica libre (sin asistencia activa) |

### 2.6 C6: TC-N4 (Trazabilidad Cognitiva N4)

**Archivo**: `backend/agents/traceability.py` ‚Üí `TrazabilidadN4Agent`

Captura todas las interacciones en 4 niveles de profundidad:

| Nivel | Nombre | Qu√© Captura |
|-------|--------|-------------|
| N1 | Superficial | Archivos, entregas, versi√≥n final |
| N2 | T√©cnico | Commits, branches, tests automatizados |
| N3 | Interaccional | Prompts, respuestas, reintentos |
| N4 | Cognitivo | Intenci√≥n, decisiones, justificaciones, alternativas |

```python
def _create_trace(
    self,
    session_id: str,
    student_id: str,
    activity_id: str,
    interaction_type: InteractionType,
    content: str,
    level: TraceLevel,
    **kwargs
) -> CognitiveTrace:
    """Crea una traza cognitiva (no la persiste a√∫n)"""
```

**Tipos de Interacci√≥n** (`InteractionType`):

| Tipo | Descripci√≥n |
|------|-------------|
| `STUDENT_PROMPT` | Mensaje del estudiante |
| `AI_RESPONSE` | Respuesta del agente IA |
| `TUTOR_INTERVENTION` | Intervenci√≥n pedag√≥gica |
| `SELF_CORRECTION` | Autocorrecci√≥n del estudiante |
| `DESIGN_DECISION` | Decisi√≥n de dise√±o documentada |

---

## 3. Flujo de Procesamiento de Peticiones

### 3.1 Diagrama de Flujo Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUJO DE PROCESAMIENTO DE INTERACCI√ìN                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Cliente (Frontend)
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ POST /api/v1/    ‚îÇ  InteractionRequest:
‚îÇ   interactions   ‚îÇ  - session_id
‚îÇ                  ‚îÇ  - prompt
‚îÇ                  ‚îÇ  - context (optional)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         FASE 1: VALIDACI√ìN                            ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  _validate_interaction_input()                                        ‚îÇ
‚îÇ  ‚îú‚îÄ Validar session_id (no vac√≠o, m√°x 100 chars)                     ‚îÇ
‚îÇ  ‚îú‚îÄ Validar prompt (m√≠n 10, m√°x 5000 chars)                          ‚îÇ
‚îÇ  ‚îî‚îÄ Validar context (m√°x 10KB, serializable JSON)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FASE 2: SANITIZACI√ìN PII (GOV-IA)                  ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  governance_agent.sanitize_prompt(prompt)                             ‚îÇ
‚îÇ  ‚îú‚îÄ Detectar emails ‚Üí [EMAIL_REDACTED]                               ‚îÇ
‚îÇ  ‚îú‚îÄ Detectar DNI ‚Üí [DNI_REDACTED]                                    ‚îÇ
‚îÇ  ‚îú‚îÄ Detectar tel√©fonos ‚Üí [PHONE_REDACTED]                            ‚îÇ
‚îÇ  ‚îî‚îÄ Detectar tarjetas ‚Üí [CARD_REDACTED]                              ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  Si PII detectado ‚Üí Log warning + usar prompt sanitizado              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   FASE 3: OBTENER SESI√ìN (STATELESS)                  ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  session_repo.get_by_id(session_id)                                   ‚îÇ
‚îÇ  ‚îú‚îÄ Si no existe ‚Üí raise ValueError                                  ‚îÇ
‚îÇ  ‚îî‚îÄ Extraer: student_id, activity_id, current_mode                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 FASE 4: CLASIFICACI√ìN DE PROMPT (IPC)                 ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  cognitive_engine.classify_prompt(prompt, context)                    ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  Output:                                                              ‚îÇ
‚îÇ  ‚îú‚îÄ is_total_delegation: bool                                        ‚îÇ
‚îÇ  ‚îú‚îÄ is_question: bool                                                ‚îÇ
‚îÇ  ‚îú‚îÄ requests_explanation: bool                                       ‚îÇ
‚îÇ  ‚îú‚îÄ cognitive_state: CognitiveState                                  ‚îÇ
‚îÇ  ‚îú‚îÄ requires_intervention: bool                                      ‚îÇ
‚îÇ  ‚îî‚îÄ suggested_response_type: str                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              FASE 5: VERIFICACI√ìN DE GOBERNANZA (GSR)                 ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  cognitive_engine.should_block_response(classification)               ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  Si delegaci√≥n total detectada Y block_total_delegation=True:         ‚îÇ
‚îÇ  ‚îî‚îÄ should_block = True, reason = "Delegaci√≥n total detectada..."    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               FASE 6: REGISTRO DE TRAZA DE ENTRADA (N4)               ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  _create_trace(                                                       ‚îÇ
‚îÇ      session_id, student_id, activity_id,                            ‚îÇ
‚îÇ      InteractionType.STUDENT_PROMPT,                                  ‚îÇ
‚îÇ      content=prompt,                                                  ‚îÇ
‚îÇ      level=TraceLevel.N4_COGNITIVO,                                  ‚îÇ
‚îÇ      cognitive_intent=classification["cognitive_state"]               ‚îÇ
‚îÇ  )                                                                    ‚îÇ
‚îÇ  _persist_trace(input_trace)                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   ¬øshould_block?        ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ           ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ SI                      ‚îÇ NO
                    ‚ñº                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   RESPUESTA BLOQUEADA         ‚îÇ   ‚îÇ   FASE 7: ESTRATEGIA          ‚îÇ
‚îÇ                               ‚îÇ   ‚îÇ   PEDAG√ìGICA (CRPE)           ‚îÇ
‚îÇ   _generate_blocked_response()‚îÇ   ‚îÇ                               ‚îÇ
‚îÇ   ‚îú‚îÄ Mensaje pedag√≥gico       ‚îÇ   ‚îÇ   _get_student_history()      ‚îÇ
‚îÇ   ‚îú‚îÄ Registrar intervenci√≥n   ‚îÇ   ‚îÇ   generate_pedagogical_       ‚îÇ
‚îÇ   ‚îî‚îÄ Registrar riesgo RC1     ‚îÇ   ‚îÇ   response_strategy()         ‚îÇ
‚îÇ      (COGNITIVE_DELEGATION)   ‚îÇ   ‚îÇ                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                     ‚îÇ
                                                     ‚ñº
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                    ‚îÇ    FASE 8: ROUTING A AGENTE    ‚îÇ
                                    ‚îÇ    (OSM - Orquestaci√≥n)        ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                     ‚îÇ
                           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                           ‚îÇ                         ‚îÇ                         ‚îÇ
                           ‚ñº                         ‚ñº                         ‚ñº
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ   TUTOR MODE     ‚îÇ      ‚îÇ  SIMULATOR MODE  ‚îÇ      ‚îÇ  EVALUATOR MODE  ‚îÇ
                ‚îÇ   (T-IA-Cog)     ‚îÇ      ‚îÇ   (S-IA-X)       ‚îÇ      ‚îÇ   (E-IA-Proc)    ‚îÇ
                ‚îÇ                  ‚îÇ      ‚îÇ                  ‚îÇ      ‚îÇ                  ‚îÇ
                ‚îÇ _process_tutor_  ‚îÇ      ‚îÇ _process_        ‚îÇ      ‚îÇ _process_        ‚îÇ
                ‚îÇ mode()           ‚îÇ      ‚îÇ simulator_mode() ‚îÇ      ‚îÇ evaluator_mode() ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ   Tipos de Respuesta        ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚ñº                   ‚ñº                   ‚ñº                   ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Socratic ‚îÇ       ‚îÇConceptual‚îÇ       ‚îÇ Guided   ‚îÇ       ‚îÇClarifica-‚îÇ
‚îÇQuestioning‚îÇ      ‚îÇExplanation‚îÇ      ‚îÇ Hints    ‚îÇ       ‚îÇtion      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
                         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ            FASE 9: REGISTRO DE TRAZA DE RESPUESTA (N4)               ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  _create_trace(                                                       ‚îÇ
‚îÇ      InteractionType.AI_RESPONSE,                                     ‚îÇ
‚îÇ      content=response["message"],                                     ‚îÇ
‚îÇ      agent_id=current_mode.value                                      ‚îÇ
‚îÇ  )                                                                    ‚îÇ
‚îÇ  _persist_trace(response_trace)                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              FASE 10: AN√ÅLISIS DE RIESGOS (AR-IA)                    ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  _analyze_risks_async(session_id, input_trace, response_trace,       ‚îÇ
‚îÇ                       classification)                                 ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  Riesgos detectados:                                                  ‚îÇ
‚îÇ  ‚îú‚îÄ RC1: Delegaci√≥n Total (COGNITIVE_DELEGATION)                     ‚îÇ
‚îÇ  ‚îú‚îÄ RC2: Dependencia Excesiva (AI_DEPENDENCY)                        ‚îÇ
‚îÇ  ‚îú‚îÄ RC3: Falta de Justificaci√≥n (LACK_JUSTIFICATION)                 ‚îÇ
‚îÇ  ‚îî‚îÄ REp1: Aceptaci√≥n Acr√≠tica (UNCRITICAL_ACCEPTANCE)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                FASE 11: M√âTRICAS PROMETHEUS                          ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  metrics.record_interaction(session_id, student_id, agent, status)   ‚îÇ
‚îÇ  metrics.record_cognitive_state(cognitive_state)                      ‚îÇ
‚îÇ  metrics.record_trace_creation(trace_level, interaction_type)        ‚îÇ
‚îÇ  metrics.record_risk_detection(risk_type, risk_level, dimension)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      RESPUESTA AL CLIENTE                             ‚îÇ
‚îÇ                                                                       ‚îÇ
‚îÇ  InteractionResponse:                                                 ‚îÇ
‚îÇ  ‚îú‚îÄ interaction_id: UUID                                             ‚îÇ
‚îÇ  ‚îú‚îÄ session_id: str                                                  ‚îÇ
‚îÇ  ‚îú‚îÄ response: str (mensaje del agente)                               ‚îÇ
‚îÇ  ‚îú‚îÄ agent_used: str                                                  ‚îÇ
‚îÇ  ‚îú‚îÄ cognitive_state_detected: str                                    ‚îÇ
‚îÇ  ‚îú‚îÄ ai_involvement: float (0-1)                                      ‚îÇ
‚îÇ  ‚îú‚îÄ blocked: bool                                                    ‚îÇ
‚îÇ  ‚îú‚îÄ block_reason: Optional[str]                                      ‚îÇ
‚îÇ  ‚îú‚îÄ trace_id: str                                                    ‚îÇ
‚îÇ  ‚îú‚îÄ risks_detected: List[str]                                        ‚îÇ
‚îÇ  ‚îî‚îÄ timestamp: datetime                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 3.2 C√≥digo del Flujo Principal

```python
async def process_interaction(
    self,
    session_id: str,
    prompt: str,
    context: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    Procesa una interacci√≥n del estudiante a trav√©s del gateway (STATELESS)

    Este es el flujo principal que:
    1. Valida entrada
    2. Obtiene sesi√≥n desde BD (no de memoria)
    3. Clasifica el prompt (IPC)
    4. Verifica gobernanza (GSR)
    5. Genera estrategia pedag√≥gica (CRPE)
    6. Detecta riesgos (AR-IA)
    7. Registra en trazabilidad (N4) v√≠a repositorio
    8. Genera respuesta seg√∫n el agente activo
    """
```

---

## 4. Distribuci√≥n a los Agentes

### 4.1 Modo TUTOR (T-IA-Cog)

**Archivo**: `backend/agents/tutor.py` ‚Üí `TutorCognitivoAgent`

El modo Tutor implementa el andamiaje cognitivo con 4 tipos de respuesta:

```python
async def _process_tutor_mode(
    self,
    session_id: str,
    prompt: str,
    strategy: Dict[str, Any],
    classification: Dict[str, Any]
) -> Dict[str, Any]:
    """Procesa la interacci√≥n en modo T-IA-Cog (Tutor)"""

    response_type = strategy.get("response_type", "unknown")

    if response_type == "socratic_questioning":
        message = await self._generate_socratic_response(prompt, strategy, session_id)
    elif response_type == "conceptual_explanation":
        message = await self._generate_conceptual_explanation(prompt, strategy, session_id)
    elif response_type == "guided_hints":
        message = await self._generate_guided_hints(prompt, strategy, session_id)
    else:
        message = await self._generate_conceptual_explanation(prompt, strategy, session_id)
```

#### 4.1.1 Respuesta Socr√°tica

```python
async def _generate_socratic_response(self, prompt, strategy, session_id):
    """Genera respuesta socr√°tica con memoria de conversaci√≥n"""

    messages = [
        LLMMessage(
            role=LLMRole.SYSTEM,
            content="""Eres un tutor socr√°tico. Tu objetivo es guiar al estudiante
            a descubrir la respuesta por s√≠ mismo mediante preguntas orientadoras.

            NO des la respuesta directa. Haz preguntas que:
            1. Exploren su comprensi√≥n actual
            2. Identifiquen sus suposiciones
            3. Lo gu√≠en a descomponer el problema
            4. Lo ayuden a encontrar la soluci√≥n por s√≠ mismo

            S√© breve y preciso. M√°ximo 4-5 preguntas."""
        )
    ]

    # Agregar historial de conversaci√≥n
    messages.extend(conversation_history)

    # Generar respuesta
    response = await self.llm.generate(messages, max_tokens=300, temperature=0.7)
```

#### 4.1.2 Explicaci√≥n Conceptual

```python
async def _generate_conceptual_explanation(self, prompt, strategy, session_id):
    """Explicaci√≥n conceptual sin c√≥digo"""

    system_prompt = """Eres un tutor pedag√≥gico. Explica conceptos
    fundamentales de manera clara y did√°ctica.

    Estructura tu explicaci√≥n:
    1. Concepto clave (definici√≥n simple)
    2. Principio fundamental (por qu√© es importante)
    3. Ejemplo concreto y simple
    4. Aplicaci√≥n pr√°ctica

    Usa markdown para formato. S√© claro y conciso (m√°ximo 200 palabras)."""
```

#### 4.1.3 Pistas Guiadas

```python
async def _generate_guided_hints(self, prompt, strategy, session_id):
    """Pistas graduadas sin soluci√≥n completa"""

    system_prompt = """Eres un tutor que da pistas graduadas.
    NO des la soluci√≥n completa.

    Proporciona 3-4 pistas que:
    1. Sugieran c√≥mo descomponer el problema
    2. Mencionen conceptos/estructuras relevantes
    3. Indiquen casos a considerar
    4. Sugieran un pr√≥ximo paso concreto

    Cada pista debe acercar al estudiante a la soluci√≥n
    sin d√°rsela directamente."""
```

### 4.2 Modo SIMULATOR (S-IA-X)

El modo Simulador delega a los 11 simuladores profesionales:

**Simuladores V1**:
| ID | Simulador | Rol |
|----|-----------|-----|
| PO-IA | Product Owner | Priorizaci√≥n de backlog |
| SM-IA | Scrum Master | Gesti√≥n de sprints |
| IT-IA | Tech Interviewer | Entrevistas t√©cnicas |
| IR-IA | Incident Responder | Respuesta a incidentes |
| CX-IA | Client | Cliente exigente |
| DSO-IA | DevSecOps | Auditor√≠a de seguridad |

**Simuladores V2**:
| ID | Simulador | Rol |
|----|-----------|-----|
| SD-IA | Senior Developer | Code review |
| QA-IA | QA Engineer | Testing |
| SA-IA | Security Auditor | Seguridad |
| TL-IA | Tech Lead | Arquitectura |
| DC-IA | Demanding Client | Requisitos cambiantes |

### 4.3 Modo EVALUATOR (E-IA-Proc)

El modo Evaluador activa el pipeline de 7 fases basado en Zimmerman (2002):

1. **Forethought** - Planificaci√≥n y establecimiento de metas
2. **Performance** - Ejecuci√≥n con auto-monitoreo
3. **Self-Reflection** - Evaluaci√≥n del proceso
4. **Cognitive** - An√°lisis de estrategias cognitivas
5. **Metacognitive** - Evaluaci√≥n de autorregulaci√≥n
6. **Behavioral** - An√°lisis de patrones de comportamiento
7. **Integration** - S√≠ntesis y feedback formativo

---

## 5. Gesti√≥n de Memoria y Conversaci√≥n

### 5.1 Carga del Historial de Conversaci√≥n

```python
def _load_conversation_history(self, session_id: str) -> List[LLMMessage]:
    """
    Carga el historial de conversaci√≥n de esta sesi√≥n como mensajes LLM.

    Recupera todas las trazas de la sesi√≥n y las convierte al formato
    de mensajes que espera el LLM provider, manteniendo el contexto
    completo de la conversaci√≥n.
    """
    db_traces = self.trace_repo.get_by_session(session_id)

    messages = []
    for trace in db_traces:
        if trace.interaction_type == InteractionType.STUDENT_PROMPT.value:
            messages.append(LLMMessage(role=LLMRole.USER, content=trace.content))
        elif trace.interaction_type in [
            InteractionType.AI_RESPONSE.value,
            InteractionType.TUTOR_INTERVENTION.value
        ]:
            messages.append(LLMMessage(role=LLMRole.ASSISTANT, content=trace.content))

    return messages
```

### 5.2 Cache de Respuestas LLM

```python
# Verificar cache antes de generar
if self.cache is not None:
    cached_response = self.cache.get(
        prompt=prompt,
        context=cache_context,
        mode="TUTOR"
    )

if cached_response is not None:
    # Cache HIT - usar respuesta cacheada (ahorra llamada LLM)
    message = cached_response
else:
    # Cache MISS - generar respuesta nueva
    message = await self._generate_response(...)

    # Guardar en cache para futuras solicitudes
    self.cache.set(
        prompt=prompt,
        response=message,
        context=cache_context,
        mode="TUTOR"
    )
```

**Configuraci√≥n del Cache**:
```python
cache_enabled = os.getenv("LLM_CACHE_ENABLED", "true")
cache_ttl = int(os.getenv("LLM_CACHE_TTL", "3600"))  # 1 hora
cache_max_entries = int(os.getenv("LLM_CACHE_MAX_ENTRIES", "1000"))
```

---

## 6. An√°lisis de Riesgos (AR-IA)

### 6.1 Riesgos Detectados

```python
def _analyze_risks_async(
    self,
    session_id: str,
    input_trace: CognitiveTrace,
    response_trace: CognitiveTrace,
    classification: Dict[str, Any]
) -> None:
    """
    An√°lisis de riesgos as√≠ncrono (AR-IA)

    Detecta:
    - RC1: Delegaci√≥n total (solicitudes de c√≥digo completo)
    - RC2: Dependencia excesiva de IA (alto ai_involvement)
    - RC3: Falta de justificaci√≥n (decisiones sin explicaci√≥n)
    - RE1: Integridad acad√©mica (uso no divulgado de IA)
    - REp1: Aceptaci√≥n acr√≠tica (no cuestiona respuestas de IA)
    """
```

### 6.2 Dimensiones de Riesgo

| Dimensi√≥n | C√≥digo | Tipos de Riesgo |
|-----------|--------|-----------------|
| **Cognitivo** | RC | COGNITIVE_DELEGATION, SUPERFICIAL_REASONING, AI_DEPENDENCY, LACK_JUSTIFICATION |
| **√âtico** | RE | ACADEMIC_INTEGRITY, UNDISCLOSED_AI_USE, PLAGIARISM |
| **Epist√©mico** | REp | CONCEPTUAL_ERROR, LOGICAL_FALLACY, UNCRITICAL_ACCEPTANCE |
| **T√©cnico** | RT | SECURITY_VULNERABILITY, POOR_CODE_QUALITY, ARCHITECTURAL_FLAW |
| **Gobernanza** | RG | POLICY_VIOLATION, UNAUTHORIZED_USE, AUTOMATION_SUSPECTED |

### 6.3 Umbrales de Detecci√≥n

```python
# Constantes en backend/core/constants.py
AI_DEPENDENCY_LOW_THRESHOLD = 0.3    # 30%
AI_DEPENDENCY_MEDIUM_THRESHOLD = 0.6  # 60% - Genera riesgo MEDIUM
AI_DEPENDENCY_HIGH_THRESHOLD = 0.8    # 80%

# Umbral para bloqueo autom√°tico
GOVERNANCE_BLOCK_THRESHOLD_AI_DEPENDENCY = 0.9  # 90%
GOVERNANCE_BLOCK_CONSECUTIVE_DELEGATIONS = 5     # Intentos consecutivos
```

---

## 7. Dependency Injection

### 7.1 Archivo: `backend/api/deps.py`

```python
def get_ai_gateway(
    session_repo: SessionRepository = Depends(get_session_repository),
    trace_repo: TraceRepository = Depends(get_trace_repository),
    risk_repo: RiskRepository = Depends(get_risk_repository),
    evaluation_repo: EvaluationRepository = Depends(get_evaluation_repository),
    sequence_repo: TraceSequenceRepository = Depends(get_sequence_repository),
) -> AIGateway:
    """
    Dependency para obtener el AI Gateway con DI completa.
    Crea NUEVA instancia por request con repositorios frescos.

    IMPORTANTE: No usar singleton para el gateway ya que los repositorios
    contienen sesiones de BD que deben ser √∫nicas por request.
    El LLM provider y el cache s√≠ se cachean (stateless).
    """

    return AIGateway(
        llm_provider=_llm_provider_instance,
        cognitive_engine=None,  # Usar default
        session_repo=session_repo,
        trace_repo=trace_repo,
        risk_repo=risk_repo,
        evaluation_repo=evaluation_repo,
        sequence_repo=sequence_repo,
        cache=llm_cache,
        config=None
    )
```

### 7.2 Thread Safety para Singletons

```python
# Lock para thread-safety en LLM provider singleton
_llm_provider_instance: Optional[LLMProviderFactory] = None
_llm_provider_lock = threading.Lock()

def get_llm_provider():
    """Thread-safe singleton para LLM provider"""
    global _llm_provider_instance

    # Lock-first pattern (m√°s seguro en Python)
    with _llm_provider_lock:
        if _llm_provider_instance is None:
            _llm_provider_instance = _initialize_llm_provider()

    return _llm_provider_instance
```

---

## 8. Circuit Breaker y Fallbacks

### 8.1 Fallback cuando LLM no est√° disponible

```python
def _get_fallback_socratic_response(self, prompt: str) -> str:
    """Fallback cuando Ollama est√° inaccesible"""

    return """‚ö†Ô∏è El sistema de IA est√° experimentando dificultades temporales,
    pero puedo ayudarte con estas preguntas gu√≠a:

    **Para ayudarte mejor, necesito entender tu proceso de pensamiento:**

    1. ¬øQu√© entend√©s que te est√°n pidiendo resolver?
    2. ¬øQu√© conceptos cre√©s que son relevantes para este problema?
    3. ¬øC√≥mo funcionar√≠a una soluci√≥n ideal?
    4. ¬øQu√© has intentado hasta ahora y qu√© resultados obtuviste?

    üí° **Tip**: Intenta descomponer el problema en partes m√°s peque√±as.

    _Responde estas preguntas y podremos continuar cuando el sistema se recupere._"""
```

---

## 9. M√©tricas Prometheus

### 9.1 M√©tricas Registradas

```python
# Por cada interacci√≥n exitosa
metrics.record_interaction(
    session_id=session_id,
    student_id=student_id,
    agent_used=current_mode.value,
    status="success"
)

# Por cada estado cognitivo detectado
metrics.record_cognitive_state(cognitive_state.value)

# Por cada traza creada
metrics.record_trace_creation(
    trace_level=trace.trace_level.value,
    interaction_type=trace.interaction_type.value
)

# Por cada riesgo detectado
metrics.record_risk_detection(
    risk_type=risk_type.value,
    risk_level=risk_level.value,
    dimension=dimension.value
)

# Por cada bloqueo de gobernanza
metrics.record_governance_block(
    reason="total_delegation",
    session_id=session_id
)
```

---

## 10. Validaci√≥n de Entrada

### 10.1 Constantes de Validaci√≥n

```python
# backend/core/constants.py

PROMPT_MIN_LENGTH = 10          # M√≠nimo de caracteres
PROMPT_MAX_LENGTH = 5000        # M√°ximo de caracteres
CONTEXT_MAX_SIZE_BYTES = 10240  # 10KB m√°ximo
SESSION_ID_MAX_LENGTH = 100     # M√°ximo de caracteres
```

### 10.2 M√©todo de Validaci√≥n

```python
def _validate_interaction_input(
    self,
    session_id: str,
    prompt: str,
    context: Optional[Dict[str, Any]]
) -> None:
    """
    Valida la entrada de una interacci√≥n.

    Raises:
        ValueError: Si la validaci√≥n falla
    """
    # Validar session_id
    if not session_id or len(session_id) > SESSION_ID_MAX_LENGTH:
        raise ValueError("session_id inv√°lido")

    # Validar prompt
    prompt_length = len(prompt.strip())
    if prompt_length < PROMPT_MIN_LENGTH or prompt_length > PROMPT_MAX_LENGTH:
        raise ValueError("Prompt fuera de rango")

    # Validar context
    if context is not None:
        context_size = len(json.dumps(context).encode('utf-8'))
        if context_size > CONTEXT_MAX_SIZE_BYTES:
            raise ValueError("Context demasiado grande")
```

---

## 11. Repositorios (Repository Protocol)

### 11.1 Interfaces Protocol

```python
@runtime_checkable
class SessionRepositoryProtocol(Protocol):
    """Protocol for session repository operations"""
    def create(self, student_id: str, activity_id: str, mode: str) -> Any: ...
    def get(self, session_id: str) -> Any: ...
    def update(self, session_id: str, **kwargs: Any) -> Any: ...

@runtime_checkable
class TraceRepositoryProtocol(Protocol):
    """Protocol for trace repository operations"""
    def create(self, trace: CognitiveTrace) -> Any: ...
    def get_by_session(self, session_id: str) -> List[CognitiveTrace]: ...

@runtime_checkable
class RiskRepositoryProtocol(Protocol):
    """Protocol for risk repository operations"""
    def create(self, risk: Risk) -> Any: ...
    def get_by_session(self, session_id: str) -> List[Risk]: ...
```

---

## 12. Tablas de Base de Datos Relacionadas

| Tabla | Prop√≥sito | FK Principal |
|-------|-----------|--------------|
| `sessions` | Sesiones de interacci√≥n | `user_id` |
| `cognitive_traces` | Trazas N4 | `session_id` |
| `trace_sequences` | Secuencias de trazas | `session_id` |
| `risks` | Riesgos detectados | `session_id` |
| `evaluations` | Evaluaciones generadas | `session_id` |
| `interactions` | Historial de interacciones | `session_id` |

---

## 13. Referencias Bibliogr√°ficas

El AI Gateway se basa en fundamentos te√≥ricos de:

| Teor√≠a | Autor | Aplicaci√≥n |
|--------|-------|------------|
| Cognici√≥n Distribuida | Hutchins (1995) | Distribuci√≥n de carga cognitiva |
| Cognici√≥n Extendida | Clark & Chalmers (1998) | IA como extensi√≥n cognitiva |
| Teor√≠a de Carga Cognitiva | Sweller (1988) | Reducci√≥n de carga extr√≠nseca |
| Autorregulaci√≥n | Zimmerman (2002) | Modelo de 7 fases para evaluaci√≥n |
| Andamiaje Cognitivo | Wood, Bruner & Ross (1976) | Scaffolding adaptativo |

---

## 14. Archivos Relacionados

| Archivo | Prop√≥sito |
|---------|-----------|
| `backend/core/ai_gateway.py` | Orquestador central |
| `backend/core/cognitive_engine.py` | Motor CRPE |
| `backend/core/constants.py` | Constantes y umbrales |
| `backend/agents/governance.py` | Agente GOV-IA |
| `backend/agents/tutor.py` | Agente T-IA-Cog |
| `backend/agents/traceability.py` | Sistema TC-N4 |
| `backend/agents/risk_analyst.py` | Agente AR-IA |
| `backend/api/deps.py` | Dependency Injection |
| `backend/api/routers/interactions.py` | Router principal |
| `backend/llm/factory.py` | Factory de LLM providers |

---

## 15. Resumen Ejecutivo

El **AI Gateway** es el coraz√≥n del sistema AI-Native MVP, implementando:

1. **Arquitectura STATELESS** que permite escalabilidad horizontal
2. **Pipeline de 11 fases** desde validaci√≥n hasta respuesta
3. **6 componentes internos** (C1-C6) que coordinan el procesamiento
4. **Routing inteligente** a 6 agentes especializados seg√∫n modo
5. **Gobernanza robusta** con sanitizaci√≥n de PII y pol√≠ticas pedag√≥gicas
6. **Trazabilidad N4 completa** de cada interacci√≥n
7. **An√°lisis de riesgos en tiempo real** en 5 dimensiones
8. **Cache LLM** para optimizaci√≥n de costos (30-50% ahorro)
9. **Circuit Breaker** con fallbacks cuando LLM no disponible
10. **M√©tricas Prometheus** para observabilidad

El sistema eval√∫a el **PROCESO** (c√≥mo resuelve el estudiante) y no solo el **PRODUCTO** (c√≥digo final), aline√°ndose con la tesis doctoral de evaluaci√≥n basada en procesos.