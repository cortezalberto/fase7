"""
TEST DE INTEGRACI√ìN COMPLETO - SUPER TEST
==========================================

Prueba integral del sistema AI-Native con:
1. Todos los agentes (T-IA-Cog, E-IA-Proc, AR-IA, GOV-IA, TC-N4)
2. M√∫ltiples usuarios concurrentes
3. Escenarios reales de uso
4. Validaci√≥n de trazabilidad N4
5. Detecci√≥n de riesgos
6. Filtrado PII
7. Persistencia en BD

Ejecutar:
    pytest tests/test_integration_complete.py -v -s
    pytest tests/test_integration_complete.py -v -s --log-cli-level=INFO
"""
import pytest
import asyncio
import time
from datetime import datetime
from typing import List, Dict, Any
from concurrent.futures import ThreadPoolExecutor, as_completed
from sqlalchemy.orm import Session
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from backend.core import AIGateway
from backend.core.cognitive_engine import CognitiveReasoningEngine, AgentMode
from backend.llm import LLMProviderFactory
from backend.database.config import DatabaseConfig, Base
from backend.database.repositories import (
    SessionRepository,
    TraceRepository,
    RiskRepository,
    EvaluationRepository,
    TraceSequenceRepository,
)
from backend.models.trace import TraceLevel, InteractionType
from backend.models.risk import RiskLevel, RiskType


# ============================================================================
# FIXTURES
# ============================================================================

@pytest.fixture(scope="module")
def test_db():
    """Crea una base de datos de prueba en memoria"""
    engine = create_engine("sqlite:///:memory:", echo=False)
    Base.metadata.create_all(engine)
    SessionLocal = sessionmaker(bind=engine)
    
    yield SessionLocal
    
    engine.dispose()


@pytest.fixture(scope="module")
def db_session(test_db):
    """Crea una sesi√≥n de BD para las pruebas"""
    session = test_db()
    yield session
    session.close()


@pytest.fixture(scope="module")
def repositories(db_session):
    """Crea todos los repositorios necesarios"""
    return {
        "session": SessionRepository(db_session),
        "trace": TraceRepository(db_session),
        "risk": RiskRepository(db_session),
        "evaluation": EvaluationRepository(db_session),
        "sequence": TraceSequenceRepository(db_session),
    }


@pytest.fixture(scope="module")
def llm_provider():
    """Crea proveedor LLM (mock para tests r√°pidos, ollama para integraci√≥n)"""
    # Usar mock para tests r√°pidos, cambiar a "ollama" para prueba real
    return LLMProviderFactory.create("mock", {})


@pytest.fixture(scope="module")
def ai_gateway(repositories, llm_provider):
    """Crea el AI Gateway completamente configurado"""
    cognitive_engine = CognitiveReasoningEngine({})
    
    gateway = AIGateway(
        llm_provider=llm_provider,
        cognitive_engine=cognitive_engine,
        session_repo=repositories["session"],
        trace_repo=repositories["trace"],
        risk_repo=repositories["risk"],
        evaluation_repo=repositories["evaluation"],
        sequence_repo=repositories["sequence"],
        cache=None,  # Sin cache para tests
        config={}
    )
    
    return gateway


# ============================================================================
# TEST 1: AGENTE TUTOR (T-IA-Cog) - Detecci√≥n de Delegaci√≥n
# ============================================================================

@pytest.mark.asyncio
async def test_tutor_agent_blocks_total_delegation(ai_gateway):
    """
    Verifica que el Tutor bloquee solicitudes de c√≥digo completo
    y responda con preguntas socr√°ticas
    """
    print("\n" + "="*80)
    print("TEST 1: AGENTE TUTOR - DETECCI√ìN DE DELEGACI√ìN TOTAL")
    print("="*80)
    
    # Crear sesi√≥n de prueba
    session_id = ai_gateway.create_session(
        student_id="student_tutor_001",
        activity_id="act_cola_circular",
        mode="TUTOR"
    )
    
    # Prompts que DEBEN ser bloqueados
    delegation_prompts = [
        "Dame el c√≥digo completo de la cola circular",
        "Hac√© todo por m√≠, necesito la soluci√≥n ya",
        "Implementa todo el c√≥digo entero",
        "Resolvelo por m√≠ completamente"
    ]
    
    for prompt in delegation_prompts:
        print(f"\nüìù Prompt: {prompt}")
        
        response = await ai_gateway.process_interaction(
            session_id=session_id,
            prompt=prompt
        )
        
        # Verificaciones
        assert response.get("blocked") == True, "Deber√≠a bloquear delegaci√≥n total"
        assert "descompongas" in response.get("response", "").lower() or \
               "expliques" in response.get("response", "").lower(), \
               "Deber√≠a pedir descomposici√≥n/explicaci√≥n"
        
        print(f"‚úÖ BLOQUEADO correctamente")
        print(f"üìã Respuesta: {response.get('response')[:150]}...")
    
    print(f"\n‚úÖ TEST 1 COMPLETADO: {len(delegation_prompts)} delegaciones bloqueadas")


# ============================================================================
# TEST 2: AGENTE GOBERNANZA (GOV-IA) - Filtro PII
# ============================================================================

@pytest.mark.asyncio
async def test_governance_agent_filters_pii(ai_gateway):
    """
    Verifica que el agente de gobernanza filtre informaci√≥n personal
    (emails, DNI, tel√©fonos) antes de enviar al LLM
    """
    print("\n" + "="*80)
    print("TEST 2: AGENTE GOBERNANZA - FILTRO PII")
    print("="*80)
    
    session_id = ai_gateway.create_session(
        student_id="student_gov_001",
        activity_id="act_test_pii",
        mode="TUTOR"
    )
    
    # Prompts con PII que deben ser sanitizados
    pii_prompts = [
        {
            "original": "Mi email es juan.perez@universidad.edu.ar y necesito ayuda",
            "should_contain": "[EMAIL_REDACTED]"
        },
        {
            "original": "Soy estudiante DNI 12345678, tengo una duda",
            "should_contain": "[DNI_REDACTED]"
        },
        {
            "original": "Llamame al 011-4567-8901 para coordinar",
            "should_contain": "[PHONE_REDACTED]"
        }
    ]
    
    for test_case in pii_prompts:
        print(f"\nüìù Prompt original: {test_case['original']}")
        
        # El gateway deber√≠a sanitizar autom√°ticamente
        response = await ai_gateway.process_interaction(
            session_id=session_id,
            prompt=test_case["original"]
        )
        
        # Verificar que se proces√≥ (aunque hayamos removido PII)
        assert response is not None, "Deber√≠a procesar el prompt"
        
        print(f"‚úÖ PII filtrado correctamente")
        print(f"üîí Patr√≥n esperado: {test_case['should_contain']}")
    
    print(f"\n‚úÖ TEST 2 COMPLETADO: PII filtrado en {len(pii_prompts)} prompts")


# ============================================================================
# TEST 3: AGENTE RIESGO (AR-IA) - Detecci√≥n de C√≥digo Copiado
# ============================================================================

@pytest.mark.asyncio
async def test_risk_agent_detects_suspicious_code(ai_gateway, repositories):
    """
    Verifica que el agente de riesgo detecte c√≥digo enviado muy r√°pido
    (< 5 segundos con > 100 caracteres) como sospechoso
    """
    print("\n" + "="*80)
    print("TEST 3: AGENTE RIESGO - DETECCI√ìN DE C√ìDIGO COPIADO")
    print("="*80)
    
    session_id = ai_gateway.create_session(
        student_id="student_risk_001",
        activity_id="act_test_risk",
        mode="TUTOR"
    )
    
    # Simular: pregunta del estudiante
    await ai_gateway.process_interaction(
        session_id=session_id,
        prompt="¬øC√≥mo implemento una cola circular?"
    )
    
    # Simular: c√≥digo largo enviado muy r√°pido (< 5 segundos)
    # En la pr√°ctica, esto ser√≠a detectado por el timestamp de las trazas
    time.sleep(0.5)  # Solo 0.5 segundos despu√©s
    
    long_code = """
    class ColaCircular:
        def __init__(self, capacity):
            self.capacity = capacity
            self.queue = [None] * capacity
            self.front = 0
            self.rear = -1
            self.size = 0
        
        def enqueue(self, item):
            if self.is_full():
                raise Exception("Cola llena")
            self.rear = (self.rear + 1) % self.capacity
            self.queue[self.rear] = item
            self.size += 1
    """ * 3  # Multiplicar para superar 100 chars
    
    response = await ai_gateway.process_interaction(
        session_id=session_id,
        prompt=long_code
    )
    
    print(f"üìä C√≥digo enviado: {len(long_code)} caracteres")
    print(f"‚úÖ Interacci√≥n procesada")
    
    # El agente de riesgo deber√≠a analizar esto asincr√≥nicamente
    # Para verificar, consultamos los riesgos en BD
    db_session = repositories["session"].db
    from backend.database.models import RiskDB
    
    risks = db_session.query(RiskDB).filter(
        RiskDB.session_id == session_id
    ).all()
    
    print(f"üîç Riesgos detectados: {len(risks)}")
    for risk in risks:
        print(f"   - {risk.risk_type}: {risk.description[:100]}...")
    
    print(f"\n‚úÖ TEST 3 COMPLETADO: Sistema de detecci√≥n de riesgos operativo")


# ============================================================================
# TEST 4: TRAZABILIDAD (TC-N4) - Persistencia Completa
# ============================================================================

@pytest.mark.asyncio
async def test_traceability_n4_persistence(ai_gateway, repositories):
    """
    Verifica que TODAS las interacciones se persistan en BD
    con nivel de trazabilidad N4 (cognitivo)
    """
    print("\n" + "="*80)
    print("TEST 4: TRAZABILIDAD N4 - PERSISTENCIA COMPLETA")
    print("="*80)
    
    session_id = ai_gateway.create_session(
        student_id="student_trace_001",
        activity_id="act_test_trace",
        mode="TUTOR"
    )
    
    # Realizar m√∫ltiples interacciones
    interactions = [
        "¬øQu√© es una cola circular?",
        "¬øCu√°l es la diferencia con una cola normal?",
        "¬øC√≥mo manejo el caso cuando est√° llena?",
    ]
    
    for i, prompt in enumerate(interactions, 1):
        print(f"\nüîÑ Interacci√≥n {i}: {prompt}")
        await ai_gateway.process_interaction(
            session_id=session_id,
            prompt=prompt
        )
    
    # Verificar persistencia en BD
    db_session = repositories["trace"].db
    from backend.database.models import CognitiveTraceDB
    
    traces = db_session.query(CognitiveTraceDB).filter(
        CognitiveTraceDB.session_id == session_id
    ).all()
    
    print(f"\nüìä RESULTADOS DE TRAZABILIDAD:")
    print(f"   Total de trazas persistidas: {len(traces)}")
    
    # Debe haber al menos: prompt + response por cada interacci√≥n
    expected_min = len(interactions) * 2
    assert len(traces) >= expected_min, \
        f"Deber√≠a haber al menos {expected_min} trazas (prompt + response)"
    
    # Verificar niveles de trazabilidad
    n4_traces = [t for t in traces if t.trace_level == TraceLevel.N4_COGNITIVO.value]
    print(f"   Trazas N4 (cognitivo): {len(n4_traces)}")
    
    # Verificar tipos de interacci√≥n
    interaction_types = {}
    for trace in traces:
        t_type = trace.interaction_type
        interaction_types[t_type] = interaction_types.get(t_type, 0) + 1
    
    print(f"   Tipos de interacci√≥n:")
    for t_type, count in interaction_types.items():
        print(f"      - {t_type}: {count}")
    
    print(f"\n‚úÖ TEST 4 COMPLETADO: Trazabilidad N4 funcionando correctamente")


# ============================================================================
# TEST 5: CONCURRENCIA - M√∫ltiples Usuarios Simult√°neos
# ============================================================================

def simulate_user_session(user_id: str, ai_gateway: AIGateway, num_interactions: int = 3) -> Dict[str, Any]:
    """
    Simula una sesi√≥n completa de un usuario
    
    Returns:
        Diccionario con resultados de la sesi√≥n
    """
    print(f"\nüë§ Usuario {user_id} iniciando sesi√≥n...")
    
    # Crear sesi√≥n
    session_id = ai_gateway.create_session(
        student_id=user_id,
        activity_id=f"act_{user_id}",
        mode="TUTOR"
    )
    
    results = {
        "user_id": user_id,
        "session_id": session_id,
        "interactions": [],
        "errors": [],
        "start_time": time.time()
    }
    
    # Realizar interacciones
    prompts = [
        f"Usuario {user_id}: ¬øQu√© es una pila?",
        f"Usuario {user_id}: ¬øC√≥mo implemento push y pop?",
        f"Usuario {user_id}: Dame ejemplos de uso",
    ]
    
    for i, prompt in enumerate(prompts[:num_interactions], 1):
        try:
            # Usar asyncio.run para ejecutar c√≥digo async en thread
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            
            response = loop.run_until_complete(
                ai_gateway.process_interaction(
                    session_id=session_id,
                    prompt=prompt
                )
            )
            
            loop.close()
            
            results["interactions"].append({
                "prompt": prompt,
                "success": True,
                "response_length": len(response.get("response", ""))
            })
            
            print(f"   ‚úÖ Interacci√≥n {i}/{num_interactions} completada")
            
        except Exception as e:
            results["errors"].append(str(e))
            print(f"   ‚ùå Error en interacci√≥n {i}: {e}")
    
    results["end_time"] = time.time()
    results["duration"] = results["end_time"] - results["start_time"]
    
    return results


@pytest.mark.asyncio
async def test_concurrent_users(ai_gateway, repositories):
    """
    Prueba el sistema con m√∫ltiples usuarios concurrentes
    para validar que el gateway STATELESS funcione correctamente
    """
    print("\n" + "="*80)
    print("TEST 5: CONCURRENCIA - M√öLTIPLES USUARIOS SIMULT√ÅNEOS")
    print("="*80)
    
    num_users = 5
    interactions_per_user = 3
    
    print(f"\nüöÄ Simulando {num_users} usuarios concurrentes")
    print(f"üìä Cada usuario realizar√° {interactions_per_user} interacciones")
    
    # Ejecutar usuarios en paralelo
    with ThreadPoolExecutor(max_workers=num_users) as executor:
        futures = {
            executor.submit(
                simulate_user_session, 
                f"concurrent_user_{i:03d}", 
                ai_gateway, 
                interactions_per_user
            ): f"concurrent_user_{i:03d}"
            for i in range(1, num_users + 1)
        }
        
        results = []
        for future in as_completed(futures):
            user_id = futures[future]
            try:
                result = future.result(timeout=60)
                results.append(result)
                print(f"‚úÖ {user_id} completado en {result['duration']:.2f}s")
            except Exception as e:
                print(f"‚ùå {user_id} fall√≥: {e}")
    
    # An√°lisis de resultados
    print(f"\nüìä RESULTADOS DE CONCURRENCIA:")
    print(f"   Usuarios exitosos: {len(results)}/{num_users}")
    
    total_interactions = sum(len(r["interactions"]) for r in results)
    total_errors = sum(len(r["errors"]) for r in results)
    avg_duration = sum(r["duration"] for r in results) / len(results) if results else 0
    
    print(f"   Total de interacciones: {total_interactions}")
    print(f"   Errores totales: {total_errors}")
    print(f"   Duraci√≥n promedio por usuario: {avg_duration:.2f}s")
    
    # Verificar que todas las sesiones fueron creadas en BD
    db_session = repositories["session"].db
    from backend.database.models import Session as SessionDB
    
    sessions = db_session.query(SessionDB).filter(
        SessionDB.student_id.like("concurrent_user_%")
    ).all()
    
    print(f"   Sesiones en BD: {len(sessions)}")
    
    # Verificaciones
    assert len(results) == num_users, "Todos los usuarios deber√≠an completar"
    assert total_errors == 0, "No deber√≠a haber errores en condiciones normales"
    assert len(sessions) == num_users, "Todas las sesiones deber√≠an persistir en BD"
    
    print(f"\n‚úÖ TEST 5 COMPLETADO: Sistema soporta {num_users} usuarios concurrentes")


# ============================================================================
# TEST 6: FLUJO COMPLETO E2E - Usuario Real
# ============================================================================

@pytest.mark.asyncio
async def test_complete_e2e_flow(ai_gateway, repositories):
    """
    Simula un flujo completo de un estudiante real:
    1. Crea sesi√≥n
    2. Intenta delegar (bloqueado)
    3. Reformula y recibe ayuda
    4. Env√≠a c√≥digo (detectado riesgo si es muy r√°pido)
    5. Verifica trazabilidad completa
    """
    print("\n" + "="*80)
    print("TEST 6: FLUJO COMPLETO E2E - SIMULACI√ìN USUARIO REAL")
    print("="*80)
    
    # PASO 1: Estudiante inicia sesi√≥n
    print("\nüìù PASO 1: Crear sesi√≥n")
    session_id = ai_gateway.create_session(
        student_id="alumno_realista_001",
        activity_id="act_algoritmos_avanzados",
        mode="TUTOR"
    )
    print(f"‚úÖ Sesi√≥n creada: {session_id}")
    
    # PASO 2: Intenta delegar (DEBE SER BLOQUEADO)
    print("\nüìù PASO 2: Intento de delegaci√≥n total")
    response_blocked = await ai_gateway.process_interaction(
        session_id=session_id,
        prompt="Dame el c√≥digo completo de un √°rbol AVL con todas las rotaciones"
    )
    
    assert response_blocked.get("blocked") == True, "Deber√≠a bloquear delegaci√≥n"
    print(f"‚úÖ Delegaci√≥n bloqueada correctamente")
    print(f"üìã Respuesta: {response_blocked.get('response')[:200]}...")
    
    # PASO 3: Reformula con pregunta conceptual
    print("\nüìù PASO 3: Pregunta conceptual v√°lida")
    response_conceptual = await ai_gateway.process_interaction(
        session_id=session_id,
        prompt="¬øQu√© diferencia hay entre un √°rbol AVL y un √°rbol binario de b√∫squeda normal?"
    )
    
    assert response_conceptual.get("blocked") != True, "No deber√≠a bloquear pregunta conceptual"
    print(f"‚úÖ Pregunta procesada correctamente")
    print(f"üìã Respuesta: {response_conceptual.get('response')[:200]}...")
    
    # PASO 4: Pregunta sobre implementaci√≥n
    print("\nüìù PASO 4: Pregunta sobre implementaci√≥n")
    response_impl = await ai_gateway.process_interaction(
        session_id=session_id,
        prompt="¬øC√≥mo calculo el factor de balance en un nodo?"
    )
    
    print(f"‚úÖ Pregunta procesada")
    
    # PASO 5: Env√≠o de c√≥digo (simular r√°pido para detectar riesgo)
    print("\nüìù PASO 5: Env√≠o de c√≥digo sospechosamente r√°pido")
    time.sleep(0.3)  # Muy r√°pido
    
    code_snippet = """
    def calcular_balance(nodo):
        if nodo is None:
            return 0
        return altura(nodo.izq) - altura(nodo.der)
    
    def altura(nodo):
        if nodo is None:
            return 0
        return 1 + max(altura(nodo.izq), altura(nodo.der))
    """ * 5  # Hacer m√°s largo
    
    response_code = await ai_gateway.process_interaction(
        session_id=session_id,
        prompt=code_snippet
    )
    
    print(f"‚úÖ C√≥digo procesado ({len(code_snippet)} caracteres)")
    
    # PASO 6: Verificar trazabilidad completa
    print("\nüìù PASO 6: Verificar trazabilidad N4")
    
    db_session = repositories["trace"].db
    from backend.database.models import CognitiveTraceDB
    
    traces = db_session.query(CognitiveTraceDB).filter(
        CognitiveTraceDB.session_id == session_id
    ).order_by(CognitiveTraceDB.created_at).all()
    
    print(f"\nüìä TRAZAS CAPTURADAS:")
    for i, trace in enumerate(traces, 1):
        print(f"   {i}. {trace.interaction_type} - {trace.trace_level} - {trace.content[:50]}...")
    
    # PASO 7: Verificar riesgos detectados
    print("\nüìù PASO 7: Verificar detecci√≥n de riesgos")
    
    from backend.database.models import RiskDB
    risks = db_session.query(RiskDB).filter(
        RiskDB.session_id == session_id
    ).all()
    
    print(f"\nüö® RIESGOS DETECTADOS: {len(risks)}")
    for risk in risks:
        print(f"   - {risk.risk_type} ({risk.risk_level})")
        print(f"     {risk.description[:100]}...")
    
    # Resumen final
    print(f"\n" + "="*80)
    print(f"‚úÖ FLUJO E2E COMPLETADO EXITOSAMENTE")
    print(f"="*80)
    print(f"üìä Estad√≠sticas:")
    print(f"   - Interacciones totales: 5")
    print(f"   - Trazas capturadas: {len(traces)}")
    print(f"   - Riesgos detectados: {len(risks)}")
    print(f"   - Delegaciones bloqueadas: 1")
    print(f"   - PII filtrados: 0")
    print(f"="*80)


# ============================================================================
# TEST 7: VALIDACI√ìN DE TODOS LOS AGENTES
# ============================================================================

@pytest.mark.asyncio
async def test_all_agents_operational(ai_gateway, repositories):
    """
    Verifica que todos los agentes est√©n operativos:
    - T-IA-Cog (Tutor)
    - E-IA-Proc (Evaluador)
    - AR-IA (Riesgo)
    - GOV-IA (Gobernanza)
    - TC-N4 (Trazabilidad)
    """
    print("\n" + "="*80)
    print("TEST 7: VALIDACI√ìN DE TODOS LOS AGENTES")
    print("="*80)
    
    agents_status = {
        "T-IA-Cog (Tutor)": False,
        "E-IA-Proc (Evaluador)": False,
        "AR-IA (Riesgo)": False,
        "GOV-IA (Gobernanza)": False,
        "TC-N4 (Trazabilidad)": False,
    }
    
    session_id = ai_gateway.create_session(
        student_id="test_all_agents",
        activity_id="act_validation",
        mode="TUTOR"
    )
    
    # Test T-IA-Cog
    try:
        response = await ai_gateway.process_interaction(
            session_id=session_id,
            prompt="Dame el c√≥digo completo de una cola circular"
        )
        if response.get("blocked"):
            agents_status["T-IA-Cog (Tutor)"] = True
            print("‚úÖ T-IA-Cog: Operativo (bloqueo de delegaci√≥n funciona)")
        else:
            print(f"‚ùå T-IA-Cog: No bloque√≥ delegaci√≥n - blocked={response.get('blocked')}")
    except Exception as e:
        print(f"‚ùå T-IA-Cog: Error - {e}")
    
    # Test GOV-IA
    try:
        sanitized, pii_found = ai_gateway.governance_agent.sanitize_prompt(
            "Mi email es test@example.com y mi DNI es 12345678"
        )
        if pii_found and "[EMAIL_REDACTED]" in sanitized and "[DNI_REDACTED]" in sanitized:
            agents_status["GOV-IA (Gobernanza)"] = True
            print("‚úÖ GOV-IA: Operativo (filtro PII funciona)")
    except Exception as e:
        print(f"‚ùå GOV-IA: Error - {e}")
    
    # Test TC-N4
    try:
        db_session = repositories["trace"].db
        from backend.database.models import CognitiveTraceDB
        traces = db_session.query(CognitiveTraceDB).filter(
            CognitiveTraceDB.session_id == session_id
        ).all()
        if len(traces) > 0:
            agents_status["TC-N4 (Trazabilidad)"] = True
            print(f"‚úÖ TC-N4: Operativo ({len(traces)} trazas persistidas)")
    except Exception as e:
        print(f"‚ùå TC-N4: Error - {e}")
    
    # Test AR-IA (indirectamente a trav√©s de an√°lisis)
    try:
        # El agente de riesgo funciona si puede analizar una secuencia
        from backend.agents.risk_analyst import AnalistaRiesgoAgent
        risk_agent = AnalistaRiesgoAgent()
        agents_status["AR-IA (Riesgo)"] = True
        print("‚úÖ AR-IA: Operativo (agente instanciado)")
    except Exception as e:
        print(f"‚ùå AR-IA: Error - {e}")
    
    # Test E-IA-Proc
    try:
        from backend.agents.evaluator import EvaluadorProcesosAgent
        evaluator = EvaluadorProcesosAgent()
        agents_status["E-IA-Proc (Evaluador)"] = True
        print("‚úÖ E-IA-Proc: Operativo (agente instanciado)")
    except Exception as e:
        print(f"‚ùå E-IA-Proc: Error - {e}")
    
    # Resumen
    print(f"\nüìä ESTADO DE AGENTES:")
    operational = sum(1 for status in agents_status.values() if status)
    total = len(agents_status)
    
    for agent, status in agents_status.items():
        symbol = "‚úÖ" if status else "‚ùå"
        print(f"   {symbol} {agent}")
    
    print(f"\nüéØ RESULTADO: {operational}/{total} agentes operativos")
    
    assert operational == total, f"Todos los agentes deber√≠an estar operativos ({operational}/{total})"
    
    print(f"\n‚úÖ TEST 7 COMPLETADO: Todos los agentes validados")


# ============================================================================
# EJECUTAR TODOS LOS TESTS
# ============================================================================

if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s", "--log-cli-level=INFO"])
