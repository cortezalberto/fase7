# Implementaci√≥n de la Integraci√≥n del Entrenador Digital

## Gu√≠a de Implementaci√≥n en Prosa

Este documento describe en detalle c√≥mo implementar cada fase de la integraci√≥n del Entrenador Digital con el ecosistema de agentes de IA. A diferencia del documento t√©cnico de propuesta, aqu√≠ explicamos el **por qu√©** y el **c√≥mo** de cada decisi√≥n de implementaci√≥n, con el objetivo de que cualquier desarrollador pueda comprender la l√≥gica detr√°s de cada componente.

---

## Fase 1: Construcci√≥n de la Infraestructura Base

### El TrainingGateway: El Nuevo Orquestador

La primera pieza que debemos construir es el `TrainingGateway`, un componente que act√∫a como intermediario entre los endpoints del Entrenador Digital y el ecosistema de agentes. Actualmente, cuando un estudiante env√≠a c√≥digo o solicita una pista, la solicitud va directamente al `CodeEvaluator` o a la base de datos de pistas. Con el gateway, todas las solicitudes pasar√°n primero por un punto central que decidir√° qu√© agentes involucrar.

El gateway no reemplaza la l√≥gica existente; la envuelve. Pensemos en √©l como un decorador arquitect√≥nico: el c√≥digo actual sigue funcionando exactamente igual, pero ahora tiene la capacidad de invocar servicios adicionales antes y despu√©s de su ejecuci√≥n principal.

La implementaci√≥n del gateway debe seguir el principio de **responsabilidad √∫nica**: su √∫nico trabajo es decidir qu√© componentes invocar y en qu√© orden. No debe contener l√≥gica de negocio del entrenamiento, ni l√≥gica de los agentes. Solo orquesta.

```
Solicitud ‚Üí TrainingGateway ‚Üí [¬øQu√© necesita esta solicitud?]
                                    ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚ñº               ‚ñº               ‚ñº
              ¬øTrazabilidad?  ¬øAn√°lisis de    ¬øPista
                              riesgos?        contextual?
                    ‚îÇ               ‚îÇ               ‚îÇ
                    ‚ñº               ‚ñº               ‚ñº
               TC-N4 Agent    AR-IA Agent    T-IA-Cog
```

Para implementar esto, creamos una clase `TrainingGateway` en `backend/core/training_gateway.py`. Esta clase recibe las dependencias necesarias (agentes, repositorios) mediante inyecci√≥n de dependencias, siguiendo el patr√≥n que ya usa el sistema con `get_llm_provider` y `get_db`.

El gateway expone m√©todos como `process_code_submission`, `process_hint_request` y `process_session_start`. Cada m√©todo encapsula la l√≥gica de orquestaci√≥n espec√≠fica para ese tipo de operaci√≥n. Internamente, estos m√©todos invocan a los agentes de forma as√≠ncrona cuando es apropiado, permitiendo que operaciones independientes (como registrar una traza y analizar riesgos) ocurran en paralelo.

### El TrainingTraceCollector: Capturando el Proceso

El segundo componente fundamental es el `TrainingTraceCollector`, responsable de traducir los eventos del Entrenador Digital al modelo de trazabilidad N4 del sistema. Este componente entiende que un "intento de c√≥digo" en el contexto de entrenamiento equivale a una traza cognitiva con ciertos atributos inferidos.

La dificultad principal aqu√≠ es que el Entrenador Digital no tiene acceso expl√≠cito al razonamiento del estudiante. Mientras que en el Modo Tutor el estudiante escribe "estoy pensando en usar una lista porque..." y eso se convierte directamente en una traza, en el Entrenador Digital solo tenemos el c√≥digo enviado y el resultado de los tests.

El collector implementa una serie de heur√≠sticas para inferir el estado cognitivo. Por ejemplo:

- Si es el primer intento y el c√≥digo es similar al c√≥digo inicial proporcionado, inferimos estado de **exploraci√≥n**.
- Si el c√≥digo cambi√≥ significativamente respecto al intento anterior, inferimos **cambio de estrategia**.
- Si el c√≥digo tiene cambios m√≠nimos y el error anterior era de sintaxis, inferimos **depuraci√≥n**.
- Si todos los tests pasan, inferimos **validaci√≥n exitosa**.

Estas inferencias no son perfectas, y por eso las marcamos con un nivel de confianza. Una traza inferida con confianza "media" indica que el sistema hizo su mejor estimaci√≥n pero podr√≠a estar equivocado. Esto es importante para los an√°lisis posteriores: no queremos tomar decisiones pedag√≥gicas cr√≠ticas basadas en inferencias de baja confianza.

El collector se implementa como un servicio stateless que recibe el contexto necesario en cada llamada. No mantiene estado entre invocaciones porque el estado ya est√° persistido en la base de datos y en Redis. Esto permite escalar horizontalmente sin preocuparnos por sincronizaci√≥n.

### El TrainingRiskMonitor: Vigilancia en Tiempo Real

El tercer componente de la infraestructura base es el `TrainingRiskMonitor`, una versi√≥n especializada del agente AR-IA adaptada al contexto de ejercicios estructurados. Mientras que AR-IA analiza sesiones completas de tutor√≠a buscando patrones complejos de delegaci√≥n cognitiva, el monitor de entrenamiento se enfoca en se√±ales m√°s inmediatas y accionables.

Las se√±ales que el monitor busca incluyen:

**Detecci√≥n de copy-paste**: Si un estudiante env√≠a 200 caracteres de c√≥digo 3 segundos despu√©s de su √∫ltimo intento (que fall√≥ completamente), es f√≠sicamente imposible que haya escrito ese c√≥digo. El monitor calcula la velocidad de escritura impl√≠cita y la compara con umbrales humanamente posibles. Cuando detecta una anomal√≠a, no bloquea al estudiante pero registra una alerta que el docente puede revisar.

**Patrones de frustraci√≥n**: Cinco intentos fallidos en dos minutos, todos con errores diferentes, sugieren que el estudiante est√° probando cosas al azar sin entender el problema. El monitor puede sugerir proactivamente una pista o incluso cambiar autom√°ticamente a un ejercicio m√°s simple si las pol√≠ticas de la actividad lo permiten.

**Dependencia de pistas**: Si el estudiante solicita pista antes de cada intento, est√° usando las pistas como muleta en lugar de como andamiaje. El monitor puede reducir gradualmente el nivel de detalle de las pistas para forzar m√°s autonom√≠a.

La implementaci√≥n del monitor sigue el patr√≥n Observer: se suscribe a eventos del gateway y reacciona a ellos. Esto desacopla la l√≥gica de detecci√≥n de la l√≥gica de entrenamiento principal, permitiendo agregar nuevos detectores sin modificar el c√≥digo existente.

### Extensi√≥n de los Modelos de Datos

Para soportar la nueva funcionalidad, necesitamos extender los modelos existentes sin romper la compatibilidad hacia atr√°s. Esto significa agregar campos opcionales con valores por defecto sensatos.

En el modelo `ExerciseAttemptDB`, agregamos:
- `trace_id`: Referencia a la traza N4 correspondiente (nullable, porque los intentos anteriores no tendr√°n traza)
- `cognitive_state_inferred`: El estado cognitivo que el sistema infiri√≥ (nullable)
- `inference_confidence`: Qu√© tan seguro est√° el sistema de su inferencia (float, 0-1)
- `risk_flags`: JSON con cualquier alerta de riesgo detectada (nullable)

En el esquema `SesionEntrenamiento`, agregamos campos para tracking de trazabilidad que se mantienen en Redis junto con el resto de la sesi√≥n:
- `trace_sequence_id`: ID de la secuencia N4 que agrupa todas las trazas de esta sesi√≥n
- `cumulative_ai_involvement`: Score acumulado de cu√°nta ayuda de IA ha recibido
- `risk_alerts`: Lista de alertas activas

Estos campos se agregan mediante una migraci√≥n de base de datos que usa `ALTER TABLE ... ADD COLUMN ... DEFAULT NULL`, garantizando que el sistema siga funcionando durante y despu√©s de la migraci√≥n.

---

## Fase 2: Integraci√≥n con el Tutor Cognitivo

### La Estrategia de Pistas Contextuales

Una vez que la infraestructura base est√° en su lugar, podemos abordar la integraci√≥n m√°s significativa: hacer que el Tutor Cognitivo (T-IA-Cog) genere las pistas en lugar de usar texto est√°tico de la base de datos.

Creamos una nueva estrategia llamada `TrainingHintsStrategy` que extiende la estrategia `GuidedStrategy` existente. Esta nueva estrategia entiende el contexto espec√≠fico de los ejercicios de entrenamiento:

- Conoce la consigna del ejercicio y los conceptos que se est√°n practicando
- Tiene acceso al historial de intentos del estudiante (qu√© c√≥digo envi√≥, qu√© errores tuvo)
- Sabe cu√°ntas pistas ya recibi√≥ y de qu√© nivel
- Puede ver el error espec√≠fico del √∫ltimo intento

Con este contexto, la estrategia puede generar pistas verdaderamente personalizadas. Si un estudiante tiene un error de √≠ndice fuera de rango, la pista no ser√° gen√©rica ("revisa los l√≠mites de tus bucles") sino espec√≠fica al c√≥digo que escribi√≥ ("en la l√≠nea donde accedes a `lista[i]`, ¬øqu√© valores puede tomar `i`? ¬øQu√© pasa cuando `i` es igual al largo de la lista?").

La implementaci√≥n requiere construir un "prompt impl√≠cito" que represente lo que el estudiante est√° preguntando al solicitar una pista. El estudiante no escribe una pregunta textual; simplemente hace clic en "Pedir pista". Pero podemos inferir su pregunta impl√≠cita:

```python
def _build_implicit_prompt(self, exercise, last_error, attempt_count):
    if last_error and "SyntaxError" in last_error:
        return f"Tengo un error de sintaxis en mi c√≥digo para {exercise.title}. El error dice: {last_error}. ¬øQu√© estoy haciendo mal?"
    elif attempt_count > 3:
        return f"Llevo {attempt_count} intentos en {exercise.title} y sigo sin lograrlo. Necesito orientaci√≥n sobre el enfoque general."
    else:
        return f"Estoy trabajando en {exercise.title} y no s√© c√≥mo continuar."
```

Este prompt impl√≠cito se pasa al motor de generaci√≥n del tutor, que aplica las mismas reglas pedag√≥gicas que aplicar√≠a en una conversaci√≥n normal: no dar c√≥digo completo, priorizar preguntas sobre respuestas, exigir justificaci√≥n antes de dar m√°s ayuda.

### El Endpoint Mejorado de Pistas

Implementamos un nuevo endpoint `/pista/v2` que usa la estrategia contextual. El endpoint original `/pista` sigue funcionando exactamente igual para mantener compatibilidad con clientes existentes.

El nuevo endpoint tiene esta l√≥gica:

1. Verificar que la sesi√≥n existe y pertenece al usuario
2. Obtener el ejercicio actual y el historial de intentos
3. Decidir si usar T-IA-Cog o fallback a pista est√°tica
4. Si hay intentos previos y el LLM est√° disponible, usar T-IA-Cog
5. Si no, usar la pista est√°tica de la base de datos
6. Registrar una traza N4 de la solicitud de pista
7. Actualizar el contador de pistas usadas
8. Retornar la respuesta enriquecida con metadata

La decisi√≥n de cu√°ndo usar T-IA-Cog y cu√°ndo usar fallback es importante. Usamos la pista contextual cuando:
- El estudiante tiene al menos un intento previo (hay contexto para personalizar)
- El proveedor LLM est√° disponible y respondiendo
- La latencia del LLM est√° dentro de l√≠mites aceptables (< 3 segundos)

Si alguna de estas condiciones falla, caemos elegantemente a la pista est√°tica. El estudiante siempre recibe una pista; solo cambia qu√© tan personalizada es.

### Templates de Prompts para Ejercicios

Para que el tutor genere buenas pistas, necesita instrucciones espec√≠ficas sobre c√≥mo actuar en el contexto de ejercicios. Creamos un archivo `backend/prompts/training_hints.md` con el system prompt especializado:

```markdown
# Rol: Tutor de Programaci√≥n para Ejercicios Pr√°cticos

Est√°s ayudando a un estudiante que trabaja en un ejercicio de programaci√≥n estructurado.
Tu rol es dar pistas que gu√≠en sin resolver el problema.

## Contexto del Ejercicio
- T√≠tulo: {{exercise_title}}
- Objetivo de aprendizaje: {{learning_objectives}}
- Restricciones: {{constraints}}

## Estado del Estudiante
- Intentos realizados: {{attempt_count}}
- √öltimo error (si hay): {{last_error}}
- Pistas ya recibidas: {{hints_used}}

## Reglas Inquebrantables
1. NUNCA des c√≥digo que el estudiante pueda copiar directamente
2. Responde con preguntas que lo hagan pensar
3. Si das un ejemplo, que sea de un dominio diferente
4. Aumenta el detalle gradualmente seg√∫n el nivel de pista solicitado

## Nivel de Pista Solicitado: {{hint_level}}
- Nivel 1: Solo preguntas orientadoras
- Nivel 2: Pistas conceptuales generales
- Nivel 3: Estrategia m√°s espec√≠fica, pseudoc√≥digo de alto nivel
- Nivel 4: Orientaci√≥n detallada sin c√≥digo ejecutable
```

Este template se completa din√°micamente con el contexto del ejercicio y del estudiante antes de enviarse al LLM.

---

## Fase 3: Implementaci√≥n de la Trazabilidad N4

### Integraci√≥n en el Flujo de Inicio de Sesi√≥n

Cuando un estudiante inicia una sesi√≥n de entrenamiento (llama a `/training/iniciar`), ahora tambi√©n creamos una secuencia de trazas N4. Esta secuencia agrupar√° todas las trazas generadas durante la sesi√≥n, permitiendo reconstruir el proceso completo posteriormente.

La integraci√≥n es sutil: agregamos una llamada al `TrainingTraceCollector` despu√©s de crear la sesi√≥n pero antes de retornar la respuesta. Si la creaci√≥n de la traza falla (por ejemplo, si la base de datos de trazas est√° temporalmente inaccesible), logueamos el error pero no fallamos la operaci√≥n principal. La trazabilidad es valiosa pero no cr√≠tica para la funcionalidad b√°sica del entrenamiento.

```python
async def iniciar_entrenamiento(request, db, current_user):
    # L√≥gica existente de creaci√≥n de sesi√≥n...
    sesion_data = crear_sesion(...)
    guardar_sesion(session_id, sesion_data)

    # NUEVO: Crear secuencia de trazas
    try:
        trace_sequence = await trace_collector.create_sequence(
            student_id=str(current_user.id),
            session_id=session_id,
            activity_type="training",
            exercise_ids=[e['id'] for e in ejercicios_preparados]
        )
        sesion_data['trace_sequence_id'] = trace_sequence.id
        guardar_sesion(session_id, sesion_data)
    except Exception as e:
        logger.warning(f"No se pudo crear secuencia de trazas: {e}")
        # Continuamos sin trazabilidad

    return SesionEntrenamiento(...)
```

### Integraci√≥n en el Flujo de Env√≠o de C√≥digo

El punto m√°s importante de captura es cuando el estudiante env√≠a c√≥digo. Aqu√≠ es donde ocurre el "trabajo cognitivo" principal, y donde podemos inferir m√°s informaci√≥n sobre el proceso del estudiante.

Despu√©s de ejecutar los tests pero antes de retornar el resultado, capturamos una traza:

```python
async def submit_ejercicio(request, db, current_user, llm_provider):
    # L√≥gica existente de ejecuci√≥n de tests...
    sandbox_result = ejecutar_tests(codigo, tests)

    # L√≥gica existente de evaluaci√≥n con Alex...
    evaluation = await code_evaluator.evaluate(...)

    # NUEVO: Capturar traza del intento
    sesion = obtener_sesion(request.session_id)
    attempt_number = len(sesion.get('resultados', [])) + 1

    cognitive_trace = await trace_collector.trace_code_attempt(
        session_id=request.session_id,
        student_id=str(current_user.id),
        exercise_id=ejercicio_actual['id'],
        code=request.codigo,
        result=sandbox_result,
        attempt_number=attempt_number,
        previous_code=sesion.get('ultimo_codigo'),
        time_since_last=calcular_tiempo_desde_ultimo(sesion)
    )

    # Guardar referencia a la traza en el resultado
    resultado = ResultadoEjercicio(
        ...,
        trace_id=cognitive_trace.id
    )

    # NUEVO: Actualizar √∫ltimo c√≥digo para comparaci√≥n futura
    sesion['ultimo_codigo'] = request.codigo
    sesion['ultimo_intento_timestamp'] = datetime.now().isoformat()
    guardar_sesion(request.session_id, sesion)

    return resultado
```

El collector analiza el c√≥digo enviado compar√°ndolo con el c√≥digo anterior (si existe) para inferir qu√© tipo de cambio hizo el estudiante: ¬øagreg√≥ c√≥digo nuevo? ¬ømodific√≥ c√≥digo existente? ¬øelimin√≥ c√≥digo? ¬øel cambio fue peque√±o (typo fix) o grande (reestructuraci√≥n)?

### El Endpoint de An√°lisis de Proceso

Para que la trazabilidad sea √∫til, necesitamos exponerla. Creamos un nuevo endpoint `/training/sesion/{id}/proceso` que retorna un an√°lisis del proceso de resoluci√≥n:

```python
@router.get("/sesion/{session_id}/proceso")
async def obtener_analisis_proceso(session_id: str, db, current_user):
    # Verificar permisos
    sesion = obtener_sesion(session_id)
    if sesion['user_id'] != current_user.id and not es_docente(current_user):
        raise HTTPException(403, "No autorizado")

    # Obtener trazas de la sesi√≥n
    traces = trace_repo.get_by_session(session_id)

    # Reconstruir camino cognitivo
    cognitive_path = reconstruir_camino(traces)

    # Calcular m√©tricas
    metrics = calcular_metricas_proceso(traces)

    return ProcesoEntrenamientoReport(
        session_id=session_id,
        cognitive_path=cognitive_path,
        total_attempts=metrics.total_attempts,
        total_hints_used=metrics.hints_used,
        time_to_first_success=metrics.time_to_success,
        autonomy_score=metrics.autonomy_score,
        strategy_changes=metrics.strategy_changes,
        recommendations=generar_recomendaciones(metrics)
    )
```

Este endpoint es √∫til tanto para el estudiante (para reflexionar sobre su proceso) como para el docente (para entender c√≥mo sus estudiantes abordan los ejercicios).

### Dashboard de Proceso en el Frontend

La trazabilidad no sirve de nada si no se visualiza. Creamos un componente de frontend que muestra el proceso de resoluci√≥n de forma visual:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Tu Proceso de Resoluci√≥n                                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚è±Ô∏è Tiempo total: 12 minutos                                ‚îÇ
‚îÇ  üìù Intentos: 5                                             ‚îÇ
‚îÇ  üí° Pistas usadas: 2                                        ‚îÇ
‚îÇ  üéØ Autonom√≠a: 72%                                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  L√≠nea de tiempo:                                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ üîç ‚îÄ‚îÄ‚ñ∂ üíª ‚îÄ‚îÄ‚ñ∂ üíª ‚îÄ‚îÄ‚ñ∂ üí° ‚îÄ‚îÄ‚ñ∂ üíª ‚îÄ‚îÄ‚ñ∂ üêõ ‚îÄ‚îÄ‚ñ∂ ‚úÖ          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ exp    impl   impl   pista  impl   debug  √©xito      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Observaciones:                                             ‚îÇ
‚îÇ  ‚Ä¢ Buen progreso incremental                                ‚îÇ
‚îÇ  ‚Ä¢ Solicitaste pista en momento apropiado                   ‚îÇ
‚îÇ  ‚Ä¢ Corregiste el error r√°pidamente despu√©s de la pista      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Este dashboard usa iconos y una l√≠nea de tiempo para representar visualmente el camino cognitivo, haciendo tangible algo que normalmente es invisible.

---

## Fase 4: Integraci√≥n del An√°lisis de Riesgos

### Monitoreo en Tiempo Real Durante Submit

En la fase final, conectamos el `TrainingRiskMonitor` al flujo de env√≠o de c√≥digo. El monitor analiza cada intento buscando se√±ales de alerta:

```python
async def submit_ejercicio(request, db, current_user, llm_provider):
    # ... l√≥gica existente ...

    # NUEVO: An√°lisis de riesgos
    risk_alerts = await risk_monitor.analyze_attempt(
        student_id=str(current_user.id),
        exercise_id=ejercicio_actual['id'],
        code=request.codigo,
        time_since_last=calcular_tiempo_desde_ultimo(sesion),
        attempt_history=obtener_historial_intentos(sesion)
    )

    # Si hay alertas de alta severidad, agregarlas a la respuesta
    if any(r.severity == 'high' for r in risk_alerts):
        resultado.warnings = [r.message for r in risk_alerts if r.severity == 'high']

    # Persistir alertas para revisi√≥n posterior
    for alert in risk_alerts:
        await risk_repo.create(alert)

    return resultado
```

Las alertas de baja severidad se registran silenciosamente para an√°lisis posterior. Las de alta severidad pueden mostrarse al estudiante (de forma pedag√≥gica, no punitiva) o notificarse al docente en tiempo real.

### Alertas para Docentes

Implementamos un sistema de notificaciones WebSocket que permite a los docentes ver alertas en tiempo real mientras sus estudiantes trabajan:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Panel del Docente - Alertas en Vivo                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  üî¥ Juan P√©rez (hace 2 min)                                 ‚îÇ
‚îÇ     Posible copy-paste: 180 caracteres en 2 segundos        ‚îÇ
‚îÇ     Ejercicio: U1-VAR-03                                    ‚îÇ
‚îÇ     [Ver detalle] [Contactar]                               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  üü° Mar√≠a Garc√≠a (hace 5 min)                               ‚îÇ
‚îÇ     Frustraci√≥n detectada: 6 intentos fallidos consecutivos ‚îÇ
‚îÇ     Ejercicio: U2-COND-01                                   ‚îÇ
‚îÇ     [Ver detalle] [Ofrecer ayuda]                           ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  üü¢ Sin alertas recientes para los dem√°s estudiantes        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

El docente puede hacer clic en "Ver detalle" para ver el c√≥digo del estudiante y el historial de intentos, permiti√©ndole intervenir de forma informada si lo considera necesario.

### Reportes Agregados

Adem√°s del monitoreo en tiempo real, generamos reportes agregados que muestran patrones a nivel de curso:

```python
@router.get("/teacher/reports/training-risks")
async def obtener_reporte_riesgos(course_id: str, date_range: str, db, current_user):
    require_teacher_role(current_user)

    # Obtener todos los riesgos del per√≠odo
    risks = risk_repo.get_by_course_and_period(course_id, date_range)

    # Agregar por tipo
    risk_summary = agregar_por_tipo(risks)

    # Identificar estudiantes con patrones recurrentes
    recurring_patterns = identificar_patrones_recurrentes(risks)

    return TrainingRiskReport(
        period=date_range,
        total_sessions=contar_sesiones(course_id, date_range),
        risk_summary=risk_summary,
        students_of_concern=recurring_patterns,
        recommendations=generar_recomendaciones_curso(risk_summary)
    )
```

Este reporte ayuda al docente a identificar si hay problemas sist√©micos (por ejemplo, un ejercicio que genera mucha frustraci√≥n en muchos estudiantes podr√≠a indicar que est√° mal dise√±ado) o problemas individuales que requieren atenci√≥n personalizada.

---

## Consideraciones de Implementaci√≥n

### Feature Flags y Migraci√≥n Gradual

Toda la nueva funcionalidad se implementa detr√°s de feature flags, permitiendo activarla gradualmente:

```python
TRAINING_FEATURES = {
    "use_tutor_hints": os.getenv("TRAINING_USE_TUTOR_HINTS", "false") == "true",
    "enable_n4_tracing": os.getenv("TRAINING_N4_TRACING", "false") == "true",
    "enable_risk_monitor": os.getenv("TRAINING_RISK_MONITOR", "false") == "true",
}
```

La migraci√≥n recomendada es:
1. **Semanas 1-2**: Desplegar c√≥digo con flags desactivados. Verificar que nada se rompe.
2. **Semanas 3-4**: Activar `enable_n4_tracing` en staging. Verificar que las trazas se generan correctamente y no afectan la performance.
3. **Semanas 5-6**: Activar `use_tutor_hints` en staging. Medir latencia y calidad de las pistas generadas.
4. **Semanas 7-8**: Activar todo en producci√≥n con monitoreo intensivo.

### Manejo de Errores y Fallbacks

Cada integraci√≥n tiene un fallback robusto:
- Si T-IA-Cog falla ‚Üí Usamos pista est√°tica
- Si el TraceCollector falla ‚Üí Continuamos sin trazas (logueamos error)
- Si el RiskMonitor falla ‚Üí Continuamos sin an√°lisis de riesgos
- Si todo falla ‚Üí El entrenamiento b√°sico sigue funcionando como antes

Esto garantiza que los estudiantes nunca se queden sin poder practicar, incluso si hay problemas con los componentes nuevos.

### Performance y Escalabilidad

Las nuevas operaciones agregan latencia. Para mantenerla bajo control:
- Las trazas se escriben de forma as√≠ncrona (fire-and-forget con callback de error)
- El an√°lisis de riesgos usa cach√© para umbrales y configuraci√≥n
- Las pistas contextuales tienen timeout de 3 segundos; si el LLM tarda m√°s, usamos fallback
- Las consultas a la base de datos de trazas usan √≠ndices optimizados

Con estas optimizaciones, el overhead esperado es:
- `/iniciar`: +50ms (creaci√≥n de secuencia de trazas)
- `/submit-ejercicio`: +100ms (traza + an√°lisis de riesgos en paralelo)
- `/pista`: +0-2000ms (dependiendo de si usa LLM o fallback)

---

## Conclusi√≥n

La implementaci√≥n de estas cuatro fases transforma el Entrenador Digital de un m√≥dulo aislado a un componente integrado del ecosistema AI-Native. Cada fase construye sobre la anterior:

1. **Infraestructura** establece los cimientos y las abstracciones
2. **Integraci√≥n con T-IA-Cog** aporta inteligencia pedag√≥gica a las pistas
3. **Trazabilidad N4** hace visible el proceso cognitivo
4. **An√°lisis de riesgos** habilita intervenci√≥n temprana

El resultado es un Entrenador Digital que no solo eval√∫a si el c√≥digo funciona, sino que tambi√©n observa c√≥mo el estudiante lleg√≥ a ese c√≥digo, detecta problemas en tiempo real, y proporciona ayuda genuinamente personalizada.

Esta integraci√≥n cierra la brecha entre la pr√°ctica estructurada y el aprendizaje profundo, permitiendo que incluso en ejercicios con respuestas "correctas" definidas, el sistema capture y desarrolle las habilidades cognitivas de orden superior que son el verdadero objetivo del sistema AI-Native.

---

*Documento de implementaci√≥n - Diciembre 2025*
