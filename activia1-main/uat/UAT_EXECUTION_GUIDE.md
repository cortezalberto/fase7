# Gu√≠a de Ejecuci√≥n de UAT - AI-Native MVP

**Fecha de creaci√≥n**: 2025-11-24
**Estado**: Lista para ejecuci√≥n
**Duraci√≥n total**: 2 semanas (10 d√≠as h√°biles)

---

## üìã Tabla de Contenidos

1. [Pre-Ejecuci√≥n: Preparaci√≥n del Ambiente](#1-pre-ejecuci√≥n-preparaci√≥n-del-ambiente)
2. [Semana 1: Escenarios Fundamentales](#2-semana-1-escenarios-fundamentales)
3. [Semana 2: Escenarios Avanzados](#3-semana-2-escenarios-avanzados)
4. [Post-Ejecuci√≥n: An√°lisis y Decisi√≥n](#4-post-ejecuci√≥n-an√°lisis-y-decisi√≥n)
5. [Troubleshooting y Soporte](#5-troubleshooting-y-soporte)

---

## 1. Pre-Ejecuci√≥n: Preparaci√≥n del Ambiente

### D√≠a -3 a D√≠a -1 (3 d√≠as antes de iniciar UAT)

#### 1.1 Configuraci√≥n del Ambiente de Staging

**Ejecutar script de setup**:

**Windows**:
```powershell
cd C:\2025Desarrollo\ariel2\Tesis
.\user-acceptance-testing\setup\setup-uat-environment.ps1 -Environment staging
```

**Linux/macOS**:
```bash
cd /path/to/Tesis
chmod +x user-acceptance-testing/setup/setup-uat-environment.sh
./user-acceptance-testing/setup/setup-uat-environment.sh --staging
```

**Qu√© hace este script**:
- ‚úÖ Verifica pre-requisitos (Python, venv, database)
- ‚úÖ Inicializa base de datos PostgreSQL (staging)
- ‚úÖ Crea 6 usuarios (E01-E05, INST01)
- ‚úÖ Crea actividad "TP1 - Colas Circulares"
- ‚úÖ Configura sistema de reporte de bugs
- ‚úÖ Configura monitoreo y logging
- ‚úÖ Genera archivo de credenciales (`uat-credentials.md`)

**Duraci√≥n estimada**: 10-15 minutos

---

#### 1.2 Verificar Infraestructura Kubernetes

**Verificar que staging est√© desplegado**:

```bash
# Verificar namespace
kubectl get namespaces | grep ai-native-staging

# Verificar pods
kubectl get pods -n ai-native-staging

# Expected output:
# ai-native-backend-xxx    1/1     Running
# ai-native-frontend-xxx   1/1     Running
# ai-native-postgresql-0   1/1     Running
# redis-xxx                1/1     Running

# Verificar servicios
kubectl get svc -n ai-native-staging

# Verificar ingress
kubectl get ingress -n ai-native-staging
```

**Si hay problemas**:
```bash
# Re-desplegar staging
cd kubernetes/staging
./deploy.sh

# Esperar a que todos los pods est√©n Ready
./verify.sh
```

**Duraci√≥n estimada**: 5 minutos (si ya est√° desplegado), 20 minutos (si hay que re-desplegar)

---

#### 1.3 Validar Acceso a la Aplicaci√≥n

**Probar acceso a URLs**:

1. **Backend API**: `https://staging.ai-native.example.com/api/v1/health`
   ```bash
   curl https://staging.ai-native.example.com/api/v1/health
   # Expected: {"status": "healthy", "agents": [...]}
   ```

2. **Frontend**: `https://staging.ai-native.example.com`
   - Abrir en navegador
   - Verificar que cargue la p√°gina de login

3. **Swagger UI**: `https://staging.ai-native.example.com/docs`
   - Verificar documentaci√≥n de API

**Duraci√≥n estimada**: 5 minutos

---

#### 1.4 Probar Login con Usuario de Prueba

**Probar con E01** (primer estudiante):

```bash
curl -X POST https://staging.ai-native.example.com/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "estudiante1@uat.ai-native.edu",
    "password": "UAT2025_E01!"
  }'

# Expected:
# {
#   "success": true,
#   "data": {
#     "access_token": "eyJ...",
#     "token_type": "bearer",
#     "user": {
#       "id": "E01",
#       "name": "Estudiante 1",
#       "email": "estudiante1@uat.ai-native.edu",
#       "role": "STUDENT"
#     }
#   }
# }
```

**Si falla**:
- Verificar que los usuarios fueron creados correctamente
- Revisar logs del backend: `kubectl logs -n ai-native-staging <backend-pod>`
- Re-ejecutar `create-test-users.py`

**Duraci√≥n estimada**: 5 minutos

---

#### 1.5 Distribuir Credenciales a Participantes

**Archivo de credenciales**: `user-acceptance-testing/setup/credentials/uat-credentials.md`

**IMPORTANTE - Seguridad**:
- ‚ùå **NO** enviar credenciales por email sin cifrar
- ‚ùå **NO** compartir archivo en canales p√∫blicos (Slack, WhatsApp)
- ‚úÖ **S√ç** usar email cifrado (PGP, ProtonMail) o servicio seguro (1Password, LastPass)
- ‚úÖ **S√ç** enviar contrase√±as separadas del email (por SMS o llamada)

**Plantilla de email**:

```
Asunto: [CONFIDENCIAL] Credenciales UAT - AI-Native MVP

Hola [Nombre del participante],

Gracias por participar en las pruebas de aceptaci√≥n de usuarios (UAT) del
sistema AI-Native MVP.

CREDENCIALES:
- URL: https://staging.ai-native.example.com
- Email: [email del participante]
- Contrase√±a temporal: [VER MENSAJE SEPARADO]

IMPORTANTE:
1. Cambiar√°s tu contrase√±a en el primer login
2. Lee la Gu√≠a R√°pida: [link a student-quick-start.md]
3. Firma el consentimiento informado: [link]
4. Horario de soporte: Lun-Vie 9:00-18:00

Cualquier duda, escr√≠beme.

Saludos,
Instructor UAT
```

**Enviar a**:
- 5 estudiantes (E01-E05)
- 1 instructor (INST01)

**Duraci√≥n estimada**: 30 minutos (redactar y enviar 6 emails)

---

#### 1.6 Recolectar Consentimientos Informados

**Opciones**:

1. **Formulario digital** (recomendado):
   - Google Forms con pregunta obligatoria de aceptaci√≥n
   - Incluir texto completo de `CONSENTIMIENTO_INFORMADO.md`
   - Validar identidad (email institucional)

2. **Firma digital**:
   - DocuSign, HelloSign, o similar
   - PDF del consentimiento informado

3. **Email de confirmaci√≥n**:
   - Participante responde email con "Acepto participar en UAT"
   - Guardar evidencia de consentimiento

**Checklist de consentimientos**:
- [ ] E01 - Estudiante 1
- [ ] E02 - Estudiante 2
- [ ] E03 - Estudiante 3
- [ ] E04 - Estudiante 4
- [ ] E05 - Estudiante 5
- [ ] INST01 - Instructor

**CR√çTICO**: No iniciar UAT hasta tener TODOS los consentimientos firmados.

**Duraci√≥n estimada**: 2-3 d√≠as (esperar respuestas)

---

#### 1.7 Configurar Canales de Comunicaci√≥n

**Crear canales de Slack** (o alternativa):

1. **#uat-ai-native** (general)
   - Anuncios del instructor
   - Actualizaciones del sistema
   - Coordinaci√≥n general

2. **#uat-bugs** (reportes de bugs)
   - Solo bugs (severidad CRITICAL/HIGH)
   - Template de bug report
   - Respuestas del equipo t√©cnico

3. **#uat-soporte** (soporte t√©cnico)
   - Dudas de uso del sistema
   - Problemas de acceso
   - Consultas generales

**Invitar a participantes**:
- Todos los estudiantes (E01-E05)
- Instructor (INST01)
- Equipo t√©cnico de soporte

**Duraci√≥n estimada**: 15 minutos

---

#### 1.8 Sesi√≥n de Onboarding (Opcional pero Recomendado)

**Videollamada grupal**: 30-45 minutos

**Agenda**:
1. **Bienvenida** (5 min)
   - Presentaci√≥n del proyecto
   - Objetivos de la UAT
   - Importancia del feedback honesto

2. **Tour del sistema** (15 min)
   - Demostraci√≥n de login
   - Creaci√≥n de primera sesi√≥n
   - Interacci√≥n con T-IA-Cog
   - Panel de trazabilidad
   - Reportar un bug

3. **Expectativas y cronograma** (10 min)
   - Tiempo estimado diario (45-60 min)
   - Escenarios a completar
   - Fechas de encuestas
   - Soporte disponible

4. **Q&A** (10 min)
   - Responder dudas
   - Aclarar cualquier inquietud

**Grabar sesi√≥n** para referencia futura.

**Duraci√≥n estimada**: 45 minutos + preparaci√≥n (1 hora total)

---

### Checklist de Pre-Ejecuci√≥n

Antes de iniciar D√≠a 1, verificar:

- [ ] Ambiente de staging desplegado y funcional
- [ ] Usuarios creados (5 estudiantes + 1 instructor)
- [ ] Actividad "TP1 - Colas Circulares" disponible
- [ ] Credenciales distribuidas a todos los participantes
- [ ] Consentimientos informados firmados por todos (6/6)
- [ ] Canales de comunicaci√≥n creados (Slack)
- [ ] Sistema de reporte de bugs configurado
- [ ] Monitoreo y logging habilitado
- [ ] Sesi√≥n de onboarding completada (opcional)
- [ ] Gu√≠as distribuidas (student-quick-start.md, instructor-guide.md)

**Si TODOS los items est√°n marcados**: ‚úÖ **Listo para iniciar D√≠a 1**

---

## 2. Semana 1: Escenarios Fundamentales

### D√≠a 1-2: Onboarding y Tutor Cognitivo

**Participantes**: Todos (E01-E05)
**Tiempo estimado**: 45-60 minutos por d√≠a

#### D√≠a 1: Primera Interacci√≥n (Escenario 1)

**Objetivos**:
- Validar facilidad de acceso
- Verificar claridad de interfaz
- Probar creaci√≥n de sesi√≥n

**Tareas para estudiantes**:
1. Login con credenciales
2. Cambiar contrase√±a temporal
3. Crear primera sesi√≥n (modo TUTOR)
4. Enviar 3 prompts de exploraci√≥n conceptual:
   - "¬øQu√© es una cola circular?"
   - "¬øCu√°ndo usar cola circular vs cola simple?"
   - "¬øCu√°les son las operaciones b√°sicas?"

**Criterios de √©xito**:
- ‚úÖ Login exitoso en < 30 segundos
- ‚úÖ Creaci√≥n de sesi√≥n sin errores
- ‚úÖ Tutor responde en < 5 segundos
- ‚úÖ Respuestas son pedag√≥gicamente √∫tiles

**M√©tricas a recolectar**:
- Tiempo desde login hasta primera interacci√≥n
- N√∫mero de intentos de login fallidos
- Tiempo de respuesta del tutor (p95)

#### D√≠a 2: Sesi√≥n de Trabajo T√≠pica (Escenario 2)

**Participantes**: E02, E03, E05 (3 estudiantes intermedios)
**Tiempo estimado**: 45 minutos

**Tareas**:
1. Crear sesi√≥n con actividad "TP1 - Colas Circulares"
2. Interactuar con T-IA-Cog durante 30-45 minutos
3. Preguntas sugeridas:
   - Planificaci√≥n: "Voy a usar un arreglo de tama√±o fijo, ¬øes correcto?"
   - Implementaci√≥n: "¬øC√≥mo manejo el wrap-around de √≠ndices?"
   - Debugging: "Mi m√©todo enqueue() falla cuando la cola est√° llena"
4. Intentar solicitar c√≥digo completo (provocar bloqueo de GOV-IA)
5. Finalizar sesi√≥n y revisar trazabilidad

**Criterios de √©xito**:
- ‚úÖ Tutor responde en modo socr√°tico (no da c√≥digo completo)
- ‚úÖ Bloqueo de GOV-IA funciona correctamente
- ‚úÖ Trazas N4 capturan intenci√≥n cognitiva
- ‚úÖ Panel de trazabilidad muestra camino cognitivo

**Acci√≥n del instructor**:
- Monitorear sesiones en tiempo real (Live View)
- Observar si GOV-IA bloquea correctamente
- Revisar trazabilidad al final del d√≠a

---

### D√≠a 3-4: Simuladores Profesionales

**Participantes**: E02, E03, E05
**Tiempo estimado**: 90 minutos por d√≠a

#### D√≠a 3: PO-IA y SM-IA

**Tarea 1: Product Owner (30 min)**
1. Crear sesi√≥n con modo PO
2. Recibir requerimiento del PO
3. Hacer preguntas de clarificaci√≥n:
   - "¬øQu√© volumen de datos esperamos?"
   - "¬øHay requisitos de performance?"
   - "¬øPrioridad de este feature?"

**Tarea 2: Scrum Master (15 min)**
1. Crear sesi√≥n con modo SM
2. Completar Daily Standup:
   - ¬øQu√© hiciste ayer?
   - ¬øQu√© har√°s hoy?
   - ¬øImpedimentos?
3. Recibir feedback del SM

**Criterios de √©xito**:
- ‚úÖ PO da requerimientos realistas pero vagos (simula cliente real)
- ‚úÖ SM detecta impedimentos ocultos
- ‚úÖ Evaluaciones de soft skills son coherentes

#### D√≠a 4: IT-IA, IR-IA, DSO-IA

**Tarea 1: Technical Interviewer (45 min)**
1. Crear sesi√≥n con modo INTERVIEW
2. Responder preguntas conceptuales y algor√≠tmicas
3. Recibir evaluaci√≥n con score y breakdown

**Tarea 2: Incident Responder (20 min)**
1. Crear sesi√≥n con modo INCIDENT
2. Diagnosticar incidente simulado
3. Proponer resoluci√≥n paso a paso

**Tarea 3: DevSecOps (15 min)**
1. Crear sesi√≥n con modo SECURITY
2. Compartir c√≥digo con vulnerabilidad intencional
3. Recibir auditor√≠a OWASP Top 10

**Criterios de √©xito**:
- ‚úÖ IT-IA eval√∫a correctamente nivel t√©cnico
- ‚úÖ IR-IA simula presi√≥n de incidente real
- ‚úÖ DSO-IA detecta vulnerabilidades conocidas (SQL injection, etc.)

---

### D√≠a 5: Encuestas SUS y Satisfacci√≥n

**Participantes**: Todos (E01-E05)
**Tiempo estimado**: 15-20 minutos

**Tareas**:
1. Completar encuesta SUS (10 preguntas, 5 min)
2. Completar encuesta de satisfacci√≥n (8 dimensiones + abiertas, 10 min)
3. Reportar cualquier bug pendiente

**Instructor**:
- Compilar resultados de SUS (calcular score)
- Analizar feedback cualitativo
- Identificar bugs cr√≠ticos para resolver en fin de semana

**M√©tricas clave esperadas**:
- SUS Score: ‚â•65 (aceptable en UAT)
- Satisfacci√≥n promedio: ‚â•3.8/5.0
- Bugs cr√≠ticos: ‚â§3 (idealmente 0)

---

## 3. Semana 2: Escenarios Avanzados

### D√≠a 6-7: Evaluaci√≥n de Proceso y Riesgos

#### D√≠a 6: Evaluador de Procesos (E-IA-Proc)

**Participantes**: Todos (E01-E05)
**Tiempo estimado**: 60 minutos

**Tareas**:
1. Crear sesi√≥n completa (30-45 min) con T-IA-Cog
2. Trabajar en implementaci√≥n de ColaCircular
3. Finalizar sesi√≥n
4. Revisar Informe de Evaluaci√≥n Cognitiva (IEC):
   - Competencia general (INICIAL/INTERMEDIO/AVANZADO)
   - Score (0-100)
   - Dimensiones evaluadas (5)
   - Fortalezas y √°reas de mejora

**Criterios de √©xito**:
- ‚úÖ Reporte refleja proceso real del estudiante
- ‚úÖ Score es coherente con nivel de competencia
- ‚úÖ Feedback es accionable y √∫til
- ‚úÖ Estudiantes prefieren esta evaluaci√≥n vs ex√°menes tradicionales

#### D√≠a 7: Detecci√≥n de Riesgos (AR-IA)

**Participante principal**: E04 (estudiante con dificultades)
**Tiempo estimado**: 45 minutos

**Tareas**:
1. Provocar riesgos intencionalmente:
   - Delegaci√≥n excesiva (solicitar c√≥digo varias veces)
   - Razonamiento superficial (preguntas muy gen√©ricas)
   - Aceptaci√≥n acr√≠tica (no cuestionar respuestas)
2. Observar alertas de AR-IA en tiempo real
3. Revisar panel de riesgos al final

**Criterios de √©xito**:
- ‚úÖ AR-IA detecta delegaci√≥n cuando AI Dependency > 60%
- ‚úÖ Alertas son √∫tiles, no intrusivas
- ‚úÖ Estudiante reflexiona sobre su uso de IA

---

### D√≠a 8-9: Accesibilidad, Usabilidad y Uso Libre

#### D√≠a 8: Accesibilidad y Usabilidad (Escenario 7)

**Participantes**: Todos (E01-E05)
**Tiempo estimado**: 30 minutos

**Tareas**:
1. Probar navegaci√≥n con teclado (Tab, Enter, Esc)
2. Verificar contraste de colores (inspeccionar con DevTools)
3. Probar en diferentes resoluciones:
   - 1920x1080 (Full HD)
   - 1366x768 (laptop com√∫n)
   - Mobile (responsive)
4. Probar con diferentes navegadores:
   - Chrome
   - Firefox
   - Edge

**Criterios de √©xito**:
- ‚úÖ Navegaci√≥n por teclado funcional
- ‚úÖ Contraste cumple WCAG 2.1 AA (4.5:1 para texto normal)
- ‚úÖ Responsive funciona en mobile
- ‚úÖ Compatible con 3 navegadores principales

#### D√≠a 9: Uso Libre

**Participantes**: Todos
**Tiempo estimado**: 60 minutos

**Tareas**:
- Usar el sistema libremente
- Probar funcionalidades favoritas
- Experimentar con casos extremos
- Reportar cualquier bug encontrado
- Explorar √°reas no cubiertas en escenarios anteriores

**Objetivo**: Descubrir bugs o problemas no anticipados

---

### D√≠a 10: Encuestas Finales y Cierre

**Participantes**: Todos (E01-E05, INST01)
**Tiempo estimado**: 30 minutos

**Tareas**:
1. Completar encuesta de calidad pedag√≥gica (10 min)
2. Completar encuesta de feedback final (15 min)
3. Sesi√≥n de cierre grupal (opcional, 30 min):
   - Compartir experiencias
   - Feedback en vivo
   - Agradecimientos
   - Entrega de certificados

**Instructor**:
- Exportar todos los datos de UAT
- Compilar bugs reportados
- Calcular m√©tricas finales
- Preparar para fase de an√°lisis

---

## 4. Post-Ejecuci√≥n: An√°lisis y Decisi√≥n

### D√≠a 11-12: Compilaci√≥n de Datos

**Responsable**: Instructor + Equipo t√©cnico
**Duraci√≥n**: 2 d√≠as

**Tareas**:

1. **Exportar datos de staging**:
   ```bash
   # Ejecutar desde frontend del instructor
   curl -X POST https://staging.ai-native.example.com/api/v1/export/research-data \
     -H "Authorization: Bearer $INSTRUCTOR_TOKEN" \
     -d '{
       "start_date": "2025-11-24T00:00:00Z",
       "end_date": "2025-12-08T23:59:59Z",
       "include_traces": true,
       "include_evaluations": true,
       "include_risks": true,
       "format": "json",
       "k_anonymity": 5
     }' > uat-export.json
   ```

2. **Calcular m√©tricas cuantitativas**:
   - SUS Score promedio
   - Satisfacci√≥n promedio por dimensi√≥n
   - NPS (Net Promoter Score)
   - Bugs por severidad (CRITICAL, HIGH, MEDIUM, LOW)
   - Response time (p50, p95, p99)
   - Error rate (%)
   - Session completion rate (%)

3. **Consolidar feedback cualitativo**:
   - Categorizar comentarios (positivo, neutral, negativo)
   - Identificar temas recurrentes
   - Extraer citas representativas

4. **Analizar trazabilidad cognitiva**:
   - Patrones de uso de agentes (T-IA-Cog, S-IA-X, etc.)
   - Evoluci√≥n de AI Dependency por estudiante
   - Caminos cognitivos t√≠picos (EXPLOR ‚Üí PLAN ‚Üí IMPL ‚Üí DEBUG)

5. **Compilar bugs**:
   - Listar todos los bugs reportados
   - Clasificar por severidad y frecuencia
   - Identificar bugs duplicados
   - Priorizar para remediaci√≥n

**Entregable**: Dataset consolidado de UAT

---

### D√≠a 13-14: An√°lisis Cualitativo

**Responsable**: Instructor + Investigador doctoral
**Duraci√≥n**: 2 d√≠as

**Tareas**:

1. **An√°lisis de feedback abierto**:
   - Identificar patrones en respuestas abiertas
   - Codificar feedback con categor√≠as (usabilidad, pedagog√≠a, funcionalidad)
   - Extraer insights clave

2. **Correlaci√≥n de datos**:
   - ¬øEstudiantes con alta satisfacci√≥n tienen baja AI Dependency?
   - ¬øRiesgos detectados correlacionan con frustraci√≥n reportada?
   - ¬øSUS Score correlaciona con tiempo de respuesta?

3. **An√°lisis pedag√≥gico**:
   - ¬øTutor socr√°tico fue efectivo?
   - ¬øEvaluaci√≥n de proceso fue percibida como justa?
   - ¬øSimuladores profesionales a√±adieron valor?

**Entregable**: Informe de an√°lisis cualitativo

---

### D√≠a 15: Generaci√≥n de Reportes

**Responsable**: Instructor
**Duraci√≥n**: 1 d√≠a

**Reportes a generar**:

1. **Reporte Ejecutivo** (para stakeholders):
   - Resumen de 2 p√°ginas
   - M√©tricas clave (SUS, satisfacci√≥n, bugs)
   - Decisi√≥n Go/No-Go preliminar
   - Recomendaciones de alto nivel

2. **Reporte T√©cnico** (para equipo de desarrollo):
   - Lista completa de bugs priorizados
   - Mejoras de usabilidad requeridas
   - Performance issues detectados
   - Plan de remediaci√≥n

3. **Reporte Pedag√≥gico** (para comit√© acad√©mico):
   - Efectividad del tutor socr√°tico
   - Validez de evaluaci√≥n de proceso
   - An√°lisis de trazabilidad N4
   - Contribuci√≥n a objetivos de tesis

**Templates**: Ver secci√≥n "Anexos" al final de este documento

---

### D√≠a 16-17: Decisi√≥n Go/No-Go

**Responsable**: Instructor + Stakeholders
**Duraci√≥n**: 2 d√≠as

#### D√≠a 16: Reuni√≥n de Revisi√≥n

**Participantes**:
- Instructor UAT
- Investigador doctoral (Alberto Cortez)
- Equipo t√©cnico (backend, frontend)
- Comit√© acad√©mico (opcional)

**Agenda** (2 horas):
1. Presentaci√≥n de resultados (30 min)
2. Revisi√≥n de m√©tricas cuantitativas (20 min)
3. Discusi√≥n de feedback cualitativo (30 min)
4. An√°lisis de bugs cr√≠ticos (20 min)
5. Recomendaciones (20 min)

#### D√≠a 17: Decisi√≥n Final

**Evaluar criterios Go/No-Go**:

| Criterio | Target | Resultado UAT | Status |
|----------|--------|---------------|--------|
| SUS Score | ‚â•70 | [resultado] | [GO/NO-GO] |
| Satisfacci√≥n | ‚â•4.0 | [resultado] | [GO/NO-GO] |
| Bugs cr√≠ticos | ‚â§5 | [resultado] | [GO/NO-GO] |
| Response time p95 | <3s | [resultado] | [GO/NO-GO] |
| Error rate | <5% | [resultado] | [GO/NO-GO] |

**Opciones de decisi√≥n**:

1. **GO (Lanzar a Producci√≥n)**:
   - Todos los criterios cuantitativos cumplidos
   - Feedback cualitativo mayormente positivo (‚â•70%)
   - Bugs cr√≠ticos resueltos o con workaround
   - Instructor aprueba calidad pedag√≥gica

2. **NO-GO (Postponer Lanzamiento)**:
   - SUS Score <60
   - Bugs cr√≠ticos >10 sin resolver
   - Feedback cualitativo mayormente negativo
   - Problemas fundamentales de arquitectura

3. **CONDITIONAL GO (Lanzamiento con Reservas)**:
   - SUS Score 60-69 (aceptable pero mejorable)
   - Bugs high >15 pero no cr√≠ticos
   - Feedback mixto (50/50)
   - **Requiere**: Plan de mejoras en Sprint Post-MVP

**Documentar decisi√≥n**:
- Acta de reuni√≥n
- Justificaci√≥n detallada
- Plan de acci√≥n (si NO-GO o CONDITIONAL GO)
- Firmas de aprobaci√≥n

---

### Fase de Remediaci√≥n (si NO-GO o CONDITIONAL GO)

**Duraci√≥n**: 2-3 semanas

**Sprint de Correcci√≥n**:

**Semana 1: Bugs Cr√≠ticos**
- Resolver todos los bugs CRITICAL (P0)
- Resolver 80% de bugs HIGH (P1)
- Testing exhaustivo de fixes

**Semana 2: Mejoras de Usabilidad**
- Implementar mejoras identificadas en feedback
- Refinar respuestas de agentes (si aplica)
- Optimizar performance (si response time >3s)

**Semana 3: Validaci√≥n**
- **Mini-UAT**: 3 d√≠as con 2 estudiantes
- Verificar que fixes funcionan
- Calcular nuevo SUS Score
- **Decisi√≥n Go/No-Go final**

---

## 5. Troubleshooting y Soporte

### Problemas Comunes Durante UAT

#### Problema 1: Usuario No Puede Iniciar Sesi√≥n

**S√≠ntomas**:
- Error "Invalid credentials"
- Error 500 en login
- P√°gina de login no carga

**Soluci√≥n**:
1. Verificar credenciales (copiar/pegar desde archivo)
2. Verificar que usuario existe:
   ```bash
   kubectl exec -it -n ai-native-staging <backend-pod> -- \
     python -c "from src.ai_native_mvp.database import *; \
                with get_db_session() as s: \
                  print(s.execute(text('SELECT * FROM users WHERE email=:email'), \
                        {'email': 'estudiante1@uat.ai-native.edu'}).fetchone())"
   ```
3. Resetear contrase√±a si es necesario
4. Verificar logs del backend

#### Problema 2: Tutor No Responde o Tarda Mucho

**S√≠ntomas**:
- Timeout despu√©s de 30 segundos
- Response time >10 segundos
- Error 504 Gateway Timeout

**Soluci√≥n**:
1. Verificar LLM provider (OpenAI API status)
2. Revisar logs de backend (b√∫squeda de "LLM timeout")
3. Aumentar timeout temporalmente (no ideal para UAT)
4. Usar prompt m√°s corto (workaround)
5. Reportar como bug HIGH

#### Problema 3: Trazas No Se Guardan

**S√≠ntomas**:
- Panel de trazabilidad vac√≠o
- Error al finalizar sesi√≥n
- Trazas no aparecen despu√©s de interacci√≥n

**Soluci√≥n**:
1. Verificar estado de la base de datos:
   ```bash
   kubectl exec -it -n ai-native-staging postgresql-0 -- \
     psql -U ai_native -d ai_native_staging -c "SELECT COUNT(*) FROM cognitive_traces;"
   ```
2. Revisar logs de backend (errores de database)
3. Verificar transacciones (posible rollback)
4. Re-ejecutar interacci√≥n
5. Reportar como bug CRITICAL

#### Problema 4: Estudiante Reporta Bug Duplicado

**S√≠ntomas**:
- Mismo bug reportado por 2+ estudiantes
- Bug ya est√° en tracker como TRIAGED

**Soluci√≥n**:
1. Buscar bug en tracker (`bug-tracker.json`)
2. Si existe, responder:
   "Gracias por reportar. Este bug ya est√° registrado como BUG-XXX y est√° siendo trabajado."
3. A√±adir estudiante como "reporter adicional" en bug
4. Notificar cuando se resuelva

### Escalaci√≥n de Problemas

**Severidad CRITICAL (P0)** - Respuesta inmediata:
- Sistema inutilizable
- P√©rdida de datos
- Vulnerabilidad de seguridad

**Acci√≥n**:
1. Notificar a instructor inmediatamente (Slack + email)
2. Equipo t√©cnico investiga en <1 hora
3. Fix o workaround en <4 horas
4. Comunicar a todos los participantes

**Severidad HIGH (P1)** - Respuesta en 4 horas:
- Funcionalidad principal no funciona
- Afecta mayor√≠a de usuarios

**Acci√≥n**:
1. Triaging en <4 horas
2. Fix en <2 d√≠as
3. Comunicar a usuarios afectados

**Severidad MEDIUM/LOW** - Respuesta en 1-2 d√≠as:
- Funcionalidad secundaria
- Problema cosm√©tico

**Acci√≥n**:
1. Documentar en tracker
2. Priorizar para post-UAT
3. No bloquear progreso de UAT

---

## Anexos

### Anexo A: Template de Reporte Ejecutivo

```markdown
# UAT Results - Executive Summary

**Project**: AI-Native MVP
**Duration**: 2025-11-24 to 2025-12-08 (2 weeks)
**Participants**: 5 students + 1 instructor

## Key Metrics

| Metric | Target | Result | Status |
|--------|--------|--------|--------|
| SUS Score | ‚â•70 | [X] | [‚úÖ/‚ùå] |
| Satisfaction | ‚â•4.0 | [X] | [‚úÖ/‚ùå] |
| Critical Bugs | ‚â§5 | [X] | [‚úÖ/‚ùå] |
| NPS | ‚â•50 | [X] | [‚úÖ/‚ùå] |

## Highlights

**Strengths**:
- [Point 1]
- [Point 2]
- [Point 3]

**Areas for Improvement**:
- [Point 1]
- [Point 2]
- [Point 3]

## Recommendation

**Decision**: [GO / NO-GO / CONDITIONAL GO]

**Justification**: [2-3 sentences]

**Next Steps**: [If GO: production deployment plan] [If NO-GO: remediation plan]
```

### Anexo B: Template de Bug Report (para equipo t√©cnico)

```markdown
# Bug Report Summary - UAT

**Total Bugs**: [X]
**Critical**: [X] | **High**: [X] | **Medium**: [X] | **Low**: [X]

## Critical Bugs (P0)

### BUG-001: [T√≠tulo]
- **Severidad**: CRITICAL
- **Frecuencia**: [Siempre/Frecuente/Ocasional]
- **Reportado por**: E01, E03 (2 estudiantes)
- **Descripci√≥n**: [...]
- **Pasos para reproducir**: [...]
- **Fix propuesto**: [...]
- **ETA**: [Fecha]

[Repetir para cada bug cr√≠tico]

## High Bugs (P1)

[Similar format]

## Prioridades para Sprint de Correcci√≥n

1. [BUG-ID]: [T√≠tulo] - Impacto: [Alto/Medio/Bajo]
2. [...]
```

### Anexo C: Template de Feedback Consolidado

```markdown
# UAT Feedback - Consolidated

## Quantitative Summary

**SUS Score**: [X] / 100
**Satisfaction**: [X] / 5.0
**NPS**: [X]

## Qualitative Themes

### Theme 1: Usability
- **Positive**: [Quote 1], [Quote 2]
- **Negative**: [Quote 1], [Quote 2]
- **Recommendation**: [...]

### Theme 2: Pedagogical Effectiveness
- **Positive**: [...]
- **Negative**: [...]
- **Recommendation**: [...]

[Repetir para cada tema]

## Student Quotes (Representative)

**Most Liked**:
> "[Quote from survey]" - E03

**Most Disliked**:
> "[Quote from survey]" - E04

**Feature Request**:
> "[Quote from survey]" - E01
```

---

## Resumen de Tiempos

| Fase | Duraci√≥n | Esfuerzo (horas) |
|------|----------|------------------|
| **Pre-Ejecuci√≥n** | 3-5 d√≠as | 8-10 horas (instructor) |
| **Semana 1** | 5 d√≠as | 25-30 horas (estudiantes), 10 horas (instructor) |
| **Semana 2** | 5 d√≠as | 20-25 horas (estudiantes), 8 horas (instructor) |
| **Post-Ejecuci√≥n** | 7 d√≠as | 40-50 horas (instructor + equipo) |
| **Remediaci√≥n** (si aplica) | 2-3 semanas | 80-120 horas (equipo t√©cnico) |

**Total**: 3-5 semanas desde pre-ejecuci√≥n hasta decisi√≥n final

---

**¬°√âxito en la UAT!** üöÄ

Si tienes dudas, consulta las gu√≠as completas o contacta al equipo de soporte.

---

**Versi√≥n**: 1.0
**√öltima actualizaci√≥n**: 2025-11-24
**Autor**: Mag. Alberto Cortez